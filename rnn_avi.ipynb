{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_avi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMakyfICrOsJmhsrEFO9zdc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BARURISAIAVINASH/AVINASH_datascience/blob/main/rnn_avi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQ92QyuLlqi"
      },
      "source": [
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from numpy import array\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ4huRVUF7wF"
      },
      "source": [
        "# define model\n",
        "inputs1 = Input(shape=(1, 1))\n",
        "lstm1 = LSTM(5)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bDi7lrtL__L"
      },
      "source": [
        "# define input data\n",
        "data = array([0.1, 0.2, 0.3])\n",
        "# make and show prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PhnZ9UWKMJcB",
        "outputId": "fa306da9-6e98-4fae-d921-4b2ca49041d7"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Wdpz6gMLHX"
      },
      "source": [
        "data=data.reshape((1,3,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "4hLh9YJjMSHb",
        "outputId": "3a44e048-4646-4381-82c1-4a1139a9f61a"
      },
      "source": [
        "model.predict(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input Tensor(\"input_5:0\", shape=(None, 1, 1), dtype=float32), but it was called on an input with incompatible shape (None, 3, 1).\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc0e8755b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02967157, 0.04828845, 0.04395958, 0.03860492, 0.03141453]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgLhEMLZNpPg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7x82-Xdr903"
      },
      "source": [
        "###############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aXy-Wycr93U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3L9FxpZr9yw"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "\n",
        "data =np.random.randint(2, size=500)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KafXz4J1sD0-"
      },
      "source": [
        "data=data.reshape(100,5,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jWbVXB02sJAA",
        "outputId": "8480864d-d5e1-4515-ff7a-dfd313be1a6d"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSOBw9Nfvtkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "k5BRwbCwxxx-",
        "outputId": "69aa216a-ff4b-47f5-c9c5-9e49668f7ef5"
      },
      "source": [
        "target =np.random.randint(2, size=100)\n",
        "\n",
        "\n",
        "target.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BbaCh3Qxx0r"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sdZ0gqFxxx4J",
        "outputId": "3240b7da-de05-4eaf-c6c8-341cfbbbd62b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fuNBycVEyH0b",
        "outputId": "49d158d4-b74b-4678-9847-eef32850d471"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sv249gmvtnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B4GNx5CvuTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOQO21CsMNr"
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(LSTM((1), batch_input_shape=(20,5,1)))\n",
        "\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#4(mn+n2+n)\n",
        "#n=out,m=input_size or featuresNo of params= 4*((num_features used+1)*num_units+ num_units^2)\n",
        "#4(1*1+1*1+1)\n",
        "\n",
        "#The +1 is because of the additional bias we take.\n",
        "\n",
        "#Where the num_features is the num_features in your input shape to the LSTM: Input_shape=(window_size,num_features)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "f8yudrIoyzib",
        "outputId": "cbdb3f0e-b57e-4dd9-f57c-6ec42e87f585"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_11 (LSTM)               (20, 1)                   12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "40S-4x8myzmJ",
        "outputId": "8cd5b936-9355-4037-f52f-f57efbf24e7e"
      },
      "source": [
        "#history=model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))\n",
        "model.fit(x_train, y_train, epochs=300, shuffle=False, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-3e2e0e73c608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#history=model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [20,1] from a tensor with shape [32,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_11/lstm_11/PartitionedCall]] [Op:__inference_train_function_610252]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WeFFydeAwFp"
      },
      "source": [
        "y_pre=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Nz-xkN6KAwIc",
        "outputId": "ee748818-238e-4d18-8ee0-d74e9115ef93"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "goq_hzIcAwOF",
        "outputId": "21092d85-1f6c-40ce-d890-7939460ec324"
      },
      "source": [
        "y_pre.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "7BQ7BwJ3AwLt",
        "outputId": "130f98f9-d83a-47eb-b856-77e796430868"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY9Me0cASwIc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YlWAAKpsw4G"
      },
      "source": [
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE-zUhUfxHfy"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(2,1)))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEZkvkbpF2K2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "fSuRVHkAGaoW",
        "outputId": "4a018cd6-aeeb-4bc6-bf4a-278ae529ea5e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 11\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "print(sequence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.09090909090909091, 0.18181818181818182, 0.2727272727272727, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.9090909090909091]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHNEeqkSKRXr"
      },
      "source": [
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df.shift(1), df], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "Th2vv5O0LK_t",
        "outputId": "68a4ae57-77f8-468b-fd98-fdae5af7ba55"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.09090909, 0.18181818, 0.27272727, 0.36363636,\n",
              "       0.45454545, 0.54545455, 0.63636364, 0.72727273, 0.81818182])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "y45zeJBwLLvD",
        "outputId": "725b65c5-a9f1-4c96-ce0c-40633cb9648d"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09090909, 0.18181818, 0.27272727, 0.36363636, 0.45454545,\n",
              "       0.54545455, 0.63636364, 0.72727273, 0.81818182, 0.90909091])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu7-IooqLM9q"
      },
      "source": [
        "X = X.reshape(len(X), 1, 1)\n",
        "# 1. define network\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8giKfSLcupYI",
        "outputId": "d42a5302-b019-4454-f7fa-9d89eba9bdb7"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4l5cP5byLQ4D",
        "outputId": "43a2e686-5486-45e5-f82a-68122c6be964"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4wqFDBILRuU"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(10, batch_input_shape=(2,1,1)))\n",
        "model.add(Dense(1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGKeheCoL0GC"
      },
      "source": [
        "# 2. compile network\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "KXACr1uJL3ev",
        "outputId": "edb0d827-4205-4261-a410-75877f4c90a4"
      },
      "source": [
        "model.summary()\n",
        "#4(10*1+100+10)=480\n",
        "#10*1+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (2, 10)                   480       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (2, 1)                    11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "cisEs1AbL5l5",
        "outputId": "9e218f73-8d0e-40f5-dbeb-94138ec7b047"
      },
      "source": [
        "# 3. fit network\n",
        "history = model.fit(X, y, epochs=10, batch_size=len(X), verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (2, 1, 1) for input Tensor(\"lstm_12_input:0\", shape=(2, 1, 1), dtype=float32), but it was called on an input with incompatible shape (10, 1, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (2, 1, 1) for input Tensor(\"lstm_12_input:0\", shape=(2, 1, 1), dtype=float32), but it was called on an input with incompatible shape (10, 1, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "t-GZPr5mNMb8",
        "outputId": "6ed96ac2-5e17-455f-c219-8cff125dcbd0"
      },
      "source": [
        "# 4. evaluate network\n",
        "loss = model.evaluate(X, y, verbose=0)\n",
        "print(loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-32161f8c7b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4. evaluate network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [2,1] from a tensor with shape [10,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_12/lstm_12/PartitionedCall]] [Op:__inference_test_function_615668]\n\nFunction call stack:\ntest_function -> test_function -> test_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "hXKg3ABMNUfV",
        "outputId": "40fef745-d40a-481b-8259-8ef0b0269276"
      },
      "source": [
        "# 5. make predictions\n",
        "predictions = model.predict(X, verbose=0)\n",
        "predictions.shape\n",
        "y_=predictions\n",
        "y_=np.array(y_).reshape(9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-4b219b101c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 5. make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [2,1] from a tensor with shape [10,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_12/lstm_12/PartitionedCall]] [Op:__inference_predict_function_616174]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8cnTvYwCNYms",
        "outputId": "e328d4c5-cc84-4e40-b53c-f25403271b61"
      },
      "source": [
        "y_.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhTx0_oVTk8"
      },
      "source": [
        "from sklearn.metrics import mutual_info_score\n",
        "\n",
        "def calc_MI(x, y, bins):\n",
        "    c_xy = np.histogram2d(x, y, bins)[0]\n",
        "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
        "    return mi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "orGPAo2UVToM",
        "outputId": "6a1481fd-c69e-40a6-c572-f00b962c6c8c"
      },
      "source": [
        "calc_MI(y, y_, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0431918705451206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txy5HxmneA_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inNhWsz8eBDJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-pXlGtReBUF"
      },
      "source": [
        "##############################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Db4_4VIweBW9",
        "outputId": "14699155-2a1f-4858-ec9e-c493287a0763"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KZNWyeteBaE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif, mutual_info_regression\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9_x3dwoRRRr"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-0I8d1_URRVu",
        "outputId": "090b05aa-8884-47c4-85b7-7919b8b790b1"
      },
      "source": [
        "files=files.upload()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3c05985-a9b2-4c59-ba46-f5f7420b7b5a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3c05985-a9b2-4c59-ba46-f5f7420b7b5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving santander-train.csv to santander-train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liFOdfG8RRPe",
        "outputId": "800ca512-dbaa-4128-c45b-3e5b5247ebb5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv('santander-train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f34094232e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'santander-train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File santander-train.csv does not exist: 'santander-train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "r6fw8RjfRRMf",
        "outputId": "d6d64c01-57a7-4432-8001-207ca0399fe5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>imp_op_var40_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult3</th>\n",
              "      <th>imp_op_var41_efect_ult1</th>\n",
              "      <th>imp_op_var41_efect_ult3</th>\n",
              "      <th>imp_op_var41_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult3</th>\n",
              "      <th>imp_op_var39_ult1</th>\n",
              "      <th>imp_sal_var16_ult1</th>\n",
              "      <th>ind_var1_0</th>\n",
              "      <th>ind_var1</th>\n",
              "      <th>ind_var2_0</th>\n",
              "      <th>ind_var2</th>\n",
              "      <th>ind_var5_0</th>\n",
              "      <th>ind_var5</th>\n",
              "      <th>ind_var6_0</th>\n",
              "      <th>ind_var6</th>\n",
              "      <th>ind_var8_0</th>\n",
              "      <th>ind_var8</th>\n",
              "      <th>ind_var12_0</th>\n",
              "      <th>ind_var12</th>\n",
              "      <th>ind_var13_0</th>\n",
              "      <th>ind_var13_corto_0</th>\n",
              "      <th>ind_var13_corto</th>\n",
              "      <th>ind_var13_largo_0</th>\n",
              "      <th>ind_var13_largo</th>\n",
              "      <th>ind_var13_medio_0</th>\n",
              "      <th>ind_var13_medio</th>\n",
              "      <th>ind_var13</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var5_ult1</th>\n",
              "      <th>saldo_medio_var5_ult3</th>\n",
              "      <th>saldo_medio_var8_hace2</th>\n",
              "      <th>saldo_medio_var8_hace3</th>\n",
              "      <th>saldo_medio_var8_ult1</th>\n",
              "      <th>saldo_medio_var8_ult3</th>\n",
              "      <th>saldo_medio_var12_hace2</th>\n",
              "      <th>saldo_medio_var12_hace3</th>\n",
              "      <th>saldo_medio_var12_ult1</th>\n",
              "      <th>saldo_medio_var12_ult3</th>\n",
              "      <th>saldo_medio_var13_corto_hace2</th>\n",
              "      <th>saldo_medio_var13_corto_hace3</th>\n",
              "      <th>saldo_medio_var13_corto_ult1</th>\n",
              "      <th>saldo_medio_var13_corto_ult3</th>\n",
              "      <th>saldo_medio_var13_largo_hace2</th>\n",
              "      <th>saldo_medio_var13_largo_hace3</th>\n",
              "      <th>saldo_medio_var13_largo_ult1</th>\n",
              "      <th>saldo_medio_var13_largo_ult3</th>\n",
              "      <th>saldo_medio_var13_medio_hace2</th>\n",
              "      <th>saldo_medio_var13_medio_hace3</th>\n",
              "      <th>saldo_medio_var13_medio_ult1</th>\n",
              "      <th>saldo_medio_var13_medio_ult3</th>\n",
              "      <th>saldo_medio_var17_hace2</th>\n",
              "      <th>saldo_medio_var17_hace3</th>\n",
              "      <th>saldo_medio_var17_ult1</th>\n",
              "      <th>saldo_medio_var17_ult3</th>\n",
              "      <th>saldo_medio_var29_hace2</th>\n",
              "      <th>saldo_medio_var29_hace3</th>\n",
              "      <th>saldo_medio_var29_ult1</th>\n",
              "      <th>saldo_medio_var29_ult3</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.170000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>300.0</td>\n",
              "      <td>122.22</td>\n",
              "      <td>300.0</td>\n",
              "      <td>240.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.030000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.770000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>91.56</td>\n",
              "      <td>138.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64007.970000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>40501.08</td>\n",
              "      <td>13501.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85501.89</td>\n",
              "      <td>85501.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 371 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  var3  var15  ...  saldo_medio_var44_ult3          var38  TARGET\n",
              "0   1     2     23  ...                     0.0   39205.170000       0\n",
              "1   3     2     34  ...                     0.0   49278.030000       0\n",
              "2   4     2     23  ...                     0.0   67333.770000       0\n",
              "3   8     2     37  ...                     0.0   64007.970000       0\n",
              "4  10     2     39  ...                     0.0  117310.979016       0\n",
              "\n",
              "[5 rows x 371 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YBeOJE2mRyVc",
        "outputId": "81dfbd17-dc89-4a37-9add-f96f87393b50"
      },
      "source": [
        "X = data.drop('TARGET', axis = 1)\n",
        "y = data['TARGET']\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((76020, 370), (76020,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuR9z2PsoF2e"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvKqCYtIoKVZ"
      },
      "source": [
        "constant_filter = VarianceThreshold(threshold=0.01)\n",
        "constant_filter.fit(X_train)\n",
        "X_train_filter = constant_filter.transform(X_train)\n",
        "X_test_filter = constant_filter.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k1Z3C83N8yU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YcdS28-spgM9",
        "outputId": "681068b5-033a-4ce4-a055-9e689e7093a2"
      },
      "source": [
        "X_train_filter.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60816, 274)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YqHQWetlpjZ_",
        "outputId": "76450e95-60fa-4f6a-ef8c-f636828e822e"
      },
      "source": [
        "X_test_filter.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15204, 274)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJb8MJCipmYk"
      },
      "source": [
        "X_train_T = X_train_filter.T\n",
        "X_test_T = X_test_filter.T\n",
        "X_train_T = pd.DataFrame(X_train_T)\n",
        "X_test_T = pd.DataFrame(X_test_T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0E4JhjNupwY5",
        "outputId": "cb7012dc-da85-46e6-8e7c-cc66a72e02e0"
      },
      "source": [
        "duplicated_features = X_train_T.duplicated()\n",
        "features_to_keep = [not index for index in duplicated_features]\n",
        "X_train_unique = X_train_T[features_to_keep].T\n",
        "X_test_unique = X_test_T[features_to_keep].T\n",
        "X_train_unique.shape, X_test_unique.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60816, 257), (15204, 257))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "CRIw3rP8p1Mo",
        "outputId": "45f3d745-03b3-417e-bc71-9994d9376db7"
      },
      "source": [
        "mi = mutual_info_classif(X_train_unique, y_train) \n",
        "len(mi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "SD0yXrlMp5RA",
        "outputId": "506f2acb-72d5-4d24-9bea-627e4f88f885"
      },
      "source": [
        "mi[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.19597689e-04, 0.00000000e+00, 1.36639857e-02, 8.36827958e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.78289532e-04, 3.71316040e-04,\n",
              "       0.00000000e+00, 1.11459174e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFT1kBZpK27J"
      },
      "source": [
        "mi = pd.Series(mi)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "UQULZpvTK7fX",
        "outputId": "c862849d-49f4-45bc-cfdf-a2a2ebc1b672"
      },
      "source": [
        "mi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.000520\n",
              "1      0.000000\n",
              "2      0.013664\n",
              "3      0.000084\n",
              "4      0.000000\n",
              "         ...   \n",
              "252    0.000026\n",
              "253    0.000070\n",
              "254    0.000487\n",
              "255    0.000629\n",
              "256    0.001917\n",
              "Length: 257, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u5acZTBK8r2"
      },
      "source": [
        "\n",
        "mi.index = X_train_unique.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "dpvGj9FELCjb",
        "outputId": "b46a19b2-3638-43bb-ddfa-f0a897dc716d"
      },
      "source": [
        "mi.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
              "            ...\n",
              "            264, 265, 266, 267, 268, 269, 270, 271, 272, 273],\n",
              "           dtype='int64', length=257)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSAnaGnjLEen"
      },
      "source": [
        "mi.sort_values(ascending=False, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "OWYzWRxiLb4N",
        "outputId": "a991763d-b636-433c-e017-47a7ce983ab5"
      },
      "source": [
        "mi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89     0.017197\n",
              "42     0.016553\n",
              "22     0.016218\n",
              "53     0.016072\n",
              "105    0.015688\n",
              "         ...   \n",
              "82     0.000000\n",
              "152    0.000000\n",
              "84     0.000000\n",
              "85     0.000000\n",
              "220    0.000000\n",
              "Length: 257, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "wuEORPy3LduX",
        "outputId": "18416480-fa15-445a-f276-819c608e0937"
      },
      "source": [
        "plt.title('Mutual information with respect to features')\n",
        "mi.plot.bar(figsize = (16,5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "Md53mMNdLh6w",
        "outputId": "3a1bbe60-5a40-486d-87f1-6e987b14b20c"
      },
      "source": [
        "sel = SelectPercentile(mutual_info_classif, percentile=10).fit(X_train_unique, y_train)\n",
        "X_train_unique.columns[sel.get_support()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([  2,  21,  22,  42,  46,  48,  51,  52,  53,  88,  89,  95,  99,\n",
              "            102, 104, 105, 109, 125, 132, 134, 207, 212, 234, 235, 236, 237],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "l1H0eyGjLww6",
        "outputId": "daa9827f-0360-4a08-a046-02b62df94124"
      },
      "source": [
        "X_train_mi = sel.transform(X_train_unique)\n",
        "X_test_mi = sel.transform(X_test_unique)\n",
        "X_train_mi.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60816, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPQBJJkAS965"
      },
      "source": [
        "X_train=np.array(X_train).reshape(-1,370,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaALuYb5S9-W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMMoqHqhS-Ug"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "56xiLxfTNm2H",
        "outputId": "a5be8977-1d95-467d-c553-54fb0f8ad312"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "regressor = Sequential()\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "regressor.fit(X_train, y_train, epochs = 1, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1901/1901 [==============================] - 1522s 801ms/step - loss: 0.0377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35617faba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "GUxs_9aemy_e",
        "outputId": "1eb9ee7f-477b-4325-ff12-6a004af1355d"
      },
      "source": [
        "regressor.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a0d3a4210380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16m3kBHXmzDw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV99xkuESU-w"
      },
      "source": [
        "####################################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGhEnvnlXCc9"
      },
      "source": [
        "#https://github.com/sachinruk/PyData_Keras_Talk/blob/master/cosine_LSTM.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TH84hCXOXCZt",
        "outputId": "c80136f9-b642-4201-ce50-2c44c2881b1f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from standard_plots import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import theano\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-377f5c8b4b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstandard_plots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'standard_plots'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "TiEY4NvpXCXM",
        "outputId": "fd73c2e1-19f1-4306-8118-b42d038c2d55"
      },
      "source": [
        "pip3 install matplotlib\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-2471e70b6479>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install matplotlib\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iNKEbg_nsJo"
      },
      "source": [
        "########################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch0T_QA4RmiT"
      },
      "source": [
        "#https://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vKS5zHB8RnXn",
        "outputId": "4420519a-9cce-4b65-e3e1-ac489bae7041"
      },
      "source": [
        "from google.colab import files\n",
        "files=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42ad537f-ea7e-428a-bd90-302fe8673b8c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42ad537f-ea7e-428a-bd90-302fe8673b8c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving shampoo.csv to shampoo.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61y8JoSNRnzH"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv('shampoo.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "MEMKehtWRn8Z",
        "outputId": "fb2c5d2b-1fb5-49ba-9949-ea58f11bd1af"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Sales of shampoo over a three year period</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-01</td>\n",
              "      <td>266.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-02</td>\n",
              "      <td>145.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-03</td>\n",
              "      <td>183.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-04</td>\n",
              "      <td>119.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-05</td>\n",
              "      <td>180.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Month  Sales of shampoo over a three year period\n",
              "0  1-01                                      266.0\n",
              "1  1-02                                      145.9\n",
              "2  1-03                                      183.1\n",
              "3  1-04                                      119.3\n",
              "4  1-05                                      180.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxNnAevrRnwt"
      },
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPstRnO4RnuZ"
      },
      "source": [
        "import matplotlib\n",
        "# be able to save images on server\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot\n",
        "import numpy\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDQJBRlGRnrl"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = concat(columns, axis=1)\n",
        "\tdf = df.drop(0)\n",
        "\treturn df\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn Series(diff)\n",
        "def scale(train, test):\n",
        "\t# fit scaler\n",
        "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\tscaler = scaler.fit(train)\n",
        "\t# transform train\n",
        "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
        "\ttrain_scaled = scaler.transform(train)\n",
        "\t# transform test\n",
        "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
        "\ttest_scaled = scaler.transform(test)\n",
        "\treturn scaler, train_scaled, test_scaled\n",
        "def invert_scale(scaler, X, yhat):\n",
        "\tnew_row = [x for x in X] + [yhat]\n",
        "\tarray = numpy.array(new_row)\n",
        "\tarray = array.reshape(1, len(array))\n",
        "\tinverted = scaler.inverse_transform(array)\n",
        "\treturn inverted[0, -1]\n",
        " \n",
        "# evaluate the model on a dataset, returns RMSE in transformed units\n",
        "def evaluate(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n",
        "\t# separate\n",
        "\tX, y = scaled_dataset[:,0:-1], scaled_dataset[:,-1]\n",
        "\t# reshape\n",
        "\treshaped = X.reshape(len(X), 1, 1)\n",
        "\t# forecast dataset\n",
        "\toutput = model.predict(reshaped, batch_size=batch_size)\n",
        "\t# invert data transforms on forecast\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(output)):\n",
        "\t\tyhat = output[i,0]\n",
        "\t\t# invert scaling\n",
        "\t\tyhat = invert_scale(scaler, X[i], yhat)\n",
        "\t\t# invert differencing\n",
        "\t\tyhat = yhat + raw_data[i]\n",
        "\t\t# store forecast\n",
        "\t\tpredictions.append(yhat)\n",
        "\t# report performance\n",
        "\trmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n",
        "\treturn rmse\n",
        " \n",
        "# fit an LSTM network to training data\n",
        "def fit_lstm(train, test, raw, scaler, batch_size, nb_epoch, neurons):\n",
        "\tX, y = train[:, 0:-1], train[:, -1]\n",
        "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\t# prepare model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\t# fit model\n",
        "\ttrain_rmse, test_rmse = list(), list()\n",
        "\tfor i in range(nb_epoch):\n",
        "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "\t\tmodel.reset_states()\n",
        "\t\t# evaluate model on train data\n",
        "\t\traw_train = raw[-(len(train)+len(test)+1):-len(test)]\n",
        "\t\ttrain_rmse.append(evaluate(model, raw_train, train, scaler, 0, batch_size))\n",
        "\t\tmodel.reset_states()\n",
        "\t\t# evaluate model on test data\n",
        "\t\traw_test = raw[-(len(test)+1):]\n",
        "\t\ttest_rmse.append(evaluate(model, raw_test, test, scaler, 0, batch_size))\n",
        "\t\tmodel.reset_states()\n",
        "\thistory = DataFrame()\n",
        "\thistory['train'], history['test'] = train_rmse, test_rmse\n",
        "\treturn history\n",
        " \n",
        "# run diagnostic experiments\n",
        "def run():\n",
        "\t# load dataset\n",
        "\tseries = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\t# transform data to be stationary\n",
        "\traw_values = series.values\n",
        "\tdiff_values = difference(raw_values, 1)\n",
        "\t# transform data to be supervised learning\n",
        "\tsupervised = timeseries_to_supervised(diff_values, 1)\n",
        "\tsupervised_values = supervised.values\n",
        "\t# split data into train and test-sets\n",
        "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
        "\t# transform the scale of the data\n",
        "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
        "\t# fit and evaluate model\n",
        "\ttrain_trimmed = train_scaled[2:, :]\n",
        "\t# config\n",
        "\trepeats = 10\n",
        "\tn_batch = 4\n",
        "\tn_epochs = 500\n",
        "\tn_neurons = 1\n",
        "\t# run diagnostic tests\n",
        "\tfor i in range(repeats):\n",
        "\t\thistory = fit_lstm(train_trimmed, test_scaled, raw_values, scaler, n_batch, n_epochs, n_neurons)\n",
        "\t\tpyplot.plot(history['train'], color='blue')\n",
        "\t\tpyplot.plot(history['test'], color='orange')\n",
        "\t\tprint('%d) TrainRMSE=%f, TestRMSE=%f' % (i, history['train'].iloc[-1], history['test'].iloc[-1]))\n",
        "\tpyplot.savefig('epochs_diagnostic.png')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw-npZUVRnqB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2yK1EPxRnoV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83dA9jAtRnbH"
      },
      "source": [
        "###############################################################################################################################3\n",
        "####################################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lvu_2T8IRmgF",
        "outputId": "65817d0c-c3b2-4025-889a-d6ea4992c22d"
      },
      "source": [
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df, df.shift(1)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n",
        "# configure network\n",
        "n_batch = len(X)\n",
        "n_epoch = 100\n",
        "n_neurons = 10\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# fit network\n",
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "# online forecast\n",
        "for i in range(len(X)):\n",
        "\ttestX, testy = X[i], y[i]\n",
        "\ttestX = testX.reshape(1, 1, 1)\n",
        "\tyhat = model.predict(testX, batch_size=1)\n",
        "\tprint('>Expected=%.1f, Predicted=%.1f' % (testy, yhat))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2687\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2664\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2642\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2619\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2597\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2575\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2554\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2532\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2510\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2489\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2468\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2447\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2426\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2405\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2344\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2324\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2303\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2284\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2264\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2244\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2225\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2205\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2186\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2148\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2129\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2111\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2092\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2074\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2055\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2037\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2019\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2001\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1983\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1966\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1948\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1931\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1913\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1896\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1879\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1862\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1845\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1829\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1812\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1796\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1779\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1763\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1747\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1730\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1715\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1699\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1683\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1652\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1636\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1621\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1605\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1590\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1575\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1545\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1530\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1501\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1486\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1472\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1458\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1443\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1429\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1415\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1401\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1387\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1373\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1360\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1346\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1332\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1319\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1292\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1279\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1266\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1253\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1240\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1227\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1215\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1202\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1189\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1177\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1164\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1152\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1140\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1128\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1116\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1104\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1092\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1080\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1069\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1057\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1046\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1035\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1001\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0990\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0979\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0969\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0958\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0948\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0937\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0927\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0917\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0906\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0896\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0887\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0877\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0867\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0857\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0848\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0839\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0829\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0820\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0811\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0802\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0785\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0776\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0768\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0759\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0751\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0735\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0727\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0719\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0711\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0704\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0696\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0689\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0682\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0668\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0661\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0654\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0647\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0641\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0634\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0628\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0622\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0616\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0610\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0604\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0598\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0592\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0587\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0581\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0576\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0571\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0566\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0561\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0556\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0551\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0546\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0542\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0537\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0533\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0528\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0524\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0520\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0516\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0512\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0508\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0504\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0501\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0497\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0494\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0490\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0487\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0484\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0481\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0478\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0475\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0472\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0469\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0466\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0464\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0461\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0458\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0456\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0453\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0451\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0449\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0444\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0442\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0436\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0434\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0427\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0426\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0424\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0422\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0421\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0419\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0418\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0416\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0415\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0414\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0412\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0411\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0408\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0407\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0406\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0405\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0403\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0402\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0401\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0400\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0399\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0398\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0397\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0396\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0395\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0394\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0393\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0392\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0391\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0390\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0389\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0388\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0387\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0386\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0385\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0383\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0382\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0381\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0380\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0380\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0378\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0377\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0376\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0375\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0374\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0373\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0373\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0372\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0371\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0370\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0369\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0367\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0367\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0366\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0365\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0363\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0362\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0361\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0361\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0360\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0359\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0358\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0357\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0356\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0355\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0355\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0354\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0353\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0352\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0351\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0350\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0349\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0349\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0348\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0347\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0346\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0343\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0342\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0341\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0340\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0339\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0338\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0337\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0337\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0336\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0334\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0332\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0331\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0331\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0329\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0328\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0327\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0326\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0324\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0324\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0322\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0320\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0319\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0318\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0317\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0316\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0316\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0315\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0314\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0313\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0312\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0310\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0309\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0309\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0308\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0307\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0304\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0303\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0302\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0300\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0299\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0298\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0297\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0296\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0295\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0294\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0293\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0292\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0291\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0290\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0289\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0288\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0287\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0285\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0284\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0283\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0282\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0279\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0278\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0275\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0274\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0273\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0272\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0270\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0269\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0269\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0268\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0266\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0265\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0264\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0263\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0261\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0260\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0259\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0258\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0257\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0256\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0256\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0255\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0254\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0253\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0252\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0251\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0249\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0248\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0247\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0246\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0245\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0244\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0243\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0242\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0241\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0240\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0240\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0239\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0238\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0237\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0236\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0234\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0233\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0232\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0230\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0228\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0227\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0226\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0225\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0224\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0223\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0221\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0220\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0219\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0218\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0217\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0216\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0215\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0214\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0213\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0212\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0210\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0209\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0208\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0207\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0205\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0204\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0203\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0202\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0201\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0201\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0199\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0196\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0195\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0194\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0193\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0192\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0190\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0189\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0188\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0187\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0183\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0175\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0174\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0173\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0171\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0170\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0169\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0168\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0166\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0164\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0163\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0162\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0161\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0160\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0159\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0158\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0158\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0156\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0155\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0154\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0153\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0152\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0151\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0149\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0148\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0147\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0146\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0145\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0144\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0142\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0142\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0141\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0140\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0138\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0137\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0136\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0135\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0134\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0133\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0132\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0131\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0130\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0129\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0129\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0128\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0127\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0125\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0124\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0123\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0122\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0121\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0120\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0119\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0119\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0118\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0117\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0111\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0110\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0109\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0108\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0107\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0106\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0101\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0099\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0097\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0096\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0095\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0093\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0092\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0092\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0091\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0090\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0088\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0088\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0074\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0067\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0061\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0057\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0057\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0056\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0055\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0054\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0049\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0044\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0039\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0039\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0034\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0026\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9237e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7416e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5627e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3869e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2143e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0448e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8784e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7150e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5546e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3971e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2426e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0909e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9421e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7961e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6528e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5123e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3746e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2394e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1069e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9770e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8496e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7248e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6025e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4825e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3650e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2499e-04\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1371e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0267e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9185e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8125e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7087e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6071e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5077e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4103e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3150e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2217e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1305e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0412e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9538e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8683e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7847e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7030e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6230e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5448e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4684e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3936e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3206e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2492e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1794e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1112e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0446e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9795e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9159e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8538e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7931e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7339e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6760e-04\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6196e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5644e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5106e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4580e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4067e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3567e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3079e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2602e-04\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2137e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1684e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1242e-04\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.0810e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0389e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9979e-04\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9579e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9189e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8809e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8438e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8077e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7725e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7382e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7048e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6722e-04\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6405e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6095e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5794e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5501e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5215e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4937e-04\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4666e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4403e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4146e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3896e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3652e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3416e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3185e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2961e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2742e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2530e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2323e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2122e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1926e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1736e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1551e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1371e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1196e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1025e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0860e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0699e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0542e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0390e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0242e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0098e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9958e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9822e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9690e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9561e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9436e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9315e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9197e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9082e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8971e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8863e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8758e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8655e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8556e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8460e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8366e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8275e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8187e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8101e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8017e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7936e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7857e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7781e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7707e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7634e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7564e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7496e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7430e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7366e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7304e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7243e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7184e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7127e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7071e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7018e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6965e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6914e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6865e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6817e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6770e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6725e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6681e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6638e-04\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6597e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6556e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6517e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6479e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6442e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6406e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6371e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6337e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6304e-04\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6272e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6240e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6210e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6180e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6152e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6124e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6096e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6070e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6044e-04\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6019e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5995e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5971e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5948e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5926e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5904e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5882e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5862e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5841e-04\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5822e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5802e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5784e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5765e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5748e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5730e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5713e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5697e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5681e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5665e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5650e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5634e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5620e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5606e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5591e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5578e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5564e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5551e-04\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5539e-04\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5526e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5514e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5502e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5490e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5479e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5467e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5456e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5445e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5435e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5424e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5414e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5404e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5394e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5384e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5375e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5365e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5356e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5347e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5338e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5330e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5321e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5312e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5304e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5296e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5288e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5280e-04\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5272e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5264e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5256e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5249e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5241e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5234e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5226e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5219e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5212e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5205e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5198e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5191e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5184e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5178e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5171e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5164e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5158e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5151e-04\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5145e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5138e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5132e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5125e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5119e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5113e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5107e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5101e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5095e-04\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5088e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5082e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5077e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5071e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5065e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5059e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5053e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5047e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5041e-04\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5036e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5030e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5024e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5018e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5013e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5007e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5002e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4996e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4990e-04\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4985e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4979e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4974e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4968e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4963e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4957e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4952e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4947e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4941e-04\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4936e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4930e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4925e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4920e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4914e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-f99880533b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>Expected=%.1f, Predicted=%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_8: expected shape=(9, None, 1), found shape=[1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Ul9LOTRmcz"
      },
      "source": [
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGQmADUHcuzG"
      },
      "source": [
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Ris9n7UXcz4O",
        "outputId": "b902765f-1dc3-49f3-d7e1-9843b6baeb6c"
      },
      "source": [
        "sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ePuSonc1Xs"
      },
      "source": [
        "df = DataFrame(sequence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "b8trZkkPc_UR",
        "outputId": "11ae92bb-98f9-4700-f2ca-7513d05153ca"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0  0.0\n",
              "1  0.1\n",
              "2  0.2\n",
              "3  0.3\n",
              "4  0.4\n",
              "5  0.5\n",
              "6  0.6\n",
              "7  0.7\n",
              "8  0.8\n",
              "9  0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOyHuOjHdAOC"
      },
      "source": [
        "df = concat([df, df.shift(1)], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "v16Z9B6LdCyQ",
        "outputId": "27c06433-e03d-4bb2-84d1-4b2b9f7ad20f"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    0\n",
              "0  0.0  NaN\n",
              "1  0.1  0.0\n",
              "2  0.2  0.1\n",
              "3  0.3  0.2\n",
              "4  0.4  0.3\n",
              "5  0.5  0.4\n",
              "6  0.6  0.5\n",
              "7  0.7  0.6\n",
              "8  0.8  0.7\n",
              "9  0.9  0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlmTl1vydEJv"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "IrJaoBJRdHP4",
        "outputId": "e9f7803b-f49c-486c-8f8a-d6dd5ead2bae"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    0\n",
              "1  0.1  0.0\n",
              "2  0.2  0.1\n",
              "3  0.3  0.2\n",
              "4  0.4  0.3\n",
              "5  0.5  0.4\n",
              "6  0.6  0.5\n",
              "7  0.7  0.6\n",
              "8  0.8  0.7\n",
              "9  0.9  0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSzPLey9dImB"
      },
      "source": [
        "values = df.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "8oSlHgbWdRuX",
        "outputId": "2cc2a3ba-c6d0-45a4-ceb1-61ba5460a388"
      },
      "source": [
        "values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1, 0. ],\n",
              "       [0.2, 0.1],\n",
              "       [0.3, 0.2],\n",
              "       [0.4, 0.3],\n",
              "       [0.5, 0.4],\n",
              "       [0.6, 0.5],\n",
              "       [0.7, 0.6],\n",
              "       [0.8, 0.7],\n",
              "       [0.9, 0.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUTAt3mDdSzr"
      },
      "source": [
        "X, y = values[:, 0], values[:, 1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uEJHMZx-dWko",
        "outputId": "9c59d796-2110-48b7-9b6f-2e41fd162e56"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wfoTLXApdZPS",
        "outputId": "146f4d19-e88b-449b-b81d-b1a7b384b866"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XYDAn3vedbDX",
        "outputId": "6677ca97-1a22-4202-d853-480baf3a8438"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8p1DIL8BdevU",
        "outputId": "c1b314f7-6dd8-4e28-eee8-54316ab709a7"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MB51f00dgdA"
      },
      "source": [
        "X = X.reshape(len(X), 1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "GYxvS3Nkdhvd",
        "outputId": "3631b638-9176-42eb-965d-6452f16d4c71"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1]],\n",
              "\n",
              "       [[0.2]],\n",
              "\n",
              "       [[0.3]],\n",
              "\n",
              "       [[0.4]],\n",
              "\n",
              "       [[0.5]],\n",
              "\n",
              "       [[0.6]],\n",
              "\n",
              "       [[0.7]],\n",
              "\n",
              "       [[0.8]],\n",
              "\n",
              "       [[0.9]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYfvU5ndi-8"
      },
      "source": [
        "n_batch = len(X)\n",
        "n_epoch = 1000\n",
        "n_neurons = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8DvVK2edsZr"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FYYUHQv3d3uq",
        "outputId": "3e4d6be2-f455-46ff-b86c-c95a53c81957"
      },
      "source": [
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2269\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2245\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2198\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2175\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2152\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2129\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2106\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2083\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2061\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2039\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1995\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1973\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1952\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1930\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1909\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1888\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1867\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1846\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1826\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1785\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1765\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1745\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1725\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1705\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1686\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1667\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1647\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1628\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1610\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1591\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1572\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1554\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1536\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1518\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1482\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1465\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1447\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1430\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1413\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1396\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1363\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1346\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1314\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1297\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1282\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1266\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1220\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1205\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1190\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1175\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1160\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1146\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1131\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1117\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1103\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1089\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1075\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1062\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1048\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1009\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0996\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0983\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0970\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0958\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0946\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0933\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0910\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0898\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0886\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0875\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0864\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0853\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0842\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0831\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0820\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0810\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0799\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0789\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0779\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0769\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0759\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0750\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0740\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0731\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0722\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0713\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0704\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0695\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0686\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0678\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0669\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0661\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0653\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0645\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0637\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0630\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0622\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0615\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0600\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0593\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0587\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0580\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0573\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0567\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0560\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0554\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0548\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0542\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0536\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0531\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0525\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0520\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0514\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0509\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0504\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0499\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0494\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0490\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0485\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0480\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0476\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0472\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0467\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0459\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0455\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0452\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0448\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0444\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0441\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0437\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0434\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0427\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0424\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0421\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0418\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0415\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0413\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0407\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0405\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0402\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0400\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0397\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0395\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0393\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0391\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0389\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0386\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0384\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0382\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0381\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0379\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0377\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0375\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0373\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0372\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0370\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0367\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0365\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0364\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0362\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0361\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0360\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0358\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0357\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0356\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0354\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0353\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0352\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0351\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0349\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0348\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0347\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0346\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0345\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0343\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0342\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0341\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0340\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0339\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0338\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0337\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0336\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0335\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0334\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0332\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0331\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0330\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0329\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0328\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0327\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0326\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0325\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0324\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0324\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0323\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0322\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0321\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0320\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0319\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0318\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0317\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0317\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0316\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0315\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0314\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0313\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0312\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0310\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0308\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0307\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0306\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0304\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0303\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0302\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0301\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0299\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0298\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0297\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0296\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0295\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0294\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0294\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0293\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0292\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0291\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0290\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0289\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0289\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0288\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0287\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0286\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0285\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0284\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0283\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0283\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0282\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0281\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0280\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0279\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0278\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0277\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0276\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0275\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0274\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0273\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0272\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0271\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0270\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0270\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0269\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0268\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0267\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0266\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0265\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0264\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0264\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0263\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0262\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0261\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0260\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0259\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0258\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0257\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0257\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0256\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0255\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0254\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0253\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0252\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0251\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0250\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0249\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0248\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0247\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0246\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0245\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0244\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0243\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0243\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0242\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0241\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0240\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0239\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0238\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0237\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0236\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0236\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0235\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0234\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0233\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0232\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0231\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0230\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0228\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0228\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0227\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0226\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0225\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0224\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0223\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0222\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0221\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0221\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0220\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0219\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0218\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0217\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0216\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0215\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0214\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0213\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0213\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0212\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0211\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0210\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0209\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0208\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0207\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0205\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0204\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0203\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0202\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0201\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0199\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0196\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0195\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0194\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0193\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0192\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0191\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0191\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0190\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0189\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0188\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0187\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0186\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0185\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0183\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0182\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0181\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0180\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0176\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0175\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0174\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0173\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0171\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0170\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0169\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0168\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0166\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0164\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0163\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0162\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0161\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0160\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0160\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0159\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0158\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0157\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0156\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0155\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0154\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0154\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0153\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0152\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0151\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0150\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0149\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0149\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0148\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0147\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0146\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0145\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0144\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0144\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0142\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0141\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0140\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0138\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0137\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0136\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0135\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0135\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0134\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0133\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0132\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0131\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0131\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0130\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0129\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0128\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0127\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0127\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0126\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0125\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0124\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0123\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0123\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0122\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0120\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0119\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0119\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0118\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0117\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0116\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0115\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0114\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0113\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0112\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0111\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0110\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0110\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0109\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0108\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0107\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0107\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0106\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0103\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0102\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0101\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0099\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0097\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0096\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0096\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0095\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0093\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0093\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0092\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0091\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0091\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0090\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0088\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0084\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0081\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0072\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0070\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0067\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0062\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0062\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0061\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0059\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0058\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0057\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0057\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0056\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0056\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0053\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0051\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0051\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0049\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0048\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0047\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0046\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0045\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0043\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0042\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0040\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0039\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0039\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0038\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0032\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0026\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9459e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8002e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6563e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5143e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.3741e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2358e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0993e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9645e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8316e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7004e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5710e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4433e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3173e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1931e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0705e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9496e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8303e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7126e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5966e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4822e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3694e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2581e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1484e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0402e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9336e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8285e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7248e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6226e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5219e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4227e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3248e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2284e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1334e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0397e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9474e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8565e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7669e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6786e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5917e-04\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5060e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4216e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3385e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2566e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1759e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0965e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0183e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9412e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8654e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7907e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7171e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6447e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5734e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5032e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4341e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3661e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2992e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2333e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1684e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1046e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0417e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9799e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9191e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8592e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8003e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7424e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6854e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6293e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5741e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5198e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4664e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4139e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3623e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3115e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2615e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2124e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1641e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1166e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0699e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0239e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9788e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9344e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8908e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8479e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8057e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7642e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7235e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6835e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6441e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6054e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5674e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5301e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4934e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4574e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4219e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3871e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3529e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3193e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2864e-04\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.2539e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2221e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1908e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1601e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1300e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1003e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0712e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0427e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0146e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9871e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9600e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9335e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9074e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8818e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8567e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8320e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8078e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7841e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7607e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7378e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7154e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6933e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6717e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6504e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6296e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6092e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5891e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5694e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5501e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5311e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5126e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4943e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4764e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4589e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4417e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4248e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4082e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3920e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3761e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3604e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3451e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3301e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3154e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3009e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2868e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2729e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2593e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2459e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2328e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2200e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2074e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1951e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1830e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1711e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1595e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1481e-04\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1370e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1261e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1153e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1048e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0945e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0845e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0746e-04\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0649e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0554e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0461e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0370e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0281e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0193e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0108e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0024e-04\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9413e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8607e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7818e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7045e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6288e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5546e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4819e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4107e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3410e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2728e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2059e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1404e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0762e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0134e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9519e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8917e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8326e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.7749e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7183e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6629e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6086e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5555e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5035e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4526e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4027e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3539e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3060e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2592e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2134e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1685e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1246e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0816e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0395e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9983e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9579e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9184e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8797e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8418e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8048e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7685e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7329e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6982e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6641e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6308e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5982e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5662e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5349e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5043e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4744e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4450e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4163e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3882e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3607e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3338e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3074e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2816e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2563e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2316e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2073e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1836e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1604e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1377e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1154e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0936e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0723e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0514e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0310e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0109e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9914e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9722e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9534e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9350e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9169e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8993e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8820e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8651e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8485e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8323e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8164e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8008e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7856e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7706e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7560e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7417e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7276e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7138e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7003e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6872e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6742e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6615e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6491e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6369e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6250e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6133e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6018e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5906e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5795e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5687e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5581e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5477e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5376e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5276e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5178e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5082e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4987e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4895e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4804e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4715e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4628e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4542e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4458e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4376e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4295e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4215e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4137e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4060e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3985e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3911e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3838e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3767e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3697e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3628e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3561e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3494e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3429e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3365e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3301e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3239e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3178e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3118e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3059e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3001e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2944e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2887e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2832e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2777e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2724e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2671e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2619e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2568e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2517e-05\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2467e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2419e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2370e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2323e-05\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2276e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "AOsHyl_Md8g_",
        "outputId": "a68ca941-11fc-4f09-d44c-10fd8dc6ee50"
      },
      "source": [
        "for i in range(len(X)):\n",
        "\ttestX, testy = X[i], y[i]\n",
        "\ttestX = testX.reshape(1, 1, 1)\n",
        "\tyhat = model.predict(testX, batch_size=1)\n",
        "\tprint('>Expected=%.1f, Predicted=%.1f' % (testy, yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-a87b815894d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>Expected=%.1f, Predicted=%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_10: expected shape=(9, None, 1), found shape=[1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "neO5M0HBesh6",
        "outputId": "152fd6fd-8308-4793-b326-147b48e71083"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jO0qEpxev-d"
      },
      "source": [
        "##############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTw5gAfWJen8"
      },
      "source": [
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tP5O8LmIfQ2"
      },
      "source": [
        "from numpy import array\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhPWNFV0IfOJ"
      },
      "source": [
        "data = data.reshape((1, 10, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VUndaKzIfLX"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(10, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hKoPJSEIfIy"
      },
      "source": [
        "from numpy import array\n",
        "data = array([\n",
        "[0.1, 1.0],\n",
        "[0.2, 0.9],\n",
        "[0.3, 0.8],\n",
        "[0.4, 0.7],\n",
        "[0.5, 0.6],\n",
        "[0.6, 0.5],\n",
        "[0.7, 0.4],\n",
        "[0.8, 0.3],\n",
        "[0.9, 0.2],\n",
        "[1.0, 0.1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqrfWqk6IfGI"
      },
      "source": [
        "data = data.reshape(1, 10, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsQhxwy4IfDr"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(10, 2)))\n",
        "#4()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "pG5FV799IfBg",
        "outputId": "04a892fd-ce5a-42b6-ab84-11dc3551f2a6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                4480      \n",
            "=================================================================\n",
            "Total params: 4,480\n",
            "Trainable params: 4,480\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "R6hiYLFiIe_t",
        "outputId": "ace7e4a2-77bf-42a0-b5de-49b2eafa8a69"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "# generate a sequence of random numbers in [0, n_features)\n",
        "def generate_sequence(length, n_features):\n",
        "  return [randint(0, n_features-1) for _ in range(length)]\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_features):\n",
        "  encoding = list()\n",
        "  for value in sequence:\n",
        "    vector = [0 for _ in range(n_features)]\n",
        "    vector[value] = 1\n",
        "    encoding.append(vector)\n",
        "    return array(encoding)\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "  return [argmax(vector) for vector in encoded_seq]\n",
        "# generate random sequence\n",
        "sequence = generate_sequence(25, 100)\n",
        "print(sequence)\n",
        "# one hot encode\n",
        "encoded = one_hot_encode(sequence, 100)\n",
        "print(encoded)\n",
        "# one hot decode\n",
        "decoded = one_hot_decode(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[66, 21, 10, 23, 38, 55, 2, 63, 41, 77, 72, 91, 18, 41, 39, 75, 33, 56, 16, 25, 58, 22, 39, 96, 69]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[66]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOf2LxbtIe9S"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91jTLZVpIe5v"
      },
      "source": [
        "def generate_sequence(length, n_features):\n",
        "  return [randint(0, n_features-1) for _ in range(length)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_WUhGSu2PYh0",
        "outputId": "fc376d30-1c9e-49b7-8d1c-9cade7b3cf1a"
      },
      "source": [
        "sequence = generate_sequence(25, 100)\n",
        "print(sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[76, 91, 89, 40, 99, 25, 30, 94, 91, 60, 38, 91, 47, 52, 58, 0, 43, 93, 26, 85, 33, 14, 80, 44, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEA7UiePeeg"
      },
      "source": [
        "def one_hot_encode(sequence, n_features):\n",
        "  encoding = list()\n",
        "  for value in sequence:\n",
        "    vector = [0 for _ in range(n_features)]\n",
        "    vector[value] = 1\n",
        "    encoding.append(vector)\n",
        "  return array(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "WvnboMnuPtcN",
        "outputId": "b44b90f4-c7ba-4c1d-935a-5588a9cdfbb1"
      },
      "source": [
        "encoded = one_hot_encode(sequence, 100)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "buGOzw5OPtsm",
        "outputId": "26d6dea8-6c68-4155-9043-9e761fd44c08"
      },
      "source": [
        "def one_hot_decode(encoded_seq):\n",
        "  return [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "\n",
        "decoded = one_hot_decode(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[76, 91, 89, 40, 99, 25, 30, 94, 91, 60, 38, 91, 47, 52, 58, 0, 43, 93, 26, 85, 33, 14, 80, 44, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "3juk8KcyQWm6",
        "outputId": "904bb001-e596-45ad-af16-f91d04ed65d5"
      },
      "source": [
        "\n",
        "# generate a sequence of random numbers in [0, n_features)\n",
        "def generate_sequence(length, n_features):\n",
        "  return [randint(0, n_features-1) for _ in range(length)]\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_features):\n",
        "  encoding = list()\n",
        "  for value in sequence:\n",
        "    vector = [0 for _ in range(n_features)]\n",
        "    vector[value] = 1\n",
        "    encoding.append(vector)\n",
        "  return array(encoding)\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "  return [argmax(vector) for vector in encoded_seq]\n",
        "# generate one example for an lstm\n",
        "def generate_example(length, n_features, out_index):\n",
        "# generate sequence\n",
        "  sequence = generate_sequence(length, n_features)\n",
        "# one hot encode\n",
        "  encoded = one_hot_encode(sequence, n_features)\n",
        "# reshape sequence to be 3D\n",
        "  X = encoded.reshape((1, length, n_features))\n",
        "# select output\n",
        "  y = encoded[out_index].reshape(1, n_features)\n",
        "  return X, y\n",
        "X, y = generate_example(25, 100, 2)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 25, 100)\n",
            "(1, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "zzGSuMWCQbM7",
        "outputId": "4e25bee1-1e21-4ad4-c564-5ea5ac955009"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "ExHzXeZqQlUh",
        "outputId": "08ca503d-9823-4eb4-a147-274a744d3384"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "GIeaJoiOQlcj",
        "outputId": "cdf8f10f-e5d6-4a16-8ccc-0dc744a06f54"
      },
      "source": [
        "from keras.layers.advanced_activations import Softmax\n",
        "from scipy.special import softmax\n",
        "length = 5\n",
        "n_features = 10\n",
        "out_index = 2\n",
        "model = Sequential()\n",
        "model.add(LSTM(25, input_shape=(length, n_features)))\n",
        "model.add(Dense(10, activation= 'softmax'))\n",
        "model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'acc' ])\n",
        "print(model.summary())\n",
        "\n",
        "#lstm (4(10*25+25*25+25))\n",
        "#dense(25*15+15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, 25)                3600      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 3,860\n",
            "Trainable params: 3,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1EPA80Qln4"
      },
      "source": [
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OFGjfa0aWSB"
      },
      "source": [
        "#######################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4AaVtr6aqFK"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=500)\n",
        "y=np.random.randint(2, size=25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "9Ct6LBH1gqQt",
        "outputId": "62e3d104-5612-4d7b-ff75-33966d3d1f41"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "wpHE3Nb4gu1r",
        "outputId": "cdc5810e-b01c-47d5-f071-7279008de479"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6rhDncKhuC-"
      },
      "source": [
        "X=np.array(X).reshape(25,10,2)\n",
        "#2 input neurons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsvlQOwSsL5q",
        "outputId": "7146a6cd-71a6-4e2d-e436-1b4182581c7c"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBrkQcsXhuxN"
      },
      "source": [
        "y=np.array(y).reshape(25,1)\n",
        "#3 output neurons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "ABt7OMCjsZ-u",
        "outputId": "c20bbc40-5b7d-4a08-fdc3-9109767ff204"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xd14YLF5gwI0",
        "outputId": "5e32a44b-536d-4d4d-f349-d542b5e72c69"
      },
      "source": [
        "from keras.layers.advanced_activations import Softmax\n",
        "from scipy.special import softmax\n",
        "length = 10\n",
        "n_features = 2\n",
        "out_index = 2\n",
        "model = Sequential()\n",
        "model.add(LSTM(20, input_shape=(length, n_features)))\n",
        "model.add(Dense(1, activation= 'softmax'))\n",
        "model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'acc' ])\n",
        "print(model.summary())\n",
        "\n",
        "#lstm (4(2*20+20*20+20))\n",
        "#dense(25*3+3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_22 (LSTM)               (None, 20)                1840      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,861\n",
            "Trainable params: 1,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkBLKAahXQ7"
      },
      "source": [
        "history = model.fit(X, y, epochs=10, batch_size=len(X), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_FYT20WHhrP1",
        "outputId": "97f857ed-bd9c-44dd-8c3b-8d33438bd624"
      },
      "source": [
        "history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe158459f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "b9jdzygVjaHO",
        "outputId": "cf1ff52b-3b6f-4b2d-bfc0-5035c4be0214"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZdxL-ZTjzy6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oZohiSZkD4i"
      },
      "source": [
        "history = model.fit(X, y, batch_size=10, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "eKxagliRkNJi",
        "outputId": "b05667bf-d58d-43cf-d2d7-778caf42a9e0"
      },
      "source": [
        "loss, accuracy = model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe1577e7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 0.5200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "XtQri8NekO_n",
        "outputId": "8e31445a-1598-46ad-91b2-b03e246956af"
      },
      "source": [
        "predictions = model.predict(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe156e4c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "LSVtmShGkXHc",
        "outputId": "04afb12c-e132-4a71-963c-3f2400dff636"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nmNdZGPSkZSY",
        "outputId": "0e5bd5bc-da29-4ad7-9a86-448c90966d07"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCTTKJr1kkMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHRvDARJk0QP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4LgH1XQiNGp"
      },
      "source": [
        "###############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VR2JqGciNCl"
      },
      "source": [
        "from keras.preprocessing.text import one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXGLE_tJiM-j"
      },
      "source": [
        "docs=['glass of orange juice','bottle of mango juice','glass of mango shake','drink bottle of banana shake','i want a glass of cold water','The king and the queen','man and women']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcZY6pSBizD2"
      },
      "source": [
        "vocab_size=10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgxF435zi3Ak"
      },
      "source": [
        "encoded_docs=[one_hot(d,vocab_size) for d in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "uOTQV4oMjIJQ",
        "outputId": "6b7b9545-e25e-4bcb-ac85-aac074b3eb2a"
      },
      "source": [
        "encoded_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[683, 4701, 1298, 838],\n",
              " [3338, 4701, 1361, 838],\n",
              " [683, 4701, 1361, 3023],\n",
              " [2727, 3338, 4701, 1278, 3023],\n",
              " [6659, 6904, 7952, 683, 4701, 6779, 6493],\n",
              " [2085, 2755, 9471, 2085, 6138],\n",
              " [153, 9471, 6566]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1dpNd6jKkd"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxjN0WMwnNb1"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqZCwJNinTDM"
      },
      "source": [
        "from keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvWtMbhKnYTv"
      },
      "source": [
        "embedding_length=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIZA0s2unfrv"
      },
      "source": [
        "max_docs_len=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGtYVFcUnjzj"
      },
      "source": [
        "encoded_docs=pad_sequences(encoded_docs,truncating='post',padding='post',maxlen=max_docs_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "Oo3iKkgrn380",
        "outputId": "9775d8fc-ea59-4431-dff9-9ae58a514e8d"
      },
      "source": [
        "encoded_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 683, 4701, 1298,  838,    0,    0,    0,    0,    0,    0],\n",
              "       [3338, 4701, 1361,  838,    0,    0,    0,    0,    0,    0],\n",
              "       [ 683, 4701, 1361, 3023,    0,    0,    0,    0,    0,    0],\n",
              "       [2727, 3338, 4701, 1278, 3023,    0,    0,    0,    0,    0],\n",
              "       [6659, 6904, 7952,  683, 4701, 6779, 6493,    0,    0,    0],\n",
              "       [2085, 2755, 9471, 2085, 6138,    0,    0,    0,    0,    0],\n",
              "       [ 153, 9471, 6566,    0,    0,    0,    0,    0,    0,    0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt2BhfWdn9sq"
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxXxYb5SoXSs"
      },
      "source": [
        "\n",
        "model.add(Embedding(vocab_size,embedding_length,input_length=max_docs_len))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InMsIYMCozK7"
      },
      "source": [
        "model.compile('rmsprop','mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "OMQV2SGao9Ae",
        "outputId": "110a627d-04e5-4bda-a4e1-b7986048631a"
      },
      "source": [
        "output=model.predict(encoded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe159f77048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "i2RZVUe0pBHW",
        "outputId": "d9bde578-cdb2-4751-9f41-77c5d8c15b7c"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rqS7K26DpKfp",
        "outputId": "f3af305f-d922-407f-ccdc-8c658cfb0a0d"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.0441073 ,  0.03862188, -0.00321233,  0.04968374,\n",
              "          0.03313437],\n",
              "        [-0.04661738, -0.0481696 ,  0.02401793, -0.02968941,\n",
              "         -0.04511514],\n",
              "        [-0.00954548,  0.00362203, -0.02925272, -0.01872332,\n",
              "         -0.01459451],\n",
              "        [ 0.04968783,  0.01462314, -0.00791341,  0.00965519,\n",
              "         -0.0247534 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.04855837, -0.01124521, -0.02798055,  0.01190684,\n",
              "         -0.00679295],\n",
              "        [-0.04661738, -0.0481696 ,  0.02401793, -0.02968941,\n",
              "         -0.04511514],\n",
              "        [ 0.00764688, -0.04434595, -0.01953489, -0.01306565,\n",
              "         -0.02781837],\n",
              "        [ 0.04968783,  0.01462314, -0.00791341,  0.00965519,\n",
              "         -0.0247534 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.0441073 ,  0.03862188, -0.00321233,  0.04968374,\n",
              "          0.03313437],\n",
              "        [-0.04661738, -0.0481696 ,  0.02401793, -0.02968941,\n",
              "         -0.04511514],\n",
              "        [ 0.00764688, -0.04434595, -0.01953489, -0.01306565,\n",
              "         -0.02781837],\n",
              "        [-0.00980813, -0.03072124, -0.03307163,  0.03310077,\n",
              "          0.03780151],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.04478525,  0.0002969 ,  0.00196534,  0.03044431,\n",
              "          0.00272601],\n",
              "        [-0.04855837, -0.01124521, -0.02798055,  0.01190684,\n",
              "         -0.00679295],\n",
              "        [-0.04661738, -0.0481696 ,  0.02401793, -0.02968941,\n",
              "         -0.04511514],\n",
              "        [-0.00880856,  0.03878922,  0.0068601 ,  0.00787   ,\n",
              "          0.02867338],\n",
              "        [-0.00980813, -0.03072124, -0.03307163,  0.03310077,\n",
              "          0.03780151],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.03806193, -0.01526773,  0.01965857, -0.02004794,\n",
              "         -0.03551872],\n",
              "        [ 0.02296864, -0.00524652, -0.00551019, -0.02726573,\n",
              "          0.04710463],\n",
              "        [ 0.02182626,  0.0311203 ,  0.03157741,  0.02230212,\n",
              "         -0.04192038],\n",
              "        [-0.0441073 ,  0.03862188, -0.00321233,  0.04968374,\n",
              "          0.03313437],\n",
              "        [-0.04661738, -0.0481696 ,  0.02401793, -0.02968941,\n",
              "         -0.04511514],\n",
              "        [-0.01526766,  0.01259495, -0.0423122 ,  0.00932379,\n",
              "          0.0039385 ],\n",
              "        [ 0.01897037,  0.01032267,  0.03897608, -0.00351236,\n",
              "          0.04625882],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.0175414 ,  0.01796936, -0.04392719, -0.02538062,\n",
              "         -0.01295881],\n",
              "        [ 0.0392963 , -0.047026  ,  0.00074371, -0.03934816,\n",
              "          0.00482512],\n",
              "        [ 0.03462822, -0.04113351,  0.02025371,  0.00624792,\n",
              "         -0.01131369],\n",
              "        [-0.0175414 ,  0.01796936, -0.04392719, -0.02538062,\n",
              "         -0.01295881],\n",
              "        [-0.04953586, -0.0469386 , -0.02724112, -0.01482675,\n",
              "         -0.03320382],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]],\n",
              "\n",
              "       [[-0.0394276 , -0.01764892,  0.00189599,  0.03919305,\n",
              "          0.03954676],\n",
              "        [ 0.03462822, -0.04113351,  0.02025371,  0.00624792,\n",
              "         -0.01131369],\n",
              "        [-0.01803702,  0.02364793, -0.04991857,  0.02849277,\n",
              "          0.02130871],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ],\n",
              "        [-0.01494135,  0.01338536, -0.0421615 , -0.01117799,\n",
              "          0.0057473 ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Rwk-i_pV-X"
      },
      "source": [
        "model.add(LSTM(units=64))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPkSQgEGrRS3"
      },
      "source": [
        "model.compile('rmsprop','mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "HdWGF8SjrRQC",
        "outputId": "393c0b11-6da9-4da9-d7c6-ea465444e3a7"
      },
      "source": [
        "model.summary()\n",
        "\n",
        "#4(5*64+64*64+64)=17920"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 5)             50000     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                17920     \n",
            "=================================================================\n",
            "Total params: 67,920\n",
            "Trainable params: 67,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn66fIIprRMx"
      },
      "source": [
        "output=model.predict(encoded_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TlOypGC6rRJr",
        "outputId": "a3f3e07c-f3d3-410d-e288-628fa0faaeec"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pUsNaYugA4p8",
        "outputId": "2a244c3b-609a-46ce-f4ae-71b68f1c0933"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.9207862e-03, -8.0984517e-04,  7.5953975e-03, -4.5784647e-03,\n",
              "        -1.5796055e-03,  1.2489103e-03,  3.0406229e-03, -3.1782957e-03,\n",
              "        -3.1877758e-03, -3.7067060e-03, -5.3060339e-03,  3.2515714e-03,\n",
              "         5.3879595e-03,  7.8320811e-03,  7.5604450e-03, -2.5646121e-03,\n",
              "         1.7636532e-03,  5.2836145e-05, -8.8420010e-04, -3.6776795e-03,\n",
              "        -2.2609290e-03, -1.7713361e-03, -1.5853029e-03,  1.8372298e-03,\n",
              "         4.7827960e-04, -5.2038841e-03, -4.2644762e-03, -6.7495517e-03,\n",
              "        -2.6669251e-03,  1.4559051e-04,  1.9643679e-03,  2.7736574e-03,\n",
              "        -4.4825589e-03, -2.0366185e-03, -7.1737105e-03, -5.4075881e-03,\n",
              "        -7.5121755e-03,  3.8999980e-03,  4.0000762e-04,  9.3048322e-04,\n",
              "        -2.2967672e-03, -4.2312825e-04, -3.5352418e-03, -2.7681650e-03,\n",
              "        -4.2101736e-03, -2.5043646e-03,  3.9751199e-03, -2.7132393e-03,\n",
              "        -4.7520977e-03, -3.7604815e-03, -4.3525430e-03,  2.2912377e-03,\n",
              "        -6.4152852e-04,  2.5023001e-03, -2.7545649e-03, -3.4471194e-03,\n",
              "        -2.1859342e-03, -3.0582605e-03, -4.6507032e-03,  2.6425747e-03,\n",
              "         1.2776036e-03, -3.8221690e-03, -5.3799418e-03, -6.1787413e-03],\n",
              "       [ 5.1986934e-03, -9.0598298e-04,  7.1064951e-03, -4.2091440e-03,\n",
              "        -1.5009115e-03,  2.1751395e-04,  2.6475319e-03, -2.7835176e-03,\n",
              "        -2.5582439e-03, -2.4585081e-03, -4.7971923e-03,  3.3588586e-03,\n",
              "         5.5272118e-03,  7.3621534e-03,  7.1147648e-03, -2.5685304e-03,\n",
              "         1.0551671e-03,  3.7891223e-04, -1.0407508e-03, -3.5091005e-03,\n",
              "        -2.9607478e-03, -1.3190823e-03, -1.1958252e-03,  1.4719258e-03,\n",
              "         5.5685092e-04, -4.9174870e-03, -4.3027890e-03, -6.3201147e-03,\n",
              "        -2.7068416e-03,  1.6777702e-04,  1.1916613e-03,  2.8201139e-03,\n",
              "        -4.3034670e-03, -2.3740684e-03, -6.7661335e-03, -5.1020179e-03,\n",
              "        -7.8243418e-03,  3.6337522e-03,  2.3963611e-04,  8.9986681e-04,\n",
              "        -1.7732369e-03, -6.7594374e-04, -3.7102080e-03, -3.0687358e-03,\n",
              "        -4.0746853e-03, -2.4822531e-03,  4.0302658e-03, -2.4862860e-03,\n",
              "        -4.2725601e-03, -3.3092445e-03, -4.2676260e-03,  1.5857584e-03,\n",
              "        -3.7153234e-04,  2.2316948e-03, -2.6619832e-03, -3.3197219e-03,\n",
              "        -2.6309381e-03, -3.1495804e-03, -5.0790533e-03,  2.6971104e-03,\n",
              "         6.8726751e-04, -4.5419652e-03, -4.9433792e-03, -5.7563772e-03],\n",
              "       [ 4.9793068e-03, -9.2574273e-04,  7.5791711e-03, -4.1253865e-03,\n",
              "        -2.3483455e-03,  1.4428115e-03,  3.5032893e-03, -3.0596084e-03,\n",
              "        -3.6772182e-03, -3.1060087e-03, -6.0847574e-03,  3.9042635e-03,\n",
              "         5.6928894e-03,  7.9757720e-03,  7.2665322e-03, -1.6438764e-03,\n",
              "         2.3066897e-03,  4.5158919e-05, -4.7791420e-04, -3.4395135e-03,\n",
              "        -2.4105713e-03, -1.2124868e-04, -2.4284320e-03,  1.9905150e-03,\n",
              "         6.4434821e-04, -5.0835498e-03, -4.7533773e-03, -7.1344194e-03,\n",
              "        -2.4954916e-03, -2.7482474e-04,  1.6455108e-03,  2.9071192e-03,\n",
              "        -5.6770607e-03, -1.4443613e-03, -6.5502874e-03, -6.0084374e-03,\n",
              "        -7.3425705e-03,  4.2366595e-03,  8.9461007e-04,  2.5538920e-04,\n",
              "        -1.4343121e-03, -8.5336383e-04, -3.7919630e-03, -3.8766994e-03,\n",
              "        -4.0837987e-03, -2.3125599e-03,  4.1215741e-03, -2.0600706e-03,\n",
              "        -4.9658818e-03, -4.4823135e-03, -4.0213773e-03,  2.7475809e-03,\n",
              "        -5.4041529e-04,  1.9885628e-03, -2.1265608e-03, -2.8139458e-03,\n",
              "        -2.2121463e-03, -2.8561789e-03, -4.7738748e-03,  2.1889056e-03,\n",
              "         1.5510761e-03, -3.0406595e-03, -6.2932577e-03, -5.6225089e-03],\n",
              "       [ 4.4246619e-03, -8.6512178e-04,  7.7014822e-03, -4.4135167e-03,\n",
              "        -2.3393757e-03,  2.3362073e-03,  4.1369670e-03, -3.2477188e-03,\n",
              "        -3.9138300e-03, -3.7267366e-03, -6.7444425e-03,  3.8858356e-03,\n",
              "         4.8292172e-03,  7.5556636e-03,  6.9428082e-03, -5.2227383e-04,\n",
              "         2.8250266e-03, -2.0793208e-04,  7.0248025e-05, -3.6617725e-03,\n",
              "        -1.7318639e-03,  4.5887235e-05, -2.5018582e-03,  1.7738735e-03,\n",
              "         3.5728014e-04, -4.8070597e-03, -4.9255840e-03, -7.0617283e-03,\n",
              "        -2.4427969e-03, -4.9773960e-05,  2.3314401e-03,  2.5775770e-03,\n",
              "        -5.9601967e-03, -7.3255890e-04, -6.3318140e-03, -6.1482452e-03,\n",
              "        -6.3379575e-03,  4.4922628e-03,  1.4349198e-03,  3.2490940e-04,\n",
              "        -1.4680371e-03, -3.7601445e-04, -3.2532895e-03, -3.5569549e-03,\n",
              "        -3.8006164e-03, -2.4378137e-03,  3.7295832e-03, -1.6617302e-03,\n",
              "        -5.6527383e-03, -4.6725199e-03, -3.8989901e-03,  3.1869549e-03,\n",
              "        -9.8472682e-04,  2.1985434e-03, -1.5957210e-03, -3.0546491e-03,\n",
              "        -1.5512410e-03, -2.2309052e-03, -4.3524518e-03,  1.6749388e-03,\n",
              "         2.3616515e-03, -2.0897421e-03, -6.5765241e-03, -4.8128548e-03],\n",
              "       [ 2.7481962e-03, -4.8208112e-05,  5.6998786e-03, -3.0807126e-03,\n",
              "        -1.0518313e-03,  2.3425485e-03,  3.3197287e-03, -2.2904151e-03,\n",
              "        -2.3947246e-03, -3.0715752e-03, -4.9086860e-03,  2.0009035e-03,\n",
              "         2.1128869e-03,  5.1839733e-03,  4.8929648e-03,  3.4553310e-04,\n",
              "         1.9568466e-03, -2.6041281e-04,  2.9608389e-04, -2.9959755e-03,\n",
              "        -1.3788359e-04, -7.5038255e-04, -4.8278441e-04,  6.2081334e-04,\n",
              "        -2.6830420e-04, -3.1173904e-03, -3.0013814e-03, -4.7223722e-03,\n",
              "        -2.4102638e-03,  8.6405757e-04,  3.0353551e-03,  1.1769196e-03,\n",
              "        -4.0890318e-03,  6.5581512e-06, -5.2228384e-03, -4.2455662e-03,\n",
              "        -4.0831980e-03,  2.9750699e-03,  1.5461270e-03,  9.4894704e-04,\n",
              "        -1.0191345e-03,  5.4479227e-04, -1.0890500e-03, -1.6324987e-03,\n",
              "        -2.8945196e-03, -1.4892120e-03,  2.2413798e-03, -1.5819956e-03,\n",
              "        -4.9918285e-03, -3.0927511e-03, -2.4922732e-03,  2.0703198e-03,\n",
              "        -1.3938159e-03,  2.6303402e-03, -3.9002456e-04, -2.5007024e-03,\n",
              "        -3.8414268e-04, -1.1543834e-03, -3.5475425e-03,  1.1513268e-03,\n",
              "         2.9449968e-03, -1.8579459e-03, -4.6897172e-03, -3.2756007e-03],\n",
              "       [ 5.8132862e-03, -3.5658357e-04,  6.8514459e-03, -3.2377609e-03,\n",
              "        -1.5934613e-03,  1.8001116e-05,  2.7785753e-03, -2.8756727e-03,\n",
              "        -1.9679200e-03, -2.0390353e-03, -4.6697585e-03,  3.3710271e-03,\n",
              "         5.7827174e-03,  7.6582963e-03,  6.7192316e-03, -2.4392707e-03,\n",
              "         1.1264641e-03,  5.0789601e-04, -5.4433721e-04, -2.6341269e-03,\n",
              "        -2.9959870e-03, -5.2747404e-04, -1.4937914e-03,  1.1362510e-03,\n",
              "         4.6480101e-04, -4.5871227e-03, -3.9392048e-03, -6.7531099e-03,\n",
              "        -2.5932211e-03, -3.2063243e-05,  9.0956013e-04,  3.4023270e-03,\n",
              "        -4.0646060e-03, -2.1594788e-03, -6.7710355e-03, -5.2225213e-03,\n",
              "        -8.1461333e-03,  3.8652085e-03,  2.3878411e-05,  1.0201914e-03,\n",
              "        -1.4765773e-03, -8.6415670e-04, -3.7143650e-03, -3.9631515e-03,\n",
              "        -4.1555627e-03, -2.0194114e-03,  3.8551574e-03, -2.0772347e-03,\n",
              "        -3.9034614e-03, -3.7301278e-03, -4.0796865e-03,  1.3950223e-03,\n",
              "        -3.9588672e-04,  1.5688778e-03, -2.7097070e-03, -2.8032921e-03,\n",
              "        -3.0210856e-03, -3.1698588e-03, -5.2751955e-03,  3.0165918e-03,\n",
              "         4.7999865e-04, -4.2255502e-03, -5.1737865e-03, -6.1288900e-03],\n",
              "       [ 4.7901454e-03, -8.0611388e-04,  8.1243841e-03, -4.1569420e-03,\n",
              "        -2.3316520e-03,  1.8632371e-03,  3.1830855e-03, -3.2784464e-03,\n",
              "        -4.3463735e-03, -4.0114410e-03, -5.9264773e-03,  3.7783789e-03,\n",
              "         6.1050020e-03,  8.9386608e-03,  8.1746299e-03, -2.5837861e-03,\n",
              "         2.7219560e-03, -2.5493746e-05, -9.6245122e-04, -3.4440164e-03,\n",
              "        -1.8704821e-03, -6.4451597e-04, -2.6397114e-03,  2.7240645e-03,\n",
              "         6.8682194e-04, -5.5389157e-03, -4.2691757e-03, -7.4243345e-03,\n",
              "        -2.5774024e-03, -2.8063104e-04,  2.0487639e-03,  2.9250472e-03,\n",
              "        -5.9212106e-03, -1.6223447e-03, -7.2197039e-03, -6.3052061e-03,\n",
              "        -7.7395155e-03,  3.9783190e-03,  7.2976924e-04,  7.6642449e-05,\n",
              "        -1.9794786e-03, -8.6314260e-04, -4.0998007e-03, -3.6761807e-03,\n",
              "        -4.6247835e-03, -2.0819511e-03,  4.4102217e-03, -2.7943088e-03,\n",
              "        -5.0537465e-03, -4.7420422e-03, -4.1628149e-03,  3.2597187e-03,\n",
              "        -3.7505646e-04,  2.1750173e-03, -2.5343020e-03, -2.5555759e-03,\n",
              "        -2.2121109e-03, -3.3289678e-03, -4.5190114e-03,  2.3907321e-03,\n",
              "         1.7538532e-03, -2.9046228e-03, -6.7447694e-03, -6.8440405e-03]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoVCe1meBMkR"
      },
      "source": [
        "model.add(Dense(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "CKpvB4-XBai0",
        "outputId": "89d9ce7b-254e-46fc-8eb6-4dff52481f5e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 5)             50000     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                17920     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 4         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                30        \n",
            "=================================================================\n",
            "Total params: 68,019\n",
            "Trainable params: 68,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZLS8bYUBcgK"
      },
      "source": [
        "output=model.predict(encoded_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Ws8_zt7ZBq9p",
        "outputId": "0110524d-faa1-4689-da38-3e3a076f8432"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXqi1WU5Bsn9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGM79-8kBvyw"
      },
      "source": [
        "###############################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCsczCDfhthJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Km5MNehted"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc-E6Hl-htbt"
      },
      "source": [
        "#############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPN4l_0HhtZY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=500)\n",
        "y=np.random.randint(2, size=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8v_ACY8qhtV8",
        "outputId": "0a9ed630-eb1a-4cdf-dfe6-68173560487c"
      },
      "source": [
        "\n",
        "X=np.array(X).reshape(25,10,2)\n",
        "#2 neurons\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzkXFFjtyE0f"
      },
      "source": [
        "y=np.array(y).reshape(25,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "7jiy8ovf7EXj",
        "outputId": "c545f1b0-bedd-48f2-849b-79233808cb01"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "9C8hvK7qyLVW",
        "outputId": "a2422a2c-0725-42e0-f709-c3189190055d"
      },
      "source": [
        "from keras.layers.advanced_activations import Softmax\n",
        "from scipy.special import softmax\n",
        "length = 10\n",
        "n_features = 2\n",
        "#out_index = 2\n",
        "model = Sequential()\n",
        "model.add(LSTM(20,input_shape=(length, n_features)))\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#lstm (4(2*20+20*20+20))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_11 (LSTM)               (None, 20)                1840      \n",
            "=================================================================\n",
            "Total params: 1,840\n",
            "Trainable params: 1,840\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K514MpAyLSI"
      },
      "source": [
        "model.compile('rmsprop','mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "adORrZCO_yXj",
        "outputId": "d1ba722a-7901-4f3a-c646-75b4f0a005eb"
      },
      "source": [
        "model.fit(X, y, epochs=1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: 0.3902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f89c2afba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2NiYKzyLPE"
      },
      "source": [
        "output=model.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "p1LkLZ1jy3Al",
        "outputId": "1506d903-c3d0-49cf-81b9-a36fb0176462"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LL3XNZ5Wy-g0",
        "outputId": "8618e3c3-c06d-44f9-d47e-acb120462aad"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.18253714,  0.0031242 , -0.10397496,  0.12305828, -0.09945574,\n",
              "         0.089126  , -0.0319585 , -0.01053441,  0.0941768 , -0.09789409,\n",
              "         0.11123559,  0.13568546,  0.02098924,  0.09684923,  0.10943698,\n",
              "         0.00182198, -0.07011893,  0.00428317,  0.02351925,  0.01171817],\n",
              "       [ 0.23287714, -0.02349544, -0.14639746,  0.20038944, -0.07253135,\n",
              "         0.09572272, -0.03673123, -0.0148938 ,  0.11879177, -0.13445063,\n",
              "         0.20690994,  0.12146889,  0.00934635,  0.19221224,  0.1326289 ,\n",
              "         0.00820546, -0.12746221,  0.01074333,  0.02335401, -0.03549575],\n",
              "       [ 0.1658684 ,  0.00956068, -0.07796392,  0.09805976, -0.07503991,\n",
              "         0.06355147, -0.0633135 ,  0.01049898,  0.07387603, -0.07577421,\n",
              "         0.10731705,  0.12534663, -0.02286902,  0.05967901,  0.11089893,\n",
              "         0.02859034, -0.0410035 , -0.00354563,  0.01922642,  0.00986482],\n",
              "       [ 0.20799842, -0.00694274, -0.14601003,  0.18739824, -0.07817819,\n",
              "         0.10102264, -0.01368528, -0.03376463,  0.1139987 , -0.11892515,\n",
              "         0.16865629,  0.12669852,  0.02740839,  0.1465983 ,  0.109975  ,\n",
              "         0.00397621, -0.10460503,  0.01012209,  0.02026672, -0.01019456],\n",
              "       [ 0.2843584 , -0.0318161 , -0.16815466,  0.21753623, -0.06881687,\n",
              "         0.09188236, -0.0847187 ,  0.0098855 ,  0.13037902, -0.16451839,\n",
              "         0.25604507,  0.13343556, -0.02239593,  0.24214803,  0.16537282,\n",
              "         0.02118407, -0.1493099 ,  0.00431364,  0.02345644, -0.05390628],\n",
              "       [ 0.29312754, -0.02970611, -0.18296741,  0.21282545, -0.07289138,\n",
              "         0.09068679, -0.09460825,  0.01615752,  0.13037859, -0.16911414,\n",
              "         0.25673538,  0.13694449, -0.02678143,  0.25057134,  0.17118916,\n",
              "         0.02127173, -0.15445817,  0.00054753,  0.02518355, -0.04891786],\n",
              "       [ 0.21170421, -0.02950822, -0.12396491,  0.18613997, -0.0595727 ,\n",
              "         0.08463825, -0.03642175, -0.00857893,  0.11083481, -0.12480208,\n",
              "         0.20203218,  0.10240159,  0.00253538,  0.19053696,  0.11877083,\n",
              "         0.0067896 , -0.12491133,  0.01133341,  0.01959018, -0.04700815],\n",
              "       [ 0.28175306, -0.01895914, -0.19848424,  0.2644281 , -0.09984699,\n",
              "         0.13374822, -0.00230896, -0.05217782,  0.15076458, -0.16092284,\n",
              "         0.22113232,  0.1658665 ,  0.03700261,  0.21248218,  0.16911273,\n",
              "         0.00650601, -0.14142299,  0.02010367,  0.03399965, -0.01643935],\n",
              "       [ 0.25853908, -0.02815092, -0.16028301,  0.20725249, -0.06974053,\n",
              "         0.0916444 , -0.0638042 ,  0.00064305,  0.12286245, -0.15124567,\n",
              "         0.23434241,  0.12404536, -0.00694687,  0.22508883,  0.14791381,\n",
              "         0.01201713, -0.14167629,  0.00625172,  0.02200401, -0.04801703],\n",
              "       [ 0.24451491, -0.0304638 , -0.13807994,  0.18147992, -0.05506979,\n",
              "         0.07407624, -0.08540995,  0.01903665,  0.11354472, -0.13975914,\n",
              "         0.23055388,  0.11140777, -0.03271351,  0.21013895,  0.14000408,\n",
              "         0.0229407 , -0.1341454 ,  0.00094135,  0.0189512 , -0.05301139],\n",
              "       [ 0.21145248, -0.00532993, -0.15858975,  0.19583657, -0.1071166 ,\n",
              "         0.12177444, -0.00193081, -0.04868525,  0.12864608, -0.14679411,\n",
              "         0.14806357,  0.1636563 ,  0.05645293,  0.15581965,  0.10950429,\n",
              "        -0.01007148, -0.12740926,  0.01433822,  0.03104074,  0.01248896],\n",
              "       [ 0.3428696 , -0.02802821, -0.23154853,  0.2651774 , -0.09684867,\n",
              "         0.1177579 , -0.08199223, -0.00593372,  0.1508002 , -0.20087342,\n",
              "         0.27817646,  0.1719394 ,  0.00221576,  0.2901229 ,  0.20276248,\n",
              "         0.01288514, -0.17733252,  0.00621784,  0.03327608, -0.03705223],\n",
              "       [ 0.18101129, -0.02273638, -0.11223654,  0.20514186, -0.06714093,\n",
              "         0.10832995,  0.03546035, -0.0620989 ,  0.12081049, -0.10698382,\n",
              "         0.15752703,  0.11047641,  0.0448952 ,  0.1432815 ,  0.09212835,\n",
              "        -0.00324618, -0.10476105,  0.02500892,  0.02067167, -0.02574469],\n",
              "       [ 0.19795957, -0.0370042 , -0.11758423,  0.20867857, -0.05787834,\n",
              "         0.09770874,  0.00572497, -0.03339089,  0.12569031, -0.12259478,\n",
              "         0.18972464,  0.1001493 ,  0.02251326,  0.19754967,  0.10180623,\n",
              "        -0.00312344, -0.13662411,  0.02288907,  0.01966286, -0.04842459],\n",
              "       [ 0.05275108,  0.01344572, -0.02538929,  0.05859215, -0.04766692,\n",
              "         0.05853013,  0.03052901, -0.03933413,  0.0443024 , -0.0173052 ,\n",
              "         0.01511992,  0.07217855,  0.04077198, -0.00773985,  0.0292606 ,\n",
              "         0.00401059, -0.00047343,  0.01217388,  0.01233269,  0.02819702],\n",
              "       [ 0.21420875, -0.0008017 , -0.1167199 ,  0.15682703, -0.08456042,\n",
              "         0.09454279, -0.03140446, -0.01354942,  0.10926896, -0.09586976,\n",
              "         0.14308478,  0.13313681,  0.0100165 ,  0.11094005,  0.12397631,\n",
              "         0.01564111, -0.06893574,  0.00472241,  0.01864015, -0.00304548],\n",
              "       [ 0.10680366,  0.01540824, -0.05321686,  0.07741399, -0.06901475,\n",
              "         0.06395984, -0.01417774, -0.01596645,  0.05800122, -0.04509682,\n",
              "         0.05752966,  0.1036462 ,  0.01663553,  0.0212204 ,  0.06822259,\n",
              "         0.0129549 , -0.02107498,  0.0041711 ,  0.01641396,  0.02573797],\n",
              "       [ 0.15386744,  0.00480489, -0.13566247,  0.21058862, -0.12236962,\n",
              "         0.15557858,  0.11465346, -0.13630845,  0.13962336, -0.10746854,\n",
              "         0.0692515 ,  0.16988003,  0.11967611,  0.07849245,  0.06684666,\n",
              "        -0.02755067, -0.09287868,  0.03317684,  0.03640124,  0.04497671],\n",
              "       [ 0.13789141, -0.02139161, -0.07083694,  0.15357572, -0.04023334,\n",
              "         0.0756161 ,  0.01056766, -0.03297261,  0.09214765, -0.07768814,\n",
              "         0.13514455,  0.07743257,  0.01634105,  0.10761289,  0.07480549,\n",
              "         0.01024444, -0.07363769,  0.01831264,  0.01448495, -0.03245388],\n",
              "       [ 0.15548582, -0.01166041, -0.07557654,  0.13309835, -0.05880075,\n",
              "         0.08237517, -0.00157346, -0.02108674,  0.09476456, -0.06825777,\n",
              "         0.11556268,  0.09468529,  0.01073106,  0.08419488,  0.09936844,\n",
              "         0.01391443, -0.05036429,  0.0129101 ,  0.01632132, -0.01849555],\n",
              "       [ 0.13643312,  0.00203928, -0.10951411,  0.15949695, -0.09640396,\n",
              "         0.11654769,  0.0540959 , -0.07789002,  0.11140317, -0.0959925 ,\n",
              "         0.07895475,  0.1359968 ,  0.08052938,  0.08514509,  0.05546731,\n",
              "        -0.01880082, -0.08855522,  0.02103411,  0.0253622 ,  0.02821812],\n",
              "       [ 0.195921  ,  0.00373439, -0.10518107,  0.13367751, -0.09892904,\n",
              "         0.08996173, -0.04172594, -0.00987981,  0.09670795, -0.10488075,\n",
              "         0.12263951,  0.14471625,  0.01654849,  0.0959645 ,  0.11188278,\n",
              "         0.0086243 , -0.07001882,  0.00371123,  0.02180633,  0.00968074],\n",
              "       [ 0.2966039 , -0.01779174, -0.20398496,  0.26283753, -0.10227931,\n",
              "         0.12728444, -0.02864766, -0.04084136,  0.14455219, -0.1705461 ,\n",
              "         0.23623842,  0.16769306,  0.03611343,  0.23186396,  0.1712773 ,\n",
              "         0.00208588, -0.1539446 ,  0.01499115,  0.03211156, -0.01709402],\n",
              "       [ 0.26753563, -0.03567174, -0.15581627,  0.2837311 , -0.08105614,\n",
              "         0.13526717,  0.02434226, -0.0722203 ,  0.15797754, -0.15455137,\n",
              "         0.23334037,  0.15330143,  0.03686261,  0.20170285,  0.15623334,\n",
              "         0.0149875 , -0.13704728,  0.03137245,  0.02973468, -0.0426411 ],\n",
              "       [ 0.17033286, -0.00423045, -0.14248723,  0.21747097, -0.11623475,\n",
              "         0.1505748 ,  0.09662215, -0.11793158,  0.14188415, -0.12436227,\n",
              "         0.10008977,  0.16377415,  0.10998734,  0.11735591,  0.07851694,\n",
              "        -0.0292971 , -0.11434532,  0.03206167,  0.03382449,  0.02669476]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngTeXTUmzDuL"
      },
      "source": [
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI5brGPdzxZI"
      },
      "source": [
        "model.compile('rmsprop','mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "W2D9uPGR_30E",
        "outputId": "0f93c38c-f109-49e0-adb4-e564a256cf28"
      },
      "source": [
        "model.fit(X, y, epochs=10, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 0s - loss: 0.3376\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 0.2953\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 0.2720\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 0.2560\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 0.2444\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 0.2356\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 0.2290\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 0.2240\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 0.2202\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 0.2172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f89c00d6828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6dfNSvGz09u"
      },
      "source": [
        "o=model.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "el8GI6Grz5w4",
        "outputId": "8051e4e9-7f7f-42b2-f2eb-4536de1e17a5"
      },
      "source": [
        "o.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "u2YeFWS00kbp",
        "outputId": "4c376446-bb9c-4a0a-82d7-1e4004f21c0a"
      },
      "source": [
        "o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3489378 ],\n",
              "       [0.33659238],\n",
              "       [0.30558673],\n",
              "       [0.35904077],\n",
              "       [0.33120692],\n",
              "       [0.33221096],\n",
              "       [0.297148  ],\n",
              "       [0.4490691 ],\n",
              "       [0.3239758 ],\n",
              "       [0.28576982],\n",
              "       [0.42205453],\n",
              "       [0.4069866 ],\n",
              "       [0.3573912 ],\n",
              "       [0.3160169 ],\n",
              "       [0.244914  ],\n",
              "       [0.3605963 ],\n",
              "       [0.2841881 ],\n",
              "       [0.5110712 ],\n",
              "       [0.27161148],\n",
              "       [0.30196026],\n",
              "       [0.39906868],\n",
              "       [0.35891566],\n",
              "       [0.43381044],\n",
              "       [0.44132423],\n",
              "       [0.48389488]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cumypnah7bOT"
      },
      "source": [
        "y=y.reshape(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMMNt8An8nz1"
      },
      "source": [
        "o=o.reshape(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Zhsd9SeT84z-",
        "outputId": "8a2a65ab-19ed-46ba-c537-76204dff4c2b"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import metrics\n",
        "sklearn.metrics.mutual_info_score(y,o)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6730116670092567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CZAhgU60qhN"
      },
      "source": [
        "################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "1GWt4_rkKtZ4",
        "outputId": "fda84691-e249-471b-fca3-8443313c3c39"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import files\n",
        "files=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1ae9fd6-1104-4865-b6de-19b22c56135d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1ae9fd6-1104-4865-b6de-19b22c56135d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2jLddanKtW2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv('santander-train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btun3IcXKtTG"
      },
      "source": [
        "####################33333######################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGI3Wh9AKtPQ"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=200000)\n",
        "y=np.random.randint(2, size=100000)\n",
        "\n",
        "X=np.array(X).reshape(500,200,2)\n",
        "\n",
        "\n",
        "y=np.array(y).reshape(500,200,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxEdX7ViLsyL"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#0.33"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "JLpZL3dlUZLf",
        "outputId": "2b7cb7d3-8f88-4dfe-f0c1-586319d0571a"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        ...,\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        ...,\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        ...,\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1, 0],\n",
              "        [1, 0],\n",
              "        [0, 0],\n",
              "        ...,\n",
              "        [0, 1],\n",
              "        [1, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        ...,\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        ...,\n",
              "        [0, 0],\n",
              "        [1, 1],\n",
              "        [0, 0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Uoqc687qDxwb",
        "outputId": "aa5770de-b97b-401b-dd6e-2a181730ec4f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(335, 200, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OFmuX8QZD6W-",
        "outputId": "1d024028-93e9-4f85-bd99-6fb81bb19f64"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 200, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hWT3PEKsD9QV",
        "outputId": "39e6edfc-c4d7-4737-a0d5-0fcbb46e0f9d"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(335, 200, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HrohNxhTH_SN",
        "outputId": "5896c6fe-3df1-415a-842c-a24a570df198"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XeY42U-_D_rk",
        "outputId": "d610a56a-1ff3-4eda-ad59-dea832333d59"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165, 200, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdZe52puEDdF"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "# design network\n",
        "#model = Sequential()\n",
        "#model.add(LSTM(n_neurons, batch_input_shape=(len(X_train), X_train.shape[1], X_train.shape[2]), stateful=True))\n",
        "#model.add(Dense(1))\n",
        "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# fit network\n",
        "#for i in range(n_epoch):\n",
        "\t#model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=1, shuffle=False)\n",
        "\t#model.reset_states()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "0hlQPvzeEYQm",
        "outputId": "6438d294-2d19-41b4-c791-4c6323a92bc4"
      },
      "source": [
        "model.summary()\n",
        "#4(2*100+100*100+100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_41 (LSTM)               (335, 200, 100)           41200     \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (335, 200, 1)             101       \n",
            "=================================================================\n",
            "Total params: 41,301\n",
            "Trainable params: 41,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzMvNiaFAu7J"
      },
      "source": [
        "#new_model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "Qbb-5Jg4Epx0",
        "outputId": "bde392be-b426-4432-bf61-fcfa5d306497"
      },
      "source": [
        "\n",
        "#history = new_model.fit(X_train, y_train, epochs=20, batch_size=len(X_train), validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
        "for i in range(20):\n",
        "\tmodel.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7076\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "ajPB3cTPV6qE",
        "outputId": "2b528f89-98aa-46f1-f1e9-c31d8527739a"
      },
      "source": [
        "\n",
        "# re-define model\n",
        "new_model = Sequential()\n",
        "new_model.add(LSTM(100,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "new_model.add(Dense(1))\n",
        "new_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_42 (LSTM)               (165, 200, 100)           41200     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (165, 200, 1)             101       \n",
            "=================================================================\n",
            "Total params: 41,301\n",
            "Trainable params: 41,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6iVK4wdV63t"
      },
      "source": [
        "# copy weights\n",
        "old_weights = model.get_weights()\n",
        "new_model.set_weights(old_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4JBqLQnV7Iq"
      },
      "source": [
        "new_model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLh0eHqUE5AS"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "#plt.title('model loss')\n",
        "#plt.ylabel('loss')\n",
        "#plt.xlabel('epoch')\n",
        "#plt.legend(['train', 'test'], loc='upper right')\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "EI2BrnzUGCsa",
        "outputId": "3614c333-f7d9-4011-ed52-8db0a021709d"
      },
      "source": [
        "yhat =new_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-cc20ef2f6aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [165,2] from a tensor with shape [32,2]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_42/lstm_42/PartitionedCall]] [Op:__inference_predict_function_64610]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Xtkz2iIVkEgW",
        "outputId": "431bdf0c-6eb0-4c0c-edd0-016a93ba033a"
      },
      "source": [
        "\n",
        "yhat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CEKsV93JBDd_",
        "outputId": "8df3f116-03f7-40af-b244-b9f682623b03"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.02762847],\n",
              "        [-0.05507699],\n",
              "        [-0.07574663],\n",
              "        [-0.09165789],\n",
              "        [-0.07164446],\n",
              "        [-0.05079585],\n",
              "        [-0.07021565],\n",
              "        [-0.05658958],\n",
              "        [-0.0784375 ],\n",
              "        [-0.09395525]],\n",
              "\n",
              "       [[ 0.00486105],\n",
              "        [ 0.00650531],\n",
              "        [-0.03186614],\n",
              "        [-0.02621504],\n",
              "        [-0.02226832],\n",
              "        [-0.01335146],\n",
              "        [-0.00867455],\n",
              "        [-0.04523288],\n",
              "        [-0.03689868],\n",
              "        [-0.02525447]],\n",
              "\n",
              "       [[ 0.00486105],\n",
              "        [ 0.0010388 ],\n",
              "        [-0.0006425 ],\n",
              "        [ 0.00360362],\n",
              "        [-0.00119741],\n",
              "        [-0.03465086],\n",
              "        [-0.02237419],\n",
              "        [-0.04989784],\n",
              "        [-0.07589618],\n",
              "        [-0.06071812]],\n",
              "\n",
              "       [[ 0.00486105],\n",
              "        [-0.03041692],\n",
              "        [-0.05275297],\n",
              "        [-0.07639299],\n",
              "        [-0.06054555],\n",
              "        [-0.07705921],\n",
              "        [-0.05613143],\n",
              "        [-0.08187477],\n",
              "        [-0.0980517 ],\n",
              "        [-0.07170681]],\n",
              "\n",
              "       [[ 0.00486105],\n",
              "        [ 0.0010388 ],\n",
              "        [-0.0006425 ],\n",
              "        [-0.00162671],\n",
              "        [-0.00213068],\n",
              "        [-0.00231943],\n",
              "        [-0.00231214],\n",
              "        [-0.02980101],\n",
              "        [-0.02505712],\n",
              "        [-0.0155258 ]],\n",
              "\n",
              "       [[-0.03064558],\n",
              "        [-0.02397905],\n",
              "        [-0.01362625],\n",
              "        [-0.04110387],\n",
              "        [-0.06747229],\n",
              "        [-0.08265243],\n",
              "        [-0.06086662],\n",
              "        [-0.05300479],\n",
              "        [-0.07722238],\n",
              "        [-0.06116123]],\n",
              "\n",
              "       [[-0.03064558],\n",
              "        [-0.02397905],\n",
              "        [-0.01848405],\n",
              "        [-0.0451089 ],\n",
              "        [-0.03514818],\n",
              "        [-0.05804562],\n",
              "        [-0.0764477 ],\n",
              "        [-0.09086529],\n",
              "        [-0.10207388],\n",
              "        [-0.11071154]],\n",
              "\n",
              "       [[-0.03064558],\n",
              "        [-0.05206361],\n",
              "        [-0.07421727],\n",
              "        [-0.05839184],\n",
              "        [-0.04091295],\n",
              "        [-0.0347031 ],\n",
              "        [-0.06047634],\n",
              "        [-0.0423922 ],\n",
              "        [-0.03054599],\n",
              "        [-0.0228137 ]],\n",
              "\n",
              "       [[ 0.00486105],\n",
              "        [-0.02676103],\n",
              "        [-0.05645186],\n",
              "        [-0.03941457],\n",
              "        [-0.06425662],\n",
              "        [-0.04738826],\n",
              "        [-0.07787143],\n",
              "        [-0.05635155],\n",
              "        [-0.04374569],\n",
              "        [-0.034888  ]],\n",
              "\n",
              "       [[-0.03064558],\n",
              "        [-0.05509967],\n",
              "        [-0.07145862],\n",
              "        [-0.05667184],\n",
              "        [-0.04491466],\n",
              "        [-0.06715779],\n",
              "        [-0.05237571],\n",
              "        [-0.03593991],\n",
              "        [-0.02996244],\n",
              "        [-0.01937806]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6be9-yDIkJAY",
        "outputId": "7d4ba936-050a-49b3-d960-5a4bc732e0c7"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgkxYk2lCdRG"
      },
      "source": [
        "yhat=yhat.reshape(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUd9sJx1CdNy"
      },
      "source": [
        "y_test=y_test.reshape(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "8p3fDtRBCdJf",
        "outputId": "20fea8f6-99c9-4d22-dbad-b8478d1e3841"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02762847, -0.05507699, -0.07574663, -0.09165789, -0.07164446,\n",
              "       -0.05079585, -0.07021565, -0.05658958, -0.0784375 , -0.09395525,\n",
              "        0.00486105,  0.00650531, -0.03186614, -0.02621504, -0.02226832,\n",
              "       -0.01335146, -0.00867455, -0.04523288, -0.03689868, -0.02525447,\n",
              "        0.00486105,  0.0010388 , -0.0006425 ,  0.00360362, -0.00119741,\n",
              "       -0.03465086, -0.02237419, -0.04989784, -0.07589618, -0.06071812,\n",
              "        0.00486105, -0.03041692, -0.05275297, -0.07639299, -0.06054555,\n",
              "       -0.07705921, -0.05613143, -0.08187477, -0.0980517 , -0.07170681,\n",
              "        0.00486105,  0.0010388 , -0.0006425 , -0.00162671, -0.00213068,\n",
              "       -0.00231943, -0.00231214, -0.02980101, -0.02505712, -0.0155258 ,\n",
              "       -0.03064558, -0.02397905, -0.01362625, -0.04110387, -0.06747229,\n",
              "       -0.08265243, -0.06086662, -0.05300479, -0.07722238, -0.06116123,\n",
              "       -0.03064558, -0.02397905, -0.01848405, -0.0451089 , -0.03514818,\n",
              "       -0.05804562, -0.0764477 , -0.09086529, -0.10207388, -0.11071154,\n",
              "       -0.03064558, -0.05206361, -0.07421727, -0.05839184, -0.04091295,\n",
              "       -0.0347031 , -0.06047634, -0.0423922 , -0.03054599, -0.0228137 ,\n",
              "        0.00486105, -0.02676103, -0.05645186, -0.03941457, -0.06425662,\n",
              "       -0.04738826, -0.07787143, -0.05635155, -0.04374569, -0.034888  ,\n",
              "       -0.03064558, -0.05509967, -0.07145862, -0.05667184, -0.04491466,\n",
              "       -0.06715779, -0.05237571, -0.03593991, -0.02996244, -0.01937806],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro7jZmXmG3OS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "Z5f7IAz-D_O0",
        "outputId": "4b0b59b8-b957-406d-ed70-5b916f6c1309"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "70jCY-SkkK7Y",
        "outputId": "03b349a8-ce84-49af-a130-80bd1dfe9390"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import metrics\n",
        "sklearn.metrics.mutual_info_score(y_test,yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6740517555111015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 468
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjDFq-xV4-5B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfbKTv702mG"
      },
      "source": [
        "############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvPOA9s0Oav"
      },
      "source": [
        "#https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59KIHuB10PIT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "UHg7MaXr0PFX",
        "outputId": "c86c8d6f-69be-43dd-be36-1403ee5a2888"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=1000)\n",
        "y=np.random.randint(2, size=25)\n",
        "\n",
        "X=np.array(X).reshape(25,40,1)\n",
        "#2 neurons\n",
        "\n",
        "y=np.array(y).reshape(25,1)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "inputs1 = Input(shape=(3, 1))\n",
        "lstm1 = LSTM(1, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True,activation='relu',input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "#model.add(Dense(1),activation='sigmoid')\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "print(model.summary())\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=1, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "yhat = model.predict(X_test)\n",
        "yhat=np.array(yhat).reshape(yhat.shape[0])\n",
        "y_test=y_test.reshape(y_test.shape[0])\n",
        "print(y_test.shape)\n",
        "print(yhat.shape)\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "print(sklearn.metrics.mutual_info_score(y_test,yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 40, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 121,301\n",
            "Trainable params: 121,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "16/16 - 1s - loss: 0.6977 - val_loss: 0.8221\n",
            "Epoch 2/10\n",
            "16/16 - 0s - loss: 0.6504 - val_loss: 0.8394\n",
            "Epoch 3/10\n",
            "16/16 - 0s - loss: 0.6506 - val_loss: 0.8734\n",
            "Epoch 4/10\n",
            "16/16 - 0s - loss: 0.6487 - val_loss: 0.8882\n",
            "Epoch 5/10\n",
            "16/16 - 0s - loss: 0.6452 - val_loss: 0.8910\n",
            "Epoch 6/10\n",
            "16/16 - 0s - loss: 0.6436 - val_loss: 0.8956\n",
            "Epoch 7/10\n",
            "16/16 - 0s - loss: 0.6428 - val_loss: 0.9016\n",
            "Epoch 8/10\n",
            "16/16 - 0s - loss: 0.6433 - val_loss: 0.9031\n",
            "Epoch 9/10\n",
            "16/16 - 0s - loss: 0.6379 - val_loss: 0.9102\n",
            "Epoch 10/10\n",
            "16/16 - 0s - loss: 0.6398 - val_loss: 0.9136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(9,)\n",
            "(9,)\n",
            "0.5297061990576546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKPwdd_j0PB1"
      },
      "source": [
        "########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmfjkAUS0O-1"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from numpy import array\n",
        "import keras\n",
        "k_init = keras.initializers.Constant(value=0.1)\n",
        "b_init = keras.initializers.Constant(value=0)\n",
        "r_init = keras.initializers.Constant(value=0.1)\n",
        "# LSTM units\n",
        "units = 10\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(3, 2))\n",
        "lstm1 = LSTM(units, return_sequences=True, kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([0.1, 0.2, 0.3, 0.1, 0.2, 0.3]).reshape((1,3,2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "KgMSLvQrEcSC",
        "outputId": "0cf92881-143f-4b1a-ed1f-9d68199eb28b"
      },
      "source": [
        "model.summary()\n",
        "#4(2*1+1*1+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 3, 2)]            0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 3, 10)             520       \n",
            "=================================================================\n",
            "Total params: 520\n",
            "Trainable params: 520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "OggYzp4z0O7K",
        "outputId": "099cf4cc-2347-4414-bf05-7a5ccb9635c4"
      },
      "source": [
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1, 0.2],\n",
              "        [0.3, 0.1],\n",
              "        [0.2, 0.3]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "jDkHpSXZ0O4F",
        "outputId": "9da282b1-81fa-4bac-b397-31e9254696ab"
      },
      "source": [
        "# make and show prediction\n",
        "output = model.predict(data)\n",
        "print(output, output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4cd7283950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[0.00772376 0.00772376 0.00772376 0.00772376 0.00772376 0.00772376\n",
            "   0.00772376 0.00772376 0.00772376 0.00772376]\n",
            "  [0.01825831 0.01825831 0.01825831 0.01825831 0.01825831 0.01825831\n",
            "   0.01825831 0.01825831 0.01825831 0.01825831]\n",
            "  [0.0319109  0.0319109  0.0319109  0.0319109  0.0319109  0.0319109\n",
            "   0.0319109  0.0319109  0.0319109  0.0319109 ]]] (1, 3, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbtoQrUQEWNf"
      },
      "source": [
        "##########################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrY6mz09QLDd"
      },
      "source": [
        "#######https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "1b6BnbPxQLVT",
        "outputId": "e7ad0caa-d84a-479d-ca8f-a16f889ff122"
      },
      "source": [
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df, df.shift(1)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n",
        "# configure network\n",
        "n_batch = len(X)\n",
        "n_epoch = 20\n",
        "n_neurons = 10\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()\n",
        "X.shape\n",
        "# fit network\n",
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_47 (LSTM)               (9, 10)                   480       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (9, 1)                    11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2887\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2861\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2835\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2810\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2784\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2759\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2734\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2710\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2685\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2661\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2637\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2613\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2590\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2566\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2543\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2520\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2498\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2475\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2453\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kslDZARAQLbf",
        "outputId": "89dda36d-1364-4e08-e4ff-c2f17e0a29db"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YW-6XlU6coUR",
        "outputId": "942e9678-809d-42b4-c646-ff647bf7b21d"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIBmSflncp7j"
      },
      "source": [
        "# online forecast\n",
        "for i in range(len(X)):\n",
        "\ttestX, testy = X[i], y[i]\n",
        "\ttestX = testX.reshape(1, 1, 1)\n",
        "\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Wq94p3DgdKyw",
        "outputId": "a4cd2e53-39eb-4ea5-fda3-0933e1515b7e"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "AjAd5yyHc6Dg",
        "outputId": "474246a3-da9d-4bd2-c8f0-99f5487e2a00"
      },
      "source": [
        "yhat = model.predict(testX, batch_size=1)\n",
        "print('>Expected=%.1f, Predicted=%.1f' % (testy, yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-270-288d9b291c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>Expected=%.1f, Predicted=%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential_43: expected shape=(9, None, 1), found shape=[1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtaVMhdidQC7"
      },
      "source": [
        "#solution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JEqXvXBdopw"
      },
      "source": [
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df, df.shift(1)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n",
        "# configure network\n",
        "n_batch = 1\n",
        "n_epoch = 20\n",
        "n_neurons = 10\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "r0iRur0edomm",
        "outputId": "8559d8b0-58dd-4e62-9328-c8d15d07b1b4"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IDA4wa10dojb",
        "outputId": "30975745-e0b0-49c7-d043-758a5259a4e7"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "RiB0z8HbdogO",
        "outputId": "ffb207f5-97b5-4d1e-d731-451e9c63f13c"
      },
      "source": [
        "# fit network\n",
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3115\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.2631\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2222\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1873\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1574\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.1316\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1092\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0896\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0727\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0582\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0459\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0358\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0277\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0215\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0169\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0136\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0114\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0099\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0090\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 0.0083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1LRmJ_ydocx"
      },
      "source": [
        "# online forecast\n",
        "for i in range(len(X)):\n",
        "\ttestX, testy = X[i], y[i]\n",
        "\ttestX = testX.reshape(1, 1, 1)\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_9JoBaOheHXC",
        "outputId": "fc74b29a-fe26-44e7-fb0e-77c51d1422d3"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iINg8YScel0m",
        "outputId": "46136264-6ec1-47e0-c277-651feee47e0c"
      },
      "source": [
        "testy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rZRBCp8JeKK8",
        "outputId": "5c82553f-a083-48f5-9c1f-eae59ca74f84"
      },
      "source": [
        "yhat = model.predict(testX, batch_size=1)\n",
        "print('>Expected=%.1f, Predicted=%.1f' % (testy, yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4cd55941e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">Expected=0.8, Predicted=0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l96QubrOeq7b"
      },
      "source": [
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqaV7vrVeste"
      },
      "source": [
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df, df.shift(1)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Xasq-HQaetOa",
        "outputId": "d3ddb220-6c70-4c46-d738-465760b77d0c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gvQ-nH0QetXX",
        "outputId": "6c3c625f-9126-4a5a-bcc9-69748569fd70"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8MRBJuet-m"
      },
      "source": [
        "# configure network\n",
        "n_batch = len(X)\n",
        "n_epoch = 20\n",
        "n_neurons = 10\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "KLNncojxeuIw",
        "outputId": "52e77598-394a-4dff-b85c-f7d053d5d5aa"
      },
      "source": [
        "# fit network\n",
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2517\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2491\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2466\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2441\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2416\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2391\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2366\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2341\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2317\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2292\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2268\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2244\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2220\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2196\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2172\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2149\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2125\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2102\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2079\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "zVQ0WSJ6euXa",
        "outputId": "9636e7da-9a63-4b54-f6fd-70a30f5b45cb"
      },
      "source": [
        "# batch forecast\n",
        "yhat = model.predict(X, batch_size=n_batch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4cd52fa9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FKyaeooYeuQV",
        "outputId": "d87cfe2f-bd4d-4d53-9c31-b64c3d8e3e1a"
      },
      "source": [
        "yhat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "3PkarszNet4_",
        "outputId": "f79c9b2c-91e9-48ab-852d-2472567e19b1"
      },
      "source": [
        "for i in range(len(y)):\n",
        "\tprint('>Expected=%.1f, Predicted=%.1f' % (y[i], yhat[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Expected=0.0, Predicted=0.0\n",
            ">Expected=0.1, Predicted=0.0\n",
            ">Expected=0.2, Predicted=0.0\n",
            ">Expected=0.3, Predicted=0.0\n",
            ">Expected=0.4, Predicted=0.0\n",
            ">Expected=0.5, Predicted=0.0\n",
            ">Expected=0.6, Predicted=0.0\n",
            ">Expected=0.7, Predicted=0.0\n",
            ">Expected=0.8, Predicted=0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR46UfXetzk"
      },
      "source": [
        "########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFIErriCettn"
      },
      "source": [
        "\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df, df.shift(1)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n",
        "# configure network\n",
        "n_batch = 3\n",
        "n_epoch = 10\n",
        "n_neurons = 10\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-SJpbcM3etmd",
        "outputId": "2c87f313-bfa3-48ec-e541-baa0e422468c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DZvMSQxKetIX",
        "outputId": "7294acb6-1958-4654-e214-24096e3726a3"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "AlOS4To-etES",
        "outputId": "b55c6041-b210-4ff2-ea33-866bc229b128"
      },
      "source": [
        "# fit network\n",
        "for i in range(n_epoch):\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
        "\tmodel.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.1267\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.1169\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.1077\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0989\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0822\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0745\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0672\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0603\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTmprVLHetAi"
      },
      "source": [
        "# re-define the batch size\n",
        "n_batch = 1\n",
        "# re-define model\n",
        "new_model = Sequential()\n",
        "new_model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "new_model.add(Dense(1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-NcvDjHesqL"
      },
      "source": [
        "# copy weights\n",
        "old_weights = model.get_weights()\n",
        "new_model.set_weights(old_weights)\n",
        "# compile model\n",
        "new_model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "ztkTJL3desmH",
        "outputId": "6aee55fc-ff0c-4b42-f432-91f6645e4a42"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_56 (LSTM)               (1, 10)                   480       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (1, 1)                    11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "stXKZPp3esix",
        "outputId": "e4f5261b-6afe-4366-b502-cea2b39e1570"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_55 (LSTM)               (3, 10)                   480       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (3, 1)                    11        \n",
            "=================================================================\n",
            "Total params: 491\n",
            "Trainable params: 491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xOnNBcI6our8",
        "outputId": "ce7abbfb-357d-4ab9-9057-c4f3f699f0bf"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "3aDymUGresfe",
        "outputId": "1a8ab036-0278-43e5-bc0b-0d57a1a9615f"
      },
      "source": [
        "# online forecast\n",
        "for i in range(len(X)):\n",
        "\ttestX, testy = X[i], y[i]\n",
        "\ttestX = testX.reshape(1, 1, 1)\n",
        "\tyhat = new_model.predict(testX, batch_size=n_batch)\n",
        "\tprint('>Expected=%.1f, Predicted=%.1f' % (testy, yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4cce544268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">Expected=0.0, Predicted=0.1\n",
            ">Expected=0.1, Predicted=0.1\n",
            ">Expected=0.2, Predicted=0.2\n",
            ">Expected=0.3, Predicted=0.3\n",
            ">Expected=0.4, Predicted=0.4\n",
            ">Expected=0.5, Predicted=0.4\n",
            ">Expected=0.6, Predicted=0.5\n",
            ">Expected=0.7, Predicted=0.6\n",
            ">Expected=0.8, Predicted=0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STv1UC-9escI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxdTWPGqerdR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpxtW-20erZV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL6qW86yerVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkVLvqAHerSK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abbiIgk3eq4D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toC2qw8Seqz-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzn3dDRPeqwq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVXkHWW0eqsj"
      },
      "source": [
        "############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "UtdOTQz_eNYt",
        "outputId": "44d80e05-d424-4035-97e5-9a9825ea38c4"
      },
      "source": [
        "##############################################3\n",
        "\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=600)\n",
        "y=np.random.randint(2, size=300)\n",
        "X=np.array(X).reshape(30,10,2)\n",
        "y=np.array(y).reshape(30,10,1)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#0.33import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "for i in range(10):\n",
        "\tmodel.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "\n",
        "# re-define model\n",
        "new_model = Sequential()\n",
        "new_model.add(LSTM(100,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "new_model.add(Dense(1))\n",
        "#new_model.summary()\n",
        "# copy weights\n",
        "old_weights = model.get_weights()\n",
        "new_model.set_weights(old_weights)\n",
        "new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "yhat =new_model.predict(X_test)\n",
        "yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "print(sklearn.metrics.mutual_info_score(y_test,yhat))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4cc96df8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.6236324491684843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "mmdf2OAbeW4-",
        "outputId": "8666503f-1af1-43e0-d0dc-fbaa011aed99"
      },
      "source": [
        "\n",
        "#####################################\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "X =np.random.randint(2, size=6000)\n",
        "y=np.random.randint(2, size=3000)\n",
        "X=np.array(X).reshape(300,10,2)\n",
        "y=np.array(y).reshape(300,10,1)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "#0.33import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "units=100\n",
        "model = Sequential()\n",
        "model.add(LSTM(units, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "for i in range(10):\n",
        "\tmodel.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "\n",
        "# re-define model\n",
        "new_model = Sequential()\n",
        "new_model.add(LSTM(100,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "new_model.add(Dense(1))\n",
        "#new_model.summary()\n",
        "n_parameters=(4*((X_test.shape[2]*units)+(units*units)+(units)))\n",
        "\n",
        "# copy weights\n",
        "old_weights = model.get_weights()\n",
        "new_model.set_weights(old_weights)\n",
        "new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "yhat =new_model.predict(X_test)\n",
        "print(X_test.shape)\n",
        "yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "print(n_parameters)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-ac9a7e06c3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [99,2] from a tensor with shape [32,2]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_48/lstm_48/PartitionedCall]] [Op:__inference_predict_function_74044]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "lt0-IiZulF_G",
        "outputId": "73605806-6d88-4bde-ecc6-bb51e0c8b944"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_48 (LSTM)               (99, 10, 100)             41200     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (99, 10, 1)               101       \n",
            "=================================================================\n",
            "Total params: 41,301\n",
            "Trainable params: 41,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "fFokgF6llGOO",
        "outputId": "4842510a-484e-47a6-ec3f-f046b3e5be6d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_47 (LSTM)               (201, 10, 100)            41200     \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (201, 10, 1)              101       \n",
            "=================================================================\n",
            "Total params: 41,301\n",
            "Trainable params: 41,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hP-acdGslzsd",
        "outputId": "6c17d2d9-5693-4737-f016-37fc1692e7e3"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 10, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zZKAL0Eflz9R",
        "outputId": "78dab75c-7be7-4a1e-c558-f0a9e4d3853a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Ysvhpflz4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "voP-k1p71c5c",
        "outputId": "8f716d56-9b91-4b55-e23a-30ed6436e79b"
      },
      "source": [
        "#####################################\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "n_parameters_l=[]\n",
        "mi_score=[]\n",
        "n_samples_l=[]\n",
        "bits_l=[]\n",
        "bits_per_parameter_l=[]\n",
        "l=[1000,10000,100000]\n",
        "for i in l:\n",
        "  X =np.random.randint(2, size=i)\n",
        "  y=np.random.randint(2, size=int(i/2))\n",
        "  X=np.array(X).reshape(25,int(i/50),2)\n",
        "  y=np.array(y).reshape(25,int(i/50),1)\n",
        "  import numpy as np\n",
        "\n",
        "  #0.33import numpy as np\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  units=10\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  for i in range(10):\n",
        "    model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "    model.reset_states()\n",
        "\n",
        "  # re-define model\n",
        "  new_model = Sequential()\n",
        "  new_model.add(LSTM(units,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "  new_model.add(Dense(1,activation='sigmoid'))\n",
        "  #new_model.summary()\n",
        "  n_parameters=(4*((X_test.shape[2]*units)+(units*units)+(units)))\n",
        "  \n",
        "  n_parameters_l.append(n_parameters)\n",
        "  # copy weights\n",
        "  old_weights = model.get_weights()\n",
        "  new_model.set_weights(old_weights)\n",
        "  #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  yhat =new_model.predict(X_test)\n",
        "  yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "  y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "  import sklearn\n",
        "  from sklearn import metrics\n",
        " \n",
        "  mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "  #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "  #print('n_parameters',n_parameters)\n",
        "  z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "  p=(z/y_test.shape[0])\n",
        "  b=X.shape[0]*X.shape[1]\n",
        "\n",
        "  #no of samples\n",
        "  n_samples=X.shape[0]*X.shape[1]\n",
        "  \n",
        "  n_samples_l.append(n_samples)\n",
        "  import math\n",
        "  bits=b+b*(p*math.log2(p))+((1-p)*math.log2(1-p))\n",
        "  bits_per_parameter=(bits/n_parameters)\n",
        "  bits_l.append(bits)\n",
        "  bits_per_parameter_l.append(bits_per_parameter)\n",
        "  #print('bits : ',bits)\n",
        "  #print('bits_per_parameter : ',bits_per_parameter)\n",
        "\n",
        "print('mi_score',mi_score)\n",
        "i=mi_score.index(max(mi_score)) \n",
        "print('n_parameters',n_parameters_l)\n",
        "print('n_samples',n_samples_l)\n",
        "print('bits',bits_l)\n",
        "\n",
        "print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "print('bits',bits_l[i])\n",
        "print('bits_per_parameter',bits_per_parameter_l[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa7998f0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa7999c4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa79ad47730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "mi_score [0.6404920026352976, 0.6860328563414689, 0.6818329888937521]\n",
            "n_parameters [520, 520, 520]\n",
            "n_samples [500, 5000, 50000]\n",
            "bits [252.04308031900348, 2547.9977169266626, 25076.594278495897]\n",
            "bits_per_parameter [0.484698231382699, 4.8999956094743515, 48.224219766338265]\n",
            "bits 2547.9977169266626\n",
            "bits_per_parameter 4.8999956094743515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qT6a7Z3SxwTo",
        "outputId": "9177d553-1c7c-49f7-b0a0-5edde2d7350f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kGWPMRYxxwP1",
        "outputId": "c6fd43aa-6c87-4c89-eba6-9ee4db25f4ef"
      },
      "source": [
        "########################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1080]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OONYT9cZxwLg",
        "outputId": "ebe5e4c1-d565-4c2d-d51d-66ccf24956c2"
      },
      "source": [
        "#####################################\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "n_parameters_l=[]\n",
        "mi_score=[]\n",
        "n_samples_l=[]\n",
        "bits_l=[]\n",
        "bits_per_parameter_l=[]\n",
        "l=[1000,10000,100000]\n",
        "for i in l:\n",
        "  X =np.random.randint(2, size=i)\n",
        "  y=np.random.randint(2, size=int(i/2))\n",
        "  X=np.array(X).reshape(25,int(i/50),2)\n",
        "  y=np.array(y).reshape(25,int(i/50),1)\n",
        "  import numpy as np\n",
        "\n",
        "  #0.33import numpy as np\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  units=10\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  for i in range(10):\n",
        "    model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "    model.reset_states()\n",
        "\n",
        "  # re-define model\n",
        "  new_model = Sequential()\n",
        "  new_model.add(LSTM(units,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "  new_model.add(Dense(1,activation='sigmoid'))\n",
        "  #new_model.summary()\n",
        "  n_parameters=(4*((X_test.shape[2]*units)+(units*units)+(units)))\n",
        "  \n",
        "  n_parameters_l.append(n_parameters)\n",
        "  # copy weights\n",
        "  old_weights = model.get_weights()\n",
        "  new_model.set_weights(old_weights)\n",
        "  #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  yhat =new_model.predict(X_test)\n",
        "  yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "  y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "  import sklearn\n",
        "  from sklearn import metrics\n",
        " \n",
        "  mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "  #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "  #print('n_parameters',n_parameters)\n",
        "  z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "  p=(z/y_test.shape[0])\n",
        "  b=X.shape[0]*X.shape[1]\n",
        "\n",
        "  #no of samples\n",
        "  n_samples=X.shape[0]*X.shape[1]\n",
        "  \n",
        "  n_samples_l.append(n_samples)\n",
        "  import math\n",
        "  bits=b+b*(p*math.log2(p))+((1-p)*math.log2(1-p))\n",
        "  bits_per_parameter=(bits/n_parameters)\n",
        "  bits_l.append(bits)\n",
        "  bits_per_parameter_l.append(bits_per_parameter)\n",
        "  #print('bits : ',bits)\n",
        "  #print('bits_per_parameter : ',bits_per_parameter)\n",
        "\n",
        "print('mi_score',mi_score)\n",
        "i=mi_score.index(max(mi_score)) \n",
        "print('n_parameters',n_parameters_l)\n",
        "print('n_samples',n_samples_l)\n",
        "print('bits',bits_l)\n",
        "\n",
        "print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "print('bits',bits_l[i])\n",
        "print('bits_per_parameter',bits_per_parameter_l[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[500]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaCz5S-zxwG2"
      },
      "source": [
        "#######################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "hI3evrlUxwC4",
        "outputId": "4607c830-c6b0-491a-9179-01ceb751abcf"
      },
      "source": [
        "##111111111111##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[12,13]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2357538158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001221875\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f23547daf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012196480285141457\n",
            "10050\n",
            "n_units 15\n",
            "p_l [0.0001221875, 0.00012196480285141457]\n",
            "mi_score [6.355747422864821e-05, 1.3362261299228184e-05]\n",
            "n_parameters [1036, 1036]\n",
            "n_samples [10000, 10050]\n",
            "bits [9982.354631166443, 10032.295499156546]\n",
            "bits_per_parameter [9.635477443210853, 9.68368291424377]\n",
            "bits 9982.354631166443\n",
            "bits_per_parameter 9.635477443210853\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f235503c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012475\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2352b99620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001252444246429544\n",
            "10050\n",
            "n_units 16\n",
            "p_l [0.00012475, 0.0001252444246429544]\n",
            "mi_score [4.110920216460201e-07, 3.134709603480612e-05]\n",
            "n_parameters [1169, 1169]\n",
            "n_samples [10000, 10050]\n",
            "bits [9982.021931177744, 10031.867615002391]\n",
            "bits_per_parameter [8.538940916319712, 8.581580508984082]\n",
            "bits 10031.867615002391\n",
            "bits_per_parameter 8.581580508984082\n",
            "[9.635477443210853, 8.581580508984082]\n",
            "[9982.354631166443, 10031.867615002391]\n",
            "[1036, 1169]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XemYgDyXxv-l",
        "outputId": "7ffd0555-aa24-489b-8a7c-4311eaa5a05f"
      },
      "source": [
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ZsM-8RevKgnY",
        "outputId": "1718cd1d-918b-49fa-ffb7-58792cacec88"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skVaqzC1_zVO"
      },
      "source": [
        "###################222###################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujd9d41G_z_c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "jDs32vV2ACha",
        "outputId": "b74b6726-f11c-4856-ace6-00a3cc4d62d4"
      },
      "source": [
        "##2222222##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[24,25]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050,11000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2357ec7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.000126125\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2357b73268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012505878567362194\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2355c0da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011095041322314049\n",
            "11000\n",
            "n_units 24\n",
            "p_l [0.000126125, 0.00012505878567362194, 0.00011095041322314049]\n",
            "mi_score [6.827128685221728e-05, 1.4744226319682308e-05, 2.1691161142454313e-05]\n",
            "n_parameters [2521, 2521, 2521]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.84372334146, 10031.891801299313, 10982.20526948143]\n",
            "bits_per_parameter [3.95947787518503, 3.979330345616546, 4.3562892778585605]\n",
            "bits 9981.84372334146\n",
            "bits_per_parameter 3.95947787518503\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2356553158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001275625\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2354c80510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012085096903541991\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2354aa9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011224173553719007\n",
            "11000\n",
            "n_units 25\n",
            "p_l [0.0001275625, 0.00012085096903541991, 0.00011224173553719007]\n",
            "mi_score [8.048951364490742e-06, 0.000256917810568494, -4.996003610813204e-16]\n",
            "n_parameters [2726, 2726, 2726]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.65764637452, 10032.441107516324, 10982.018774124299]\n",
            "bits_per_parameter [3.6616499069605726, 3.6802792030507425, 4.028620239957556]\n",
            "bits 10032.441107516324\n",
            "bits_per_parameter 3.6802792030507425\n",
            "[3.95947787518503, 3.6802792030507425]\n",
            "[9981.84372334146, 10032.441107516324]\n",
            "[2521, 2726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbKSzhCr_z4n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "iIsKNWxGAfoN",
        "outputId": "2eb5420b-bda5-4cf6-c563-4f829d67d023"
      },
      "source": [
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML4OJEvp_z0M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "NVVSIVxkApwv",
        "outputId": "9d9a2d10-6a31-4f4c-e097-da75e066d768"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpOiaHRaPQJ9"
      },
      "source": [
        "###################2323232323################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EsLvz3KPP9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4aNpspPPx2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "mGDsZ4yCWIOQ",
        "outputId": "e5395ffd-311b-4cd2-a7df-fa18bfc7f4b2"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    yhat =new_model.predict(X_test)\n",
        "    #yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    print(yhat)\n",
        "    yhat = (yhat <0.5).astype(int)\n",
        "    print(yhat)\n",
        "    #yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8c67f34488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.5024794 0.5024794 0.5024794 ... 0.5024794 0.5024794 0.5024794]\n",
            "[0 0 0 ... 0 0 0]\n",
            "0.51\n",
            "10000\n",
            "n_units 1\n",
            "p_l [0.51]\n",
            "mi_score [0.0]\n",
            "n_parameters [14]\n",
            "n_samples [10000]\n",
            "bits [2.885582471901216]\n",
            "bits_per_parameter [0.20611303370722972]\n",
            "bits 2.885582471901216\n",
            "bits_per_parameter 0.20611303370722972\n",
            "[0.20611303370722972]\n",
            "[2.885582471901216]\n",
            "[14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkF_Jl-PPPo5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIZiVXoS_zuD"
      },
      "source": [
        "##########33######################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0k6Z23U_zn4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "01c0oIpSV3lt",
        "outputId": "d3d68e77-c416-4db8-8cdf-be2141119f41"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[19,20]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050,11000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499b980ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001258125\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499fcc2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012289299769807678\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499dd451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011358471074380165\n",
            "11000\n",
            "n_units 19\n",
            "p_l [0.0001258125, 0.00012289299769807678, 0.00011358471074380165]\n",
            "mi_score [1.5171560135002204e-05, 0.00017840141395420242, 9.23548896802906e-08]\n",
            "n_parameters [1616, 1616, 1616]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.884206044979, 10032.174271590884, 10981.825069049475]\n",
            "bits_per_parameter [6.176908543344665, 6.2080286334102, 6.7956838298573485]\n",
            "bits 10032.174271590884\n",
            "bits_per_parameter 6.2080286334102\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499dc4b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.000123625\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499c934ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012431622979629218\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499d840b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011513429752066116\n",
            "11000\n",
            "n_units 20\n",
            "p_l [0.000123625, 0.00012431622979629218, 0.00011513429752066116]\n",
            "mi_score [3.2804372237460466e-05, -8.881784197001252e-16, 8.847776346793124e-05]\n",
            "n_parameters [1781, 1781, 1781]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9982.16790013215, 10031.988586505906, 10981.601876171888]\n",
            "bits_per_parameter [5.604810724386384, 5.632784158622069, 6.16597522525092]\n",
            "bits 10981.601876171888\n",
            "bits_per_parameter 6.16597522525092\n",
            "[6.2080286334102, 6.16597522525092]\n",
            "[10032.174271590884, 10981.601876171888]\n",
            "[1616, 1781]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_7UxTw_zQ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "QZdlkpi0WGfJ",
        "outputId": "3b801101-7f10-4ca4-e33a-037f8ec133e8"
      },
      "source": [
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKvFTiDh_zLN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "50oHrM5mWMYN",
        "outputId": "adc94391-b394-4fdb-d52c-467a7f198b71"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOdRl5tP_zF3"
      },
      "source": [
        "##############################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDgQ6TmcY2Tv"
      },
      "source": [
        "#2 layer lstm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OIeF_iWYZXPI",
        "outputId": "039217a0-8518-417c-abba-2310033b80d7"
      },
      "source": [
        "##4444444##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[21,22]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[9050,10000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    for i in range(1):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_50 (LSTM)               (3, 1810, 21)             1932      \n",
            "_________________________________________________________________\n",
            "lstm_51 (LSTM)               (3, 1810, 21)             3612      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (3, 1810, 1)              22        \n",
            "=================================================================\n",
            "Total params: 5,566\n",
            "Trainable params: 5,566\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 550 calls to <function Model.make_train_function.<locals>.train_function at 0x7efe05990400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdfef87c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00014323433350630323\n",
            "9050\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_54 (LSTM)               (3, 2000, 21)             1932      \n",
            "_________________________________________________________________\n",
            "lstm_55 (LSTM)               (3, 2000, 21)             3612      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (3, 2000, 1)              22        \n",
            "=================================================================\n",
            "Total params: 5,566\n",
            "Trainable params: 5,566\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7efdfc419488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdfc4cfea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012825\n",
            "10000\n",
            "n_units 21\n",
            "p_l [0.00014323433350630323, 0.00012825]\n",
            "mi_score [0.0, 0.0]\n",
            "n_parameters [1954, 1954]\n",
            "n_samples [9050, 10000]\n",
            "bits [9031.577495512956, 9981.56873583018]\n",
            "bits_per_parameter [4.6220969782563746, 5.108274685685865]\n",
            "bits 9031.577495512956\n",
            "bits_per_parameter 4.6220969782563746\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_58 (LSTM)               (3, 1810, 22)             2112      \n",
            "_________________________________________________________________\n",
            "lstm_59 (LSTM)               (3, 1810, 22)             3960      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (3, 1810, 1)              23        \n",
            "=================================================================\n",
            "Total params: 6,095\n",
            "Trainable params: 6,095\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7efdff91e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efe05990510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00013850309819602574\n",
            "9050\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_62 (LSTM)               (3, 2000, 22)             2112      \n",
            "_________________________________________________________________\n",
            "lstm_63 (LSTM)               (3, 2000, 22)             3960      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (3, 2000, 1)              23        \n",
            "=================================================================\n",
            "Total params: 6,095\n",
            "Trainable params: 6,095\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7efdffa4ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdfd3cef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012575\n",
            "10000\n",
            "n_units 22\n",
            "p_l [0.00013850309819602574, 0.00012575]\n",
            "mi_score [0.00019477914308546618, 8.881784197001252e-16]\n",
            "n_parameters [2135, 2135]\n",
            "n_samples [9050, 10000]\n",
            "bits [9032.125271751298, 9981.892303928753]\n",
            "bits_per_parameter [4.230503640164542, 4.675359392940868]\n",
            "bits 9032.125271751298\n",
            "bits_per_parameter 4.230503640164542\n",
            "[4.6220969782563746, 4.230503640164542]\n",
            "[9031.577495512956, 9032.125271751298]\n",
            "[1954, 2135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ0JpsLlY3qR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "G9iNAnsHc3xi",
        "outputId": "4c785268-9dc7-4693-86f0-f690ca11773e"
      },
      "source": [
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('2 layer LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2 layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcJ9YCOkY4Mb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "bw6TJE30c-j1",
        "outputId": "3ca23fd2-0381-4b4e-e918-23d059e36cb2"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "plt.title('2 layer LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2 layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbRDZ91Y4Gy"
      },
      "source": [
        "\n",
        "####################################################################################################3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjlRFz1zY4Br"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHFBonwcd-G5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2708
        },
        "id": "Lnbkehoyd_O5",
        "outputId": "dca807c3-47d6-4016-ad60-b579ae9bd991"
      },
      "source": [
        "##555555555##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[20,21]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050,11000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_158\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_244 (LSTM)              (3, 2000, 20)             1760      \n",
            "_________________________________________________________________\n",
            "lstm_245 (LSTM)              (3, 2000, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_246 (LSTM)              (3, 2000, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_247 (LSTM)              (3, 2000, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_248 (LSTM)              (3, 2000, 20)             3280      \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (3, 2000, 1)              21        \n",
            "=================================================================\n",
            "Total params: 14,901\n",
            "Trainable params: 14,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4998e5b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012731249999999998\n",
            "10000\n",
            "Model: \"sequential_160\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_254 (LSTM)              (3, 2010, 20)             1760      \n",
            "_________________________________________________________________\n",
            "lstm_255 (LSTM)              (3, 2010, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_256 (LSTM)              (3, 2010, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_257 (LSTM)              (3, 2010, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_258 (LSTM)              (3, 2010, 20)             3280      \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (3, 2010, 1)              21        \n",
            "=================================================================\n",
            "Total params: 14,901\n",
            "Trainable params: 14,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4998811510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012406871117051556\n",
            "10050\n",
            "Model: \"sequential_162\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_264 (LSTM)              (3, 2200, 20)             1760      \n",
            "_________________________________________________________________\n",
            "lstm_265 (LSTM)              (3, 2200, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_266 (LSTM)              (3, 2200, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_267 (LSTM)              (3, 2200, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_268 (LSTM)              (3, 2200, 20)             3280      \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (3, 2200, 1)              21        \n",
            "=================================================================\n",
            "Total params: 14,901\n",
            "Trainable params: 14,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499989e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011317148760330577\n",
            "11000\n",
            "n_units 20\n",
            "p_l [0.00012731249999999998, 0.00012406871117051556, 0.00011317148760330577]\n",
            "mi_score [0.00011800047358728749, -1.3322676295501878e-15, 9.994904775600943e-06]\n",
            "n_parameters [1781, 1781, 1781]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.68999072171, 10032.020862515175, 10981.88464362953]\n",
            "bits_per_parameter [5.604542386705059, 5.632802281030418, 6.166133994177164]\n",
            "bits 9981.68999072171\n",
            "bits_per_parameter 5.604542386705059\n",
            "Model: \"sequential_164\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_274 (LSTM)              (3, 2000, 21)             1932      \n",
            "_________________________________________________________________\n",
            "lstm_275 (LSTM)              (3, 2000, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_276 (LSTM)              (3, 2000, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_277 (LSTM)              (3, 2000, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_278 (LSTM)              (3, 2000, 21)             3612      \n",
            "_________________________________________________________________\n",
            "dense_164 (Dense)            (3, 2000, 1)              22        \n",
            "=================================================================\n",
            "Total params: 16,402\n",
            "Trainable params: 16,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49955437b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012431250000000002\n",
            "10000\n",
            "Model: \"sequential_166\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_284 (LSTM)              (3, 2010, 21)             1932      \n",
            "_________________________________________________________________\n",
            "lstm_285 (LSTM)              (3, 2010, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_286 (LSTM)              (3, 2010, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_287 (LSTM)              (3, 2010, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_288 (LSTM)              (3, 2010, 21)             3612      \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (3, 2010, 1)              22        \n",
            "=================================================================\n",
            "Total params: 16,402\n",
            "Trainable params: 16,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4997386400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012233608079007945\n",
            "10050\n",
            "Model: \"sequential_168\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_294 (LSTM)              (3, 2200, 21)             1932      \n",
            "_________________________________________________________________\n",
            "lstm_295 (LSTM)              (3, 2200, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_296 (LSTM)              (3, 2200, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_297 (LSTM)              (3, 2200, 21)             3612      \n",
            "_________________________________________________________________\n",
            "lstm_298 (LSTM)              (3, 2200, 21)             3612      \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (3, 2200, 1)              22        \n",
            "=================================================================\n",
            "Total params: 16,402\n",
            "Trainable params: 16,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4994a66a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011637396694214876\n",
            "11000\n",
            "n_units 21\n",
            "p_l [0.00012431250000000002, 0.00012233608079007945, 0.00011637396694214876]\n",
            "mi_score [8.881784197001252e-16, -4.440892098500626e-16, 0.00017659205306169712]\n",
            "n_parameters [1954, 1954, 1954]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9982.078679414879, 10032.246995881858, 10981.423560418656]\n",
            "bits_per_parameter [5.108535659884789, 5.134210335661135, 5.61997111587444]\n",
            "bits 10981.423560418656\n",
            "bits_per_parameter 5.61997111587444\n",
            "[5.604542386705059, 5.61997111587444]\n",
            "[9981.68999072171, 10981.423560418656]\n",
            "[1781, 1954]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w7_me7Vd9_Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "7eD36d7RgmVo",
        "outputId": "145f82ad-8678-4cc8-f906-9afdaa9724f3"
      },
      "source": [
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multi layer LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_6Xu2Ld96d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "dq0IxGaLhCyi",
        "outputId": "f9ac9c48-0d8c-4f9b-9057-0543f0a44428"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "plt.title('multi layer LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'multi layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1I4cIy-d91n"
      },
      "source": [
        "##################5555555555555555555555555##########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "xAGNo_lkd9wu",
        "outputId": "56a6badc-1c71-4968-ca3e-772fc66d65d3"
      },
      "source": [
        "pip install np_utils\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.6/dist-packages (0.5.12.1)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.6/dist-packages (from np_utils) (1.18.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.6/dist-packages (from np_utils) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "O3FB9kiaFNOk",
        "outputId": "59605931-2ca6-4138-b69c-005d6fcd9033"
      },
      "source": [
        "pip install --upgrade --user keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "oZurQE7rFFme",
        "outputId": "96878a36-357c-4bf7-f234-2fe377924932"
      },
      "source": [
        "conda install numpy\n",
        "\n",
        "conda install future\n",
        "\n",
        "conda install -c anaconda theano\n",
        "\n",
        "conda install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-efe19e9426ad>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install numpy\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjOwvIPjd9r2"
      },
      "source": [
        "#############\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "i_Qity1_CwF3",
        "outputId": "53ae0afd-1d93-4d92-8b5c-78f621ecfa1b"
      },
      "source": [
        "##66666666666##################################\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[80000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(10,int(i/10),1)\n",
        "    y=np.array(y).reshape(10,int(i/10),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "    \n",
        "    #import numpy as np\n",
        "    #from sklearn.model_selection import KFold\n",
        "    #kf = KFold(n_splits=10)\n",
        "    #kf.get_n_splits(X)\n",
        "    #kfold = KFold(3, True, 1)\n",
        "    #for train, test in kfold.split(data):\n",
        "\t   # print('train: %s, test: %s' % (data[train], data[test]))\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    \n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    #model.fit()\n",
        "    #for i in range(1):\n",
        "     # model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "     # model.reset_states()\n",
        "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1000,verbose=0)\n",
        "\n",
        "    # re-define model\n",
        "    #new_model = Sequential()\n",
        "    #new_model.add(LSTM(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "   \n",
        "    #new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    #old_weights = model.get_weights()\n",
        "    #new_model.set_weights(old_weights)\n",
        "    #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_train)\n",
        "    #yhat=model.predict(X_test)\n",
        "    print(yhat)\n",
        "    #y_p =new_model.predict(X_test)\n",
        "    #yhat= keras.np_utils.probas_to_classes(y_p)\n",
        "    yhat=yhat.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    print(y_test.shape)\n",
        "    print(yhat.shape)\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #print('z',z)\n",
        "    #print(y_test.shape[0])\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_72 (LSTM)               (5, 8000, 1)              12        \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (5, 8000, 1)              2         \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "EpFhbpQ07vWa",
        "outputId": "53ae0afd-1d93-4d92-8b5c-78f621ecfa1b"
      },
      "source": [
        "##66666666666##################################\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[80000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(10,int(i/10),1)\n",
        "    y=np.array(y).reshape(10,int(i/10),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "    \n",
        "    #import numpy as np\n",
        "    #from sklearn.model_selection import KFold\n",
        "    #kf = KFold(n_splits=10)\n",
        "    #kf.get_n_splits(X)\n",
        "    #kfold = KFold(3, True, 1)\n",
        "    #for train, test in kfold.split(data):\n",
        "\t   # print('train: %s, test: %s' % (data[train], data[test]))\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    \n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    #model.fit()\n",
        "    #for i in range(1):\n",
        "     # model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "     # model.reset_states()\n",
        "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1000,verbose=0)\n",
        "\n",
        "    # re-define model\n",
        "    #new_model = Sequential()\n",
        "    #new_model.add(LSTM(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "   \n",
        "    #new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    #old_weights = model.get_weights()\n",
        "    #new_model.set_weights(old_weights)\n",
        "    #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_train)\n",
        "    #yhat=model.predict(X_test)\n",
        "    print(yhat)\n",
        "    #y_p =new_model.predict(X_test)\n",
        "    #yhat= keras.np_utils.probas_to_classes(y_p)\n",
        "    yhat=yhat.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    print(y_test.shape)\n",
        "    print(yhat.shape)\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #print('z',z)\n",
        "    #print(y_test.shape[0])\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_72 (LSTM)               (5, 8000, 1)              12        \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (5, 8000, 1)              2         \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YSsD_ZY_7x3b",
        "outputId": "fbbe6405-1d36-4416-fbf3-b368c87aa49c"
      },
      "source": [
        "##66666666666##################################\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[27000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(10,int(i/10),1)\n",
        "    y=np.array(y).reshape(10,int(i/10),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "    \n",
        "    #import numpy as np\n",
        "    #from sklearn.model_selection import KFold\n",
        "    #kf = KFold(n_splits=10)\n",
        "    #kf.get_n_splits(X)\n",
        "    #kfold = KFold(3, True, 1)\n",
        "    #for train, test in kfold.split(data):\n",
        "\t   # print('train: %s, test: %s' % (data[train], data[test]))\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    #model.fit()\n",
        "    #for i in range(1):\n",
        "     # model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "     # model.reset_states()\n",
        "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1000,verbose=0)\n",
        "\n",
        "    # re-define model\n",
        "    #new_model = Sequential()\n",
        "    #new_model.add(LSTM(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "   \n",
        "    #new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    #old_weights = model.get_weights()\n",
        "    #new_model.set_weights(old_weights)\n",
        "    #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_train)\n",
        "    #yhat=model.predict(X_test)\n",
        "    print(yhat)\n",
        "    #y_p =new_model.predict(X_test)\n",
        "    #yhat= keras.np_utils.probas_to_classes(y_p)\n",
        "    yhat=yhat.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    print(y_test.shape)\n",
        "    print(yhat.shape)\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #print('z',z)\n",
        "    #print(y_test.shape[0])\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_74 (LSTM)               (5, 2700, 1)              12        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (5, 2700, 1)              4         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (5, 2700, 1)              2         \n",
            "=================================================================\n",
            "Total params: 18\n",
            "Trainable params: 16\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efdfcf57a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "(13500,)\n",
            "(13500,)\n",
            "0.5033333333333333\n",
            "27000\n",
            "n_units 1\n",
            "p_l [0.5033333333333333]\n",
            "mi_score [8.326672684688674e-16]\n",
            "n_parameters [14]\n",
            "n_samples [27000]\n",
            "bits [0.8656234366208082]\n",
            "bits_per_parameter [0.06183024547291487]\n",
            "bits 0.8656234366208082\n",
            "bits_per_parameter 0.06183024547291487\n",
            "[0.06183024547291487]\n",
            "[0.8656234366208082]\n",
            "[14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obURELFbd9nD"
      },
      "source": [
        "\n",
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# generate and prepare the dataset\n",
        "def get_data():\n",
        "\t# generate dataset\n",
        "\tX, y = make_circles(n_samples=1000, noise=0.1, random_state=1)\n",
        "\t# split into train and test\n",
        "\tn_test = 500\n",
        "\ttrainX, testX = X[:n_test, :], X[n_test:, :]\n",
        "\ttrainy, testy = y[:n_test], y[n_test:]\n",
        "\treturn trainX, trainy, testX, testy\n",
        "\n",
        "# define and fit the model\n",
        "def get_model(trainX, trainy):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(100, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy, epochs=300, verbose=0)\n",
        "\treturn model\n",
        "\n",
        "# generate data\n",
        "trainX, trainy, testX, testy = get_data()\n",
        "# fit model\n",
        "model = get_model(trainX, trainy)\n",
        "\n",
        "\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(testX, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(testX, verbose=0)\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(testy, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testy, yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testy, yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testy, yhat_classes)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(testy, yhat_classes)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(testy, yhat_probs)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(testy, yhat_classes)\n",
        "print(matrix)\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "25\n",
        "26\n",
        "27\n",
        "28\n",
        "29\n",
        "30\n",
        "31\n",
        "32\n",
        "33\n",
        "34\n",
        "35\n",
        "36\n",
        "37\n",
        "38\n",
        "39\n",
        "40\n",
        "41\n",
        "42\n",
        "43\n",
        "44\n",
        "45\n",
        "46\n",
        "47\n",
        "48\n",
        "49\n",
        "50\n",
        "51\n",
        "52\n",
        "53\n",
        "54\n",
        "55\n",
        "56\n",
        "57\n",
        "58\n",
        "59\n",
        "60\n",
        "61\n",
        "62\n",
        "63\n",
        "64\n",
        "65\n",
        "66\n",
        "67\n",
        "68\n",
        "69\n",
        "70\n",
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "# generate and prepare the dataset\n",
        "def get_data():\n",
        "\t# generate dataset\n",
        "\tX, y = make_circles(n_samples=1000, noise=0.1, random_state=1)\n",
        "\t# split into train and test\n",
        "\tn_test = 500\n",
        "\ttrainX, testX = X[:n_test, :], X[n_test:, :]\n",
        "\ttrainy, testy = y[:n_test], y[n_test:]\n",
        "\treturn trainX, trainy, testX, testy\n",
        " \n",
        "# define and fit the model\n",
        "def get_model(trainX, trainy):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(100, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy, epochs=300, verbose=0)\n",
        "\treturn model\n",
        " \n",
        "# generate data\n",
        "trainX, trainy, testX, testy = get_data()\n",
        "# fit model\n",
        "model = get_model(trainX, trainy)\n",
        " \n",
        " \n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(testX, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(testX, verbose=0)\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        " \n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(testy, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testy, yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testy, yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testy, yhat_classes)\n",
        "print('F1 score: %f' % f1)\n",
        " \n",
        "# kappa\n",
        "kappa = cohen_kappa_score(testy, yhat_classes)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(testy, yhat_probs)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(testy, yhat_classes)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC3zsyIwQKzu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9GV6p5uQMQY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GWjwkOCQMsW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7IEgzdxd9iS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaDqZAndd9cQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtAeilYYd9XB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXyTdC6gY3lV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9w4oOSY2O1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu7vMmhiY2Is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5xjVwAY2Ct"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiAZjduhWP0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxBojjV-WQRm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi8JosD5WQNE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cVBmlWZWPwS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMqHglqZWPqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twM5eOMAWPl_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95RabSRYhU0o"
      },
      "source": [
        "y_test=[0,0,1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0-rvvR5hVUO"
      },
      "source": [
        "yhat=[1,1,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vUFsA2dehVQU",
        "outputId": "7ce55a64-9eb2-400f-df19-b97dd59fbd5e"
      },
      "source": [
        "sklearn.metrics.mutual_info_score(y_test,yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6931471805599453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAGtY0ychVMR"
      },
      "source": [
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "FKJHxsJMkRql",
        "outputId": "91ce5af5-c24b-45af-e74e-535d990986f8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[200]\n",
        "  for i in l:\n",
        "    #X=[1,1,1,1,1,0,0,0,0,0]\n",
        "    #y=[1,0,1,0,1,0,1,0,1,0]\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i/2))\n",
        "    X=np.array(X).reshape(5,40,1)\n",
        "    y=np.array(y).reshape(5,20,1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    yhat =new_model.predict(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    z=accuracy_score(y_test, yhat.round(), normalize=True)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3b9d25cb0285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1605 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4823 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((3, 40, 1) vs (3, 20, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dr8tkyZakRk8",
        "outputId": "d546f620-876c-48d7-84a0-0c5dfdeb9faa"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.5, 0.5, 0.5], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XpO-tKn2kRg4",
        "outputId": "82f3ed8b-b126-4822-d190-8dd129cfbdf9"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wVZgAU_kRb-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ0IT7QbkRXt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CPQV_nGkRTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cof0oFVFkROs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMGYXr_SkRJ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unvBB75jkRFl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkcxDPUkRAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0R1XuDCkQ7l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX8FLMbikQ3h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1DQl3V4kQyH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jzQld3rkQsp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ0r8jjqkQnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfkFJfxchVIM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2wnD39OhVEd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAiIRx4YM51X"
      },
      "source": [
        "##################################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjkIqU1p__RR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cYKeGN__Nt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL4mIXR8__KG"
      },
      "source": [
        "\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qWOvEBeEM_xL",
        "outputId": "26fd4a86-439a-46c4-d94a-d6cdd2f6b808"
      },
      "source": [
        "from google.colab import files\n",
        "files=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fcdcd958-52a8-47fd-8c07-6815ab09d8cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fcdcd958-52a8-47fd-8c07-6815ab09d8cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sonar.csv to sonar.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyz46FXPY6de"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv('sonar.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyICUkECZLP3"
      },
      "source": [
        "dataframe=data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIHyYmYOa8W4"
      },
      "source": [
        "dataset = dataframe.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "znDXW6Es_j6d",
        "outputId": "c94c5bbf-ba12-4173-c7a4-5d68fa4d1b9e"
      },
      "source": [
        "dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>0.3108</td>\n",
              "      <td>0.2933</td>\n",
              "      <td>0.2275</td>\n",
              "      <td>0.0994</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.2732</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2034</td>\n",
              "      <td>0.1740</td>\n",
              "      <td>0.4130</td>\n",
              "      <td>0.6879</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8453</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8104</td>\n",
              "      <td>0.6199</td>\n",
              "      <td>0.6041</td>\n",
              "      <td>0.5547</td>\n",
              "      <td>0.4160</td>\n",
              "      <td>0.1472</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.1411</td>\n",
              "      <td>0.1676</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1977</td>\n",
              "      <td>0.1339</td>\n",
              "      <td>0.0902</td>\n",
              "      <td>0.1085</td>\n",
              "      <td>0.1521</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.0858</td>\n",
              "      <td>0.0290</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>0.3085</td>\n",
              "      <td>0.3425</td>\n",
              "      <td>0.2990</td>\n",
              "      <td>0.1402</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.1901</td>\n",
              "      <td>0.2429</td>\n",
              "      <td>0.2120</td>\n",
              "      <td>0.2395</td>\n",
              "      <td>0.3272</td>\n",
              "      <td>0.5949</td>\n",
              "      <td>0.8302</td>\n",
              "      <td>0.9045</td>\n",
              "      <td>0.9888</td>\n",
              "      <td>0.9912</td>\n",
              "      <td>0.9448</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9092</td>\n",
              "      <td>0.7412</td>\n",
              "      <td>0.7691</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.5304</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0928</td>\n",
              "      <td>0.1297</td>\n",
              "      <td>0.1159</td>\n",
              "      <td>0.1226</td>\n",
              "      <td>0.1768</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0.1562</td>\n",
              "      <td>0.0824</td>\n",
              "      <td>0.1149</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0790</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.0647</td>\n",
              "      <td>0.0179</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>0.2716</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>0.1878</td>\n",
              "      <td>0.0983</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>0.1503</td>\n",
              "      <td>0.1723</td>\n",
              "      <td>0.2339</td>\n",
              "      <td>0.1962</td>\n",
              "      <td>0.1395</td>\n",
              "      <td>0.3164</td>\n",
              "      <td>0.5888</td>\n",
              "      <td>0.7631</td>\n",
              "      <td>0.8473</td>\n",
              "      <td>0.9424</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.9699</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>0.6979</td>\n",
              "      <td>0.7717</td>\n",
              "      <td>0.7305</td>\n",
              "      <td>0.5197</td>\n",
              "      <td>0.1786</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1446</td>\n",
              "      <td>0.1066</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1929</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.0328</td>\n",
              "      <td>0.0537</td>\n",
              "      <td>0.1309</td>\n",
              "      <td>0.0910</td>\n",
              "      <td>0.0757</td>\n",
              "      <td>0.1059</td>\n",
              "      <td>0.1005</td>\n",
              "      <td>0.0535</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2898</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.0273</td>\n",
              "      <td>0.0673</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.2645</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.5685</td>\n",
              "      <td>0.6990</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.9242</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.8297</td>\n",
              "      <td>0.7032</td>\n",
              "      <td>0.7141</td>\n",
              "      <td>0.6893</td>\n",
              "      <td>0.4961</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>0.0776</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.1572</td>\n",
              "      <td>0.1823</td>\n",
              "      <td>0.1349</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.0492</td>\n",
              "      <td>0.1367</td>\n",
              "      <td>0.1552</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.1319</td>\n",
              "      <td>0.0985</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>0.2720</td>\n",
              "      <td>0.2442</td>\n",
              "      <td>0.1665</td>\n",
              "      <td>0.0336</td>\n",
              "      <td>0.1302</td>\n",
              "      <td>0.1708</td>\n",
              "      <td>0.2177</td>\n",
              "      <td>0.3175</td>\n",
              "      <td>0.3714</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.7397</td>\n",
              "      <td>0.8062</td>\n",
              "      <td>0.8837</td>\n",
              "      <td>0.9432</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.7603</td>\n",
              "      <td>0.7123</td>\n",
              "      <td>0.8358</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.4567</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.1549</td>\n",
              "      <td>0.1641</td>\n",
              "      <td>0.1869</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0768</td>\n",
              "      <td>0.0847</td>\n",
              "      <td>0.2076</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.1439</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.0991</td>\n",
              "      <td>0.0041</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0181</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1       2       3       4   ...      56      57      58      59  60\n",
              "0    0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ...  ..\n",
              "203  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157   M\n",
              "204  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067   M\n",
              "205  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031   M\n",
              "206  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048   M\n",
              "207  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115   M\n",
              "\n",
              "[208 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "R6TFgdhla_jK",
        "outputId": "4ef735f2-b182-4d85-c0e4-171e1ad4a788"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02, 0.0371, 0.0428, ..., 0.009, 0.0032, 'R'],\n",
              "       [0.0453, 0.0523, 0.0843, ..., 0.0052, 0.0044, 'R'],\n",
              "       [0.0262, 0.0582, 0.1099, ..., 0.0095, 0.0078, 'R'],\n",
              "       ...,\n",
              "       [0.0522, 0.0437, 0.018, ..., 0.0077, 0.0031, 'M'],\n",
              "       [0.0303, 0.0353, 0.049, ..., 0.0036, 0.0048, 'M'],\n",
              "       [0.026, 0.0363, 0.0136, ..., 0.0061, 0.0115, 'M']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61uGePX8b1JN"
      },
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "Kznm0IsvcD_Y",
        "outputId": "f8fa1315-12f1-490c-e6d5-4355fb1cf7e2"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
              "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
              "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
              "       ...,\n",
              "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
              "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
              "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "dBzZ-b8Jchyb",
        "outputId": "8b1a7c58-8e9f-4e7d-aa14-a9d5ecfe3197"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JD_9P7R1cu7z",
        "outputId": "2371632e-728a-4e87-fa7e-6dd04730f5c1"
      },
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "encoder.fit(Y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "_MUdQocT_03k",
        "outputId": "3d9dbbca-22ec-44b8-dbe6-3fcaf19bcc1a"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmNLGrFoAFf8"
      },
      "source": [
        "encoded_Y = encoder.transform(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "rGXxdClEAKAG",
        "outputId": "0c8aea60-c07e-46eb-d485-8e6003260ad7"
      },
      "source": [
        "encoded_Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63I6HkchAMQ4"
      },
      "source": [
        "def create_baseline():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(60, input_dim=60, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqOErg5AqCM"
      },
      "source": [
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4paMzoiHAsFP",
        "outputId": "f5d2d298-0c65-4181-f270-b506325094b6"
      },
      "source": [
        "estimator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7f8047ee2d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCPrgviMBPHK"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KsI7Ta3yBTCi",
        "outputId": "6950f4f1-7d19-4d4d-d719-16f0d1494aa2"
      },
      "source": [
        "kfold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wr15dNUBUUd"
      },
      "source": [
        "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "17owQssSBXDS",
        "outputId": "714a6ec4-7d03-4e44-8466-2ab77c16795d"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.76190478, 0.85714287, 0.90476191, 0.66666669, 0.76190478,\n",
              "       0.80952382, 0.85714287, 0.71428573, 0.94999999, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "E5elm4iABk_6",
        "outputId": "af9b3f2e-c0af-49b2-a339-52922cc828e5"
      },
      "source": [
        "\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 82.83% (10.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W3HTylCBsvK"
      },
      "source": [
        "##################\n",
        "y=[1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZXW8mwaq5OEq",
        "outputId": "ef926a54-cf3d-436f-bc77-1ea659ae962c"
      },
      "source": [
        "np.array(y).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSZ-_i1k5PMS"
      },
      "source": [
        "y=np.array(y).reshape(3,6,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "Ohz8vXRj5W3S",
        "outputId": "cbdc3eb3-9706-4b7d-f34a-d6ac7176507b"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4],\n",
              "        [5],\n",
              "        [6]],\n",
              "\n",
              "       [[7],\n",
              "        [8],\n",
              "        [9],\n",
              "        [1],\n",
              "        [2],\n",
              "        [3]],\n",
              "\n",
              "       [[4],\n",
              "        [5],\n",
              "        [6],\n",
              "        [7],\n",
              "        [8],\n",
              "        [9]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YBPF5MM45zdm",
        "outputId": "9418fb65-4a9b-4d4e-a27b-5b2c22fd6a18"
      },
      "source": [
        "y.reshape(y.shape[0]*y.shape[1]*y.shape[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOM3rw7y57Z5"
      },
      "source": [
        "y_test=[1,1,1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3amrDCMkKI3C"
      },
      "source": [
        "yhat=[1,1,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSQuKIO3KLfH"
      },
      "source": [
        "z=accuracy_score(y_test,yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AbDsV36cKON-",
        "outputId": "50fe246b-5d01-4650-ed53-604f9a9a62f1"
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMKJ0C3eKPEd"
      },
      "source": [
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "# data sample\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "d=array([1,0,1,0,1,0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FgoyZ2PQCda"
      },
      "source": [
        "data=data.reshape(6,1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "pjwVX5o7Q1ga",
        "outputId": "0fdf2d70-ce30-4bac-bd81-267b20bcc86c"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1]],\n",
              "\n",
              "       [[0.2]],\n",
              "\n",
              "       [[0.3]],\n",
              "\n",
              "       [[0.4]],\n",
              "\n",
              "       [[0.5]],\n",
              "\n",
              "       [[0.6]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VJzVohnQ4yu"
      },
      "source": [
        "d=d.reshape(6,1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "pQTqO56mRBfk",
        "outputId": "35f5a97d-d1ce-4e80-e0e4-0f9ad3275ff0"
      },
      "source": [
        "# prepare cross validation\n",
        "kfold = KFold(6, True, 1)\n",
        "# enumerate splits\n",
        "for train_X, test_X,train_y,test_y in kfold.split(d):\n",
        "\tprint('train: %s, test: %s,%s,%s' % (data[train_X], data[test_X],d[test_y],d[train[y]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-54fbdaabdff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# enumerate splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train: %s, test: %s,%s,%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxRoh52TRfBu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "TQValnZUKfl5",
        "outputId": "0c82860d-8b7e-41b5-a470-54f2250ee67d"
      },
      "source": [
        "##66666666666##################################\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[27000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(10,int(i/10),1)\n",
        "    y=np.array(y).reshape(10,int(i/10),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "    \n",
        "    #import numpy as np\n",
        "    #from sklearn.model_selection import KFold\n",
        "    #kf = KFold(n_splits=10)\n",
        "    #kf.get_n_splits(X)\n",
        "    #kfold = KFold(3, True, 1)\n",
        "    #for train, test in kfold.split(data):\n",
        "\t   # print('train: %s, test: %s' % (data[train], data[test]))\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    #model.fit()\n",
        "    #for i in range(1):\n",
        "     # model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "     # model.reset_states()\n",
        "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1000,verbose=0)\n",
        "\n",
        "    # re-define model\n",
        "    #new_model = Sequential()\n",
        "    #new_model.add(LSTM(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "   \n",
        "    #new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    #old_weights = model.get_weights()\n",
        "    #new_model.set_weights(old_weights)\n",
        "    #new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_train)\n",
        "    #yhat=model.predict(X_test)\n",
        "    print(yhat)\n",
        "    #y_p =new_model.predict(X_test)\n",
        "    #yhat= keras.np_utils.probas_to_classes(y_p)\n",
        "    yhat=yhat.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    print(y_test.shape)\n",
        "    print(yhat.shape)\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #print('z',z)\n",
        "    #print(y_test.shape[0])\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_75 (LSTM)               (5, 2700, 1)              12        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (5, 2700, 1)              4         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (5, 2700, 1)              2         \n",
            "=================================================================\n",
            "Total params: 18\n",
            "Trainable params: 16\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nE8KeH-KgGQ"
      },
      "source": [
        "########################################3\n",
        "########################################3\n",
        "######################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwtqDvSqaZ0y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "PyscxpU-aZt5",
        "outputId": "75482dbe-6390-4056-9d28-6c447639c1e7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFT6m7XraZn8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "ubM-bg4iaaaa",
        "outputId": "6842b0a8-b64b-42f3-e0e8-e3a28171ef1a"
      },
      "source": [
        "##777777777777##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "\n",
        "units=[10]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[5000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "    #opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    for i in range(100):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dropout(0.2))\n",
        "    new_model.add(LSTM(j,return_sequences=True))\n",
        "    new_model.add(Dropout(0.2))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "    #opt = keras.optimizers.Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    #for i in range(100):\n",
        "      #new_model.fit(X_test, y_test, epochs=1, batch_size=len(X_test), verbose=0, shuffle=False)\n",
        "      #new_model.reset_states()\n",
        "    \n",
        "    #y_hat =new_model.predict(X_test)\n",
        "    #yhat=new_model.predict_classes(X_test)\n",
        "    yhat =new_model.predict(X_test, batch_size=len(X_train))\n",
        "    print(yhat)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    yhat = (yhat <0.4980).astype(int)\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_50 (LSTM)               (3, 1000, 10)             480       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (3, 1000, 10)             0         \n",
            "_________________________________________________________________\n",
            "lstm_51 (LSTM)               (3, 1000, 10)             840       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (3, 1000, 10)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (3, 1000, 1)              11        \n",
            "=================================================================\n",
            "Total params: 1,331\n",
            "Trainable params: 1,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8c70990510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[0.4999484 ]\n",
            "  [0.49963188]\n",
            "  [0.49945107]\n",
            "  ...\n",
            "  [0.49716666]\n",
            "  [0.49698138]\n",
            "  [0.49694118]]\n",
            "\n",
            " [[0.49965513]\n",
            "  [0.4994715 ]\n",
            "  [0.49937007]\n",
            "  ...\n",
            "  [0.49744242]\n",
            "  [0.4973572 ]\n",
            "  [0.4973784 ]]]\n",
            "0.5015\n",
            "5000\n",
            "n_units 10\n",
            "p_l [0.5015]\n",
            "mi_score [8.308371092696039e-05]\n",
            "n_parameters [491]\n",
            "n_samples [5000]\n",
            "bits [0.03246068711177941]\n",
            "bits_per_parameter [6.61113790463939e-05]\n",
            "bits 0.03246068711177941\n",
            "bits_per_parameter 6.61113790463939e-05\n",
            "[6.61113790463939e-05]\n",
            "[0.03246068711177941]\n",
            "[491]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pc0xTjbP8MS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5G_EZHox2t4Q",
        "outputId": "9cf29dcd-a307-45c3-c48f-a4daef57f434"
      },
      "source": [
        "##888888888888888888##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "\n",
        "units=[10]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[5000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(10,int(i/10),1)\n",
        "    y=np.array(y).reshape(10,int(i/10),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(j,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "    #opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    for i in range(100):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    \n",
        "    \n",
        "    #y_hat =new_model.predict(X_test)\n",
        "    #yhat=new_model.predict_classes(X_test)\n",
        "    yhat =model.predict(X_test, batch_size=len(X_train))\n",
        "    print(yhat)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    #yhat = (yhat <0.5).astype(int)\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_56 (LSTM)               (5, 500, 10)              480       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (5, 500, 10)              0         \n",
            "_________________________________________________________________\n",
            "lstm_57 (LSTM)               (5, 500, 10)              840       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (5, 500, 10)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (5, 500, 1)               11        \n",
            "=================================================================\n",
            "Total params: 1,331\n",
            "Trainable params: 1,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8c704fbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[0.49933872]\n",
            "  [0.49839634]\n",
            "  [0.49743024]\n",
            "  ...\n",
            "  [0.4978164 ]\n",
            "  [0.4975282 ]\n",
            "  [0.49695492]]\n",
            "\n",
            " [[0.49933872]\n",
            "  [0.49839634]\n",
            "  [0.49823576]\n",
            "  ...\n",
            "  [0.497016  ]\n",
            "  [0.49749488]\n",
            "  [0.49720585]]\n",
            "\n",
            " [[0.49933872]\n",
            "  [0.49839634]\n",
            "  [0.49823576]\n",
            "  ...\n",
            "  [0.49668977]\n",
            "  [0.49706188]\n",
            "  [0.49758476]]\n",
            "\n",
            " [[0.49933872]\n",
            "  [0.49914828]\n",
            "  [0.49920395]\n",
            "  ...\n",
            "  [0.49412677]\n",
            "  [0.49513623]\n",
            "  [0.49525383]]\n",
            "\n",
            " [[0.49933872]\n",
            "  [0.49839634]\n",
            "  [0.49823576]\n",
            "  ...\n",
            "  [0.49642542]\n",
            "  [0.4968096 ]\n",
            "  [0.4973749 ]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a4e6695d9ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m#z=accuracy_score(y_test, yhat.round(), normalize=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;31m#p=(z/y_test.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mp_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-JK6W3gP8HW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dSOP7qmP8CT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lkC1S3P79Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFiTEQ5XP74b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "cJ3K8GyjP7zc",
        "outputId": "d6bb370f-e28a-4524-ad11-1ab02299e337"
      },
      "source": [
        "yhat[0:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "a3EVEsjWP7tJ",
        "outputId": "74c43872-59a1-4157-e696-c047f7be4d1a"
      },
      "source": [
        "yhat[0:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49970245, 0.49967834, 0.4996661 , 0.49965993, 0.49965677,\n",
              "       0.4996552 , 0.49965438, 0.49965397, 0.49965376, 0.49965367,\n",
              "       0.4996536 , 0.49965358, 0.49965358, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "8UOHNBGjP6_H",
        "outputId": "1c108e82-cc63-4a26-8356-b15918f3b80a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355,\n",
              "       0.49965355, 0.49965355, 0.49965355, 0.49965355, 0.49965355],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM72GAgeXTdb"
      },
      "source": [
        "X =np.random.randint(2, size=10)\n",
        "y=np.random.randint(2, size=int(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dUGfDqWKX_R3",
        "outputId": "fbd520c8-5344-491e-b202-d99f4df70378"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "co4nkoYOYAMX",
        "outputId": "7e78ec4b-6700-4cb2-db20-0fcdb701142f"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyAfGZkhYBjA"
      },
      "source": [
        "#########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqjMgWQApaxG"
      },
      "source": [
        "#GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idc3B5DIpani"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "BWRjDPB5pdGM",
        "outputId": "e8b0daa4-2e58-46c7-c0d4-d2525f0049ad"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "#from keras.layers import LSTM\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[100000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(GRU(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    yhat =new_model.predict(X_test)\n",
        "    #yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    print(yhat)\n",
        "    yhat = (yhat <0.5).astype(int)\n",
        "    print(yhat)\n",
        "    #yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.50249076 0.50249076 0.4466346  ... 0.47025144 0.48651397 0.43706724]\n",
            "[0 0 1 ... 1 1 1]\n",
            "0.49655\n",
            "100000\n",
            "n_units 1\n",
            "p_l [0.49655]\n",
            "mi_score [3.055356085981953e-06]\n",
            "n_parameters [14]\n",
            "n_samples [100000]\n",
            "bits [3.434362796804635]\n",
            "bits_per_parameter [0.2453116283431882]\n",
            "bits 3.434362796804635\n",
            "bits_per_parameter 0.2453116283431882\n",
            "[0.2453116283431882]\n",
            "[3.434362796804635]\n",
            "[14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7LjJqhepnfx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "niceNnLxrTus",
        "outputId": "86589594-627c-48ea-e04f-7ff70676e15d"
      },
      "source": [
        "##4444444##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "\n",
        "units=[21,22]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[9050,10000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(GRU(j,return_sequences=True))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model.summary()\n",
        "    for i in range(1):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(GRU(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(GRU(j,return_sequences=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_4 (GRU)                  (3, 1810, 21)             1512      \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (3, 1810, 21)             2772      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (3, 1810, 1)              22        \n",
            "=================================================================\n",
            "Total params: 4,306\n",
            "Trainable params: 4,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-5-e2ef743dfc1e>:60: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "0.000134306034614328\n",
            "9050\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_8 (GRU)                  (3, 2000, 21)             1512      \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (3, 2000, 21)             2772      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (3, 2000, 1)              22        \n",
            "=================================================================\n",
            "Total params: 4,306\n",
            "Trainable params: 4,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "0.0001249375\n",
            "10000\n",
            "n_units 21\n",
            "p_l [0.000134306034614328, 0.0001249375]\n",
            "mi_score [3.0458377170666795e-05, 0.0003917552582178227]\n",
            "n_parameters [1954, 1954]\n",
            "n_samples [9050, 10000]\n",
            "bits [9032.612966799772, 9981.997617286255]\n",
            "bits_per_parameter [4.62262690214932, 5.108494174660315]\n",
            "bits 9981.997617286255\n",
            "bits_per_parameter 5.108494174660315\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_12 (GRU)                 (3, 1810, 22)             1650      \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (3, 1810, 22)             3036      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (3, 1810, 1)              23        \n",
            "=================================================================\n",
            "Total params: 4,709\n",
            "Trainable params: 4,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f191b5ee158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00013644272152864688\n",
            "9050\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_16 (GRU)                 (3, 2000, 22)             1650      \n",
            "_________________________________________________________________\n",
            "gru_17 (GRU)                 (3, 2000, 22)             3036      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (3, 2000, 1)              23        \n",
            "=================================================================\n",
            "Total params: 4,709\n",
            "Trainable params: 4,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x7f191ee7e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f191d8536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.000126375\n",
            "10000\n",
            "n_units 22\n",
            "p_l [0.00013644272152864688, 0.000126375]\n",
            "mi_score [4.440892098500626e-16, 3.654319696791419e-05]\n",
            "n_parameters [2135, 2135]\n",
            "n_samples [9050, 10000]\n",
            "bits [9032.364474972986, 9981.811345223772]\n",
            "bits_per_parameter [4.230615679144256, 4.675321473172727]\n",
            "bits 9981.811345223772\n",
            "bits_per_parameter 4.675321473172727\n",
            "[5.108494174660315, 4.675321473172727]\n",
            "[9981.997617286255, 9981.811345223772]\n",
            "[1954, 2135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3kSTDgoserR"
      },
      "source": [
        "##########3###########333"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzp9ih-nIh9e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "zbETXxKTIioz",
        "outputId": "22f1bce1-09ee-4273-de6b-60fd1535794f"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  b_c_entropy=[]\n",
        "  l=[10000,70000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p=p+0.4\n",
        "    p_l.append(z)\n",
        "    print(p)\n",
        "    loss=sklearn.metrics.log_loss(y_test,yhat,normalize=False)\n",
        "    b_c_entropy.append(loss)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('binary_cross_entropy',b_c_entropy)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  k=b_c_entropy.index(min(b_c_entropy))\n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "plt.plot(n_parameters_f,bits_f)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IoxPDGWIh3j"
      },
      "source": [
        "x=[0,0]\n",
        "y=[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "6PGY-v77IhvM",
        "outputId": "12d4421d-2fbf-445e-add5-d387b9d64f06"
      },
      "source": [
        "\n",
        "sklearn.metrics.log_loss(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a1b4f75a194c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2253\u001b[0m             raise ValueError('y_true contains only one label ({0}). Please '\n\u001b[1;32m   2254\u001b[0m                              \u001b[0;34m'provide the true labels explicitly through the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m                              'labels argument.'.format(lb.classes_[0]))\n\u001b[0m\u001b[1;32m   2256\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m             raise ValueError('The labels array needs to contain at least two '\n",
            "\u001b[0;31mValueError\u001b[0m: y_true contains only one label (0). Please provide the true labels explicitly through the labels argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dod55rltIhqg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "RX4k-V7Hvq7X",
        "outputId": "d3d68e77-c416-4db8-8cdf-be2141119f41"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[19,20]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050,11000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499b980ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001258125\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499fcc2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012289299769807678\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499dd451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011358471074380165\n",
            "11000\n",
            "n_units 19\n",
            "p_l [0.0001258125, 0.00012289299769807678, 0.00011358471074380165]\n",
            "mi_score [1.5171560135002204e-05, 0.00017840141395420242, 9.23548896802906e-08]\n",
            "n_parameters [1616, 1616, 1616]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.884206044979, 10032.174271590884, 10981.825069049475]\n",
            "bits_per_parameter [6.176908543344665, 6.2080286334102, 6.7956838298573485]\n",
            "bits 10032.174271590884\n",
            "bits_per_parameter 6.2080286334102\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499dc4b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.000123625\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499c934ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012431622979629218\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f499d840b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011513429752066116\n",
            "11000\n",
            "n_units 20\n",
            "p_l [0.000123625, 0.00012431622979629218, 0.00011513429752066116]\n",
            "mi_score [3.2804372237460466e-05, -8.881784197001252e-16, 8.847776346793124e-05]\n",
            "n_parameters [1781, 1781, 1781]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9982.16790013215, 10031.988586505906, 10981.601876171888]\n",
            "bits_per_parameter [5.604810724386384, 5.632784158622069, 6.16597522525092]\n",
            "bits 10981.601876171888\n",
            "bits_per_parameter 6.16597522525092\n",
            "[6.2080286334102, 6.16597522525092]\n",
            "[10032.174271590884, 10981.601876171888]\n",
            "[1616, 1781]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPjK0RbivyjV"
      },
      "source": [
        "###############################################################################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "LI53djqn3HXl",
        "outputId": "717a6bfe-5185-47cc-d007-b209134e995d"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "units=[19,20]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000,10050,11000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(SimpleRNN(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    z=accuracy_score(y_test,yhat)\n",
        "    p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad2e2a6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.000124625\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad31136ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.0001252444246429544\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad2df70400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011539256198347107\n",
            "11000\n",
            "n_units 19\n",
            "p_l [0.000124625, 0.0001252444246429544, 0.00011539256198347107]\n",
            "mi_score [9.358751709920288e-05, 2.4190894250097905e-05, 5.8987474264526885e-05]\n",
            "n_parameters [1616, 1616, 1616]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9982.03814269737, 10031.867615002391, 10981.564709661865]\n",
            "bits_per_parameter [6.1770038011741155, 6.2078388706697964, 6.795522716374917]\n",
            "bits 9982.03814269737\n",
            "bits_per_parameter 6.1770038011741155\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad29a62d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012731249999999998\n",
            "10000\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad2e142ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00012728645330561123\n",
            "10050\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad2addb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.00011368801652892562\n",
            "11000\n",
            "n_units 20\n",
            "p_l [0.00012731249999999998, 0.00012728645330561123, 0.00011368801652892562]\n",
            "mi_score [0.00012383433033852365, 0.0002890020252349079, 4.2192464527746054e-07]\n",
            "n_parameters [1781, 1781, 1781]\n",
            "n_samples [10000, 10050, 11000]\n",
            "bits [9981.68999072171, 10031.601827787128, 10981.810179135948]\n",
            "bits_per_parameter [5.604542386705059, 5.632567000441958, 6.166092183681049]\n",
            "bits 10031.601827787128\n",
            "bits_per_parameter 5.632567000441958\n",
            "[6.1770038011741155, 5.632567000441958]\n",
            "[9982.03814269737, 10031.601827787128]\n",
            "[1616, 1781]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg9tUpw_3Iz_"
      },
      "source": [
        "######################3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB45Gy3bezB7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "XcfQeLwhezsw",
        "outputId": "958651b8-8806-49cb-daf3-9deb0d01bf04"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "units=[1]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[10000]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,activation='relu',stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    sgd = keras.optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu', batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    \n",
        "    sgd = keras.optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
        "\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
        "    yhat =new_model.predict(X_test)\n",
        "    #yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    print(yhat)\n",
        "    yhat = (yhat <0.5).astype(int)\n",
        "    print(yhat)\n",
        "    #yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49986404 0.49986404 0.49986404 ... 0.49986404 0.49986404 0.49986404]\n",
            "[1 1 1 ... 1 1 1]\n",
            "0.50975\n",
            "10000\n",
            "n_units 1\n",
            "p_l [0.50975]\n",
            "mi_score [0.0]\n",
            "n_parameters [14]\n",
            "n_samples [10000]\n",
            "bits [2.7430978057418542]\n",
            "bits_per_parameter [0.19593555755298958]\n",
            "bits 2.7430978057418542\n",
            "bits_per_parameter 0.19593555755298958\n",
            "[0.19593555755298958]\n",
            "[2.7430978057418542]\n",
            "[14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgLqYzSifA3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0wFH0ks7Lw"
      },
      "source": [
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1KJ2s_nAtF8W",
        "outputId": "0d508f1b-9a8d-4ef6-94fd-034fbe16a2fb"
      },
      "source": [
        "\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9aa17294a245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9aa17294a245>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'one_hot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "B37Q2rdstVKE",
        "outputId": "bfd95452-61ac-4a03-85d8-58a966234dfe"
      },
      "source": [
        "import math\n",
        "np.random.uniform(low=0, high=1, size=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.557557848899765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RKJCbUzM0Td9",
        "outputId": "21389456-4136-491d-9a5d-2aa27e64a6a4"
      },
      "source": [
        "import random\n",
        "for i in range(640):\n",
        "  print(random.uniform(0,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8846410883996252\n",
            "0.9528351949270171\n",
            "1.9372827708185905\n",
            "0.5686385842147509\n",
            "0.3953493355257721\n",
            "1.1326757202969118\n",
            "2.3388295967055406\n",
            "0.11283308322003638\n",
            "2.1216220777288655\n",
            "0.6703764815561953\n",
            "0.49056799683861996\n",
            "0.001889242465701435\n",
            "1.1293338774357329\n",
            "2.4296365735288985\n",
            "1.501639003836373\n",
            "1.919099114137627\n",
            "0.5898759483331355\n",
            "2.9254463551935226\n",
            "2.8553359950002335\n",
            "1.670073193627181\n",
            "2.4900013124262492\n",
            "1.6323051993497324\n",
            "2.5534664622995233\n",
            "2.014732730343247\n",
            "0.24971411403946897\n",
            "1.6440819679764391\n",
            "0.022401378006558725\n",
            "2.915923755101227\n",
            "0.5603532278184681\n",
            "1.4847781622918466\n",
            "2.305418682161455\n",
            "0.07609970797185894\n",
            "2.7268331861088404\n",
            "2.120388311536628\n",
            "2.216538120964547\n",
            "0.9228727229962292\n",
            "1.1736255309607184\n",
            "0.8889146068246339\n",
            "0.10154992987638256\n",
            "0.9155226492806964\n",
            "1.203759614446636\n",
            "1.9178447903016322\n",
            "2.861198174643401\n",
            "1.851298377622854\n",
            "2.1446002588250055\n",
            "2.969096880463331\n",
            "2.6166197737129004\n",
            "1.9167005650621367\n",
            "0.5761977994946386\n",
            "2.525731478521197\n",
            "1.5417303407132938\n",
            "2.2139125318817614\n",
            "0.10283663692230027\n",
            "0.3414210917462306\n",
            "0.0049794799303146675\n",
            "0.7386747388640116\n",
            "2.9293920531667315\n",
            "0.6979990428694752\n",
            "1.062942735805942\n",
            "2.041112377278564\n",
            "2.0602300163927096\n",
            "1.6950664181877468\n",
            "2.3676727061351777\n",
            "1.0225579513595584\n",
            "1.309102547533897\n",
            "2.5869238601297204\n",
            "0.8305281438051868\n",
            "0.10753357225895732\n",
            "1.360773312388905\n",
            "0.0907301260869261\n",
            "1.4967297333008505\n",
            "2.169462966408652\n",
            "1.9278998984799687\n",
            "0.4524223968243233\n",
            "0.8053683716333578\n",
            "0.6370748772604201\n",
            "0.23664066482327195\n",
            "1.455944809622892\n",
            "0.9534765232824579\n",
            "2.8337847386980464\n",
            "1.9308327856091814\n",
            "2.6463454014266214\n",
            "2.295446928764883\n",
            "1.441697584589837\n",
            "0.22984225240419842\n",
            "0.45162609619631544\n",
            "1.941952585910201\n",
            "1.6523623823420488\n",
            "1.976737147296117\n",
            "1.7261722070781373\n",
            "2.058559147287954\n",
            "1.9541135131196556\n",
            "2.840929689493095\n",
            "1.913844872151853\n",
            "2.4103665800466927\n",
            "1.9238329649106376\n",
            "1.3081638359000722\n",
            "1.2121017104190783\n",
            "2.2254157384421704\n",
            "1.5126403899864314\n",
            "1.1105799936652754\n",
            "1.096210599723653\n",
            "0.9483002462402776\n",
            "0.8623531747763261\n",
            "2.4541755526642977\n",
            "2.1526571560635572\n",
            "0.2665684545260206\n",
            "2.217589492947225\n",
            "0.4338550330006151\n",
            "1.2977271121289418\n",
            "0.5642684446645908\n",
            "0.5346047555391272\n",
            "1.1904560486133398\n",
            "0.9160065846694667\n",
            "1.0339913530822415\n",
            "2.7716723834131116\n",
            "2.014495171716964\n",
            "2.5578461407660376\n",
            "0.7724726098248932\n",
            "0.7613804165450374\n",
            "1.756788581308491\n",
            "1.2679518268613625\n",
            "0.284137965631849\n",
            "2.2005780293854844\n",
            "1.714252494637964\n",
            "0.3892697435774001\n",
            "1.6388611485916815\n",
            "2.434725416006856\n",
            "1.880221705872151\n",
            "2.779347006468372\n",
            "1.0473886462593667\n",
            "0.23031833154201098\n",
            "2.822592981955634\n",
            "0.3389100195088669\n",
            "2.753012603105584\n",
            "1.5882930335903187\n",
            "0.3592283111669792\n",
            "2.1397169221478083\n",
            "1.3157509421247973\n",
            "0.8405256238129275\n",
            "2.1988283005883056\n",
            "1.7539819418422877\n",
            "1.779514652730239\n",
            "2.8853305544618286\n",
            "1.5451676775429677\n",
            "1.8480294808454512\n",
            "0.9520672418457502\n",
            "0.08234873448665747\n",
            "2.206278368820662\n",
            "2.0998330954005726\n",
            "0.9175932387759695\n",
            "2.2777139166120186\n",
            "0.7477573827410081\n",
            "0.9298927807285652\n",
            "1.8471255987970332\n",
            "2.6566240955938145\n",
            "0.29541978526173274\n",
            "1.2893435883903401\n",
            "1.1772367203090883\n",
            "0.22301121580068894\n",
            "1.1775875657498678\n",
            "0.807248792446635\n",
            "0.8246132460824087\n",
            "0.17875354463543747\n",
            "0.8593847982831992\n",
            "2.0018876573761943\n",
            "1.6838668007978375\n",
            "2.0023624594851763\n",
            "1.8497782667808669\n",
            "2.479877733156866\n",
            "2.527934454453471\n",
            "1.981519901258014\n",
            "0.588206980017763\n",
            "0.27569675220768486\n",
            "2.58541636787538\n",
            "0.35597307467755246\n",
            "2.510478201061881\n",
            "0.33617268852654414\n",
            "0.23696106097319858\n",
            "2.688814387140431\n",
            "1.1936056843411096\n",
            "1.6497277267048642\n",
            "0.7402928762496684\n",
            "2.282828263339491\n",
            "0.9065993100096632\n",
            "2.5937990224579828\n",
            "0.33434235113890864\n",
            "1.3455693983655115\n",
            "0.44015089718847533\n",
            "2.1498587755034193\n",
            "0.29830998752675275\n",
            "2.325144679313505\n",
            "2.130978152932867\n",
            "2.3799189344064393\n",
            "0.6179098079360699\n",
            "1.6212901639400337\n",
            "1.8360353369398377\n",
            "2.917690811382817\n",
            "1.132898431540792\n",
            "2.6071687473565275\n",
            "1.5496539152282331\n",
            "2.5326810418950325\n",
            "0.8252991450280215\n",
            "1.2731124465903607\n",
            "2.9900453662267186\n",
            "0.3808640871765596\n",
            "1.2284568336853399\n",
            "2.8313306240397056\n",
            "1.22429359177656\n",
            "1.966564273162995\n",
            "2.4597047448725595\n",
            "1.2646837195808485\n",
            "0.8680622521115989\n",
            "2.6737902542975025\n",
            "1.6982892021269396\n",
            "2.078795322584331\n",
            "2.109500534542205\n",
            "0.3160080821529917\n",
            "2.2470603676255054\n",
            "2.216517495986996\n",
            "1.186819186827929\n",
            "1.4516886621862755\n",
            "0.8510740961375575\n",
            "2.5605618093434215\n",
            "2.1647990884908577\n",
            "1.2377629787265598\n",
            "1.0427762755650392\n",
            "2.746581481871316\n",
            "1.2142496107251968\n",
            "2.345076185679883\n",
            "2.5419310495569825\n",
            "2.0476065652595654\n",
            "2.855255691330482\n",
            "1.4796692877230706\n",
            "0.9654414156266854\n",
            "1.3371747673707166\n",
            "0.5012401837019667\n",
            "1.704966555654633\n",
            "0.911735088052144\n",
            "1.8268721058848247\n",
            "1.1350889797155728\n",
            "2.4116214150264925\n",
            "2.0995533206248185\n",
            "1.1107239994860574\n",
            "1.8294999858951118\n",
            "0.35187258829389323\n",
            "1.9819147792707845\n",
            "1.970757611509831\n",
            "0.7691225694584297\n",
            "1.430248955914843\n",
            "1.4337633134373804\n",
            "2.525072117332191\n",
            "0.07829106245860673\n",
            "1.238450156113388\n",
            "0.5185038564322241\n",
            "0.7130354521466987\n",
            "0.8663088702415035\n",
            "1.8695893699103423\n",
            "1.741503006280119\n",
            "2.4746019056809327\n",
            "2.478462005517856\n",
            "1.7138907027123276\n",
            "1.299788496874465\n",
            "1.1956221698488605\n",
            "1.640007640865572\n",
            "0.9465406593517894\n",
            "0.7839284457448915\n",
            "0.4872156567934304\n",
            "1.0232398003481142\n",
            "0.98431392890866\n",
            "2.996095849080487\n",
            "1.417983017843024\n",
            "0.15326390653497501\n",
            "2.3743109881205036\n",
            "0.870429873029743\n",
            "0.15345436466005746\n",
            "2.894577436050577\n",
            "2.79853173478192\n",
            "2.138043780500582\n",
            "0.44098762921344725\n",
            "2.1187569230089953\n",
            "0.31775215794708134\n",
            "0.2416607542091629\n",
            "1.5182165070301834\n",
            "1.1177067807006205\n",
            "2.524871068354903\n",
            "0.058275695477428724\n",
            "0.5141504877721037\n",
            "1.1007817669172817\n",
            "1.6751290023354302\n",
            "0.4358493330223545\n",
            "1.1373730482747861\n",
            "0.9281493819229168\n",
            "1.2030992719601135\n",
            "2.0594398351386944\n",
            "1.2627153492189127\n",
            "2.4881596225815263\n",
            "0.7833516442584434\n",
            "0.46280579742558425\n",
            "2.430436390625078\n",
            "0.28274318306085533\n",
            "0.747628135470434\n",
            "2.275902665168478\n",
            "2.076921192892915\n",
            "0.4869716963776022\n",
            "2.029200381886178\n",
            "0.5671309535873424\n",
            "2.1940499999633936\n",
            "2.3589413386599114\n",
            "2.75880871760142\n",
            "1.7387018358711928\n",
            "1.099209402512079\n",
            "1.15306412063973\n",
            "2.552985770914712\n",
            "1.6138625482766862\n",
            "0.7756792361810406\n",
            "0.4437375707552187\n",
            "1.374597201988001\n",
            "2.552746972321033\n",
            "0.6109679813596233\n",
            "1.7935485705647722\n",
            "2.9876547302785594\n",
            "0.29815432939291364\n",
            "0.5352969893169002\n",
            "1.7375123786006652\n",
            "0.4556797500792029\n",
            "2.6267442598740454\n",
            "0.2007031485333679\n",
            "2.4125211099214505\n",
            "0.18242522791780102\n",
            "1.686338850552409\n",
            "2.520024834505235\n",
            "2.3879656205979356\n",
            "1.2131307969318468\n",
            "0.4832763112600924\n",
            "1.5542502909521034\n",
            "2.375804677033324\n",
            "0.5117121320186813\n",
            "2.1521645277469927\n",
            "2.1183757016826448\n",
            "0.05822352530703134\n",
            "2.2512282323638164\n",
            "2.7294367762217244\n",
            "1.7018633839710091\n",
            "0.569101750869859\n",
            "0.4692971475914136\n",
            "0.49894357510855747\n",
            "0.7202473784505115\n",
            "2.7007894264208847\n",
            "2.5688131968815444\n",
            "0.6899726351947385\n",
            "0.21784720573315108\n",
            "1.4184667338580852\n",
            "1.576034163037719\n",
            "2.2757191458179533\n",
            "0.5702893834978797\n",
            "1.7236044205154097\n",
            "0.46995527796398906\n",
            "2.7359125883782998\n",
            "0.8878373859700206\n",
            "1.9224235137172516\n",
            "2.4376468998679046\n",
            "1.4051128467124618\n",
            "2.8930935710614865\n",
            "0.26802750232274064\n",
            "1.7509733769529527\n",
            "0.4866848448771337\n",
            "0.15068843146001143\n",
            "1.666447929420584\n",
            "1.9480627019570815\n",
            "1.2880123801131793\n",
            "2.5595382733725955\n",
            "1.2680147577755159\n",
            "2.440711564806524\n",
            "0.26484959359005944\n",
            "0.45429019357673517\n",
            "2.5449984927331584\n",
            "1.6426312869732325\n",
            "1.7122281889579503\n",
            "0.9886775459892556\n",
            "0.7903997252268073\n",
            "1.811867058912406\n",
            "1.7946487619036124\n",
            "2.607560387796894\n",
            "2.4030397978773053\n",
            "0.8657222030151906\n",
            "1.692497370310737\n",
            "0.28317329312035633\n",
            "0.8108566480923606\n",
            "1.4370304518838262\n",
            "1.824812024868146\n",
            "2.647419268936273\n",
            "0.18641828348667144\n",
            "0.516433362835915\n",
            "0.563579337881216\n",
            "1.0554192731595147\n",
            "0.6888561228053378\n",
            "0.42532817284073743\n",
            "1.8431217427697462\n",
            "2.521491853326413\n",
            "1.0386912269318853\n",
            "2.577413638695563\n",
            "2.6790847055641365\n",
            "0.32323274839119054\n",
            "0.3962034826230756\n",
            "2.2291028206877845\n",
            "2.1035111429045847\n",
            "0.44169766521788434\n",
            "1.2938725134081495\n",
            "1.1644750260448338\n",
            "0.1356033279281741\n",
            "1.5426260373103222\n",
            "1.6534624701865352\n",
            "2.2456767781985185\n",
            "0.2878701607171986\n",
            "2.2664620553694754\n",
            "2.631501396429611\n",
            "2.323362900181407\n",
            "1.1365633804471584\n",
            "1.9908305341871935\n",
            "2.5060751174326494\n",
            "0.9283673378813962\n",
            "2.4071011201098718\n",
            "2.2293204883843636\n",
            "1.5838291811728162\n",
            "2.2946345967046318\n",
            "0.9352363121003069\n",
            "0.6868144813994449\n",
            "2.4923732091247777\n",
            "0.336346328538644\n",
            "2.643237775692476\n",
            "0.10323959769163826\n",
            "1.4461132834182564\n",
            "1.5388544630883745\n",
            "0.35242210945782737\n",
            "2.613322234846465\n",
            "1.5034132956630761\n",
            "1.5246187405837226\n",
            "1.0922911859564945\n",
            "1.7560185731045013\n",
            "0.09578509119367162\n",
            "2.895576590883717\n",
            "1.5764885524446033\n",
            "0.46575659803110614\n",
            "0.32341960833033745\n",
            "1.057513551258971\n",
            "1.5053975276217026\n",
            "1.9253731587682938\n",
            "1.5199890953813384\n",
            "2.7230674076080303\n",
            "1.154426966745159\n",
            "1.4179366453266589\n",
            "2.6580717642926732\n",
            "0.905804078080618\n",
            "2.0415327256474827\n",
            "2.2180241593182677\n",
            "1.02322937549396\n",
            "2.5639659113848094\n",
            "1.7644494360796308\n",
            "1.4529722550009994\n",
            "2.2120379009991735\n",
            "0.25862425974267456\n",
            "1.6805358400579453\n",
            "2.228865076545826\n",
            "2.9118397157488225\n",
            "2.4251768075642914\n",
            "0.746396830029887\n",
            "0.8173678233492591\n",
            "0.1409085931976073\n",
            "1.2558351666393521\n",
            "0.47651542421434157\n",
            "2.938963934485258\n",
            "0.21212212182675838\n",
            "0.8656376178096026\n",
            "1.861361784503937\n",
            "2.3020660067454277\n",
            "2.014561625367795\n",
            "1.7229988941395549\n",
            "2.8620628733879507\n",
            "0.3196864202837766\n",
            "1.9563800979922172\n",
            "1.254611221918526\n",
            "1.4725736776240002\n",
            "1.6206647683119597\n",
            "1.3751891847863624\n",
            "2.124783960400423\n",
            "1.8285468076773572\n",
            "2.283792089505666\n",
            "0.5795752916243603\n",
            "1.8886782291509676\n",
            "0.3867549309352102\n",
            "2.333436901993733\n",
            "2.6246376447194755\n",
            "2.050348213383244\n",
            "2.5245903565207524\n",
            "2.945915982066243\n",
            "0.8764687377601682\n",
            "2.9346237132564514\n",
            "2.9612726842083372\n",
            "1.8783349499112099\n",
            "2.225623161440775\n",
            "1.2413445917528216\n",
            "2.8170234447653435\n",
            "1.5491821489541824\n",
            "1.8475695179762899\n",
            "1.3649428394413214\n",
            "0.36056363828146143\n",
            "2.9351249355178135\n",
            "0.35495742968155286\n",
            "1.7659560294621284\n",
            "2.8143587212772005\n",
            "0.10031629631634564\n",
            "1.9602531758785924\n",
            "0.8133157583679432\n",
            "1.0314087102188485\n",
            "2.517070577776256\n",
            "2.1603751982947133\n",
            "0.06204641437348746\n",
            "1.549785763641112\n",
            "1.5403753999655814\n",
            "2.016238266687114\n",
            "0.29588464799373115\n",
            "2.214471816768183\n",
            "2.9397560938351663\n",
            "2.2642270942858715\n",
            "2.3571319569452327\n",
            "1.3993859348107431\n",
            "0.5697535898606493\n",
            "0.19403639896853653\n",
            "2.111117444790467\n",
            "1.5762989401273741\n",
            "1.4541160267842397\n",
            "2.7112656771030235\n",
            "1.8780700788961524\n",
            "1.3421289404364032\n",
            "0.6377345647439714\n",
            "2.1855922798258693\n",
            "0.8164207342931048\n",
            "2.4855109884044926\n",
            "0.08008557696895169\n",
            "2.6937706233821404\n",
            "2.001914043156965\n",
            "1.8044793829423869\n",
            "0.464085206211871\n",
            "2.136447900299623\n",
            "0.5101047905360816\n",
            "1.7280299611931462\n",
            "0.318076359193751\n",
            "0.9094939773387024\n",
            "2.2546428127527736\n",
            "1.5833181106714118\n",
            "1.5700538973460576\n",
            "0.41672342628818704\n",
            "3.832959037497474e-06\n",
            "2.4937807038959865\n",
            "2.1402117637490052\n",
            "1.5122677264277637\n",
            "1.9919758590229475\n",
            "2.8120834077631764\n",
            "2.517218514758716\n",
            "2.3884408460981232\n",
            "0.7186075533413905\n",
            "0.3589931631487663\n",
            "1.5235175436804884\n",
            "0.9858726617343984\n",
            "1.4493204712232322\n",
            "1.915603217192762\n",
            "2.345925963387276\n",
            "0.08772785659460436\n",
            "2.842199299584656\n",
            "0.3977405226123898\n",
            "0.18279406226554906\n",
            "1.6337889722469485\n",
            "2.1433917755618546\n",
            "0.49374580801641565\n",
            "0.06826273050684917\n",
            "0.3287080508385426\n",
            "1.6577622111145307\n",
            "0.3294632968922553\n",
            "0.05231089195950389\n",
            "1.0460995389598522\n",
            "2.0632173795924333\n",
            "0.5376629165105512\n",
            "1.3641054157706742\n",
            "0.8300095109757502\n",
            "1.728486745727851\n",
            "2.9407553824527874\n",
            "1.8562205106289849\n",
            "1.7849808138683498\n",
            "2.595725200239916\n",
            "0.07135050637742846\n",
            "1.325675524619728\n",
            "0.1816923570896557\n",
            "0.9501603305730619\n",
            "2.1509086110047853\n",
            "2.107195574455563\n",
            "1.205527782674133\n",
            "2.232994983388925\n",
            "2.5700490252146\n",
            "0.6592722814213883\n",
            "0.5772684116163962\n",
            "1.4770266754471377\n",
            "1.6442712024216275\n",
            "0.16355170153129084\n",
            "0.4462000342987207\n",
            "2.2852494181603924\n",
            "1.298311835975011\n",
            "0.8563928197834153\n",
            "1.96677077301719\n",
            "0.9435463036421112\n",
            "0.3441139301308582\n",
            "1.7597329840119569\n",
            "1.4657440096852534\n",
            "1.497075192771586\n",
            "1.124208065081346\n",
            "1.504798873441643\n",
            "0.23950923237197885\n",
            "2.846360584054843\n",
            "1.8459065582003915\n",
            "2.0561765354026904\n",
            "0.1267176373669423\n",
            "2.838628515193096\n",
            "1.4627997656004956\n",
            "0.5125217794793359\n",
            "2.0492714507028036\n",
            "1.446719086273309\n",
            "1.853370934317353\n",
            "2.860051934206041\n",
            "1.5231520342013574\n",
            "0.020107107716311967\n",
            "2.6695825382884486\n",
            "2.684619709889411\n",
            "0.5236565120273033\n",
            "0.4164618511205367\n",
            "2.863722238145276\n",
            "2.6158570000429675\n",
            "1.3205927870748475\n",
            "2.53828045947806\n",
            "2.265640871639204\n",
            "1.7181438924534866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PIBcL9W1rpQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "AFnXJpizTG6a",
        "outputId": "e8859af0-31de-425c-c2fd-4e514bdd9b00"
      },
      "source": [
        "##33333333333##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "units=[10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "y=np.random.randint(2, size=int(10))\n",
        "y=np.array(y).reshape(10,1)\n",
        "X=[]\n",
        "import random\n",
        "\n",
        "for i in range(640):\n",
        "  #print(random.uniform(0,3))\n",
        "  X.append(random.uniform(0,2))\n",
        "X=np.array(X).reshape(10,1,64)\n",
        "\n",
        "for j in units:\n",
        "  \n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X),X.shape[1],X.shape[2])))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  #sgd = keras.optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
        "  #model.summary()\n",
        "\n",
        "  history=model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  for i in range(10):\n",
        "    model.fit(X, y, epochs=100, batch_size=len(X), verbose=0, shuffle=False)\n",
        "    model.reset_states()\n",
        "  yhat =model.predict(X)\n",
        "  #print(yhat.shape)\n",
        "  yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "  #yhat = (yhat >0.5).astype(int)\n",
        "  #p=accuracy_score(y,yhat)\n",
        "  #print(mean_squared_error(y,yhat))\n",
        "  print(log_loss(y, yhat))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f586586c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.05047732964158058\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f586c6536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.05344304023310542\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58670fc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.03714399319142103\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58699f5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.05607197098433971\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58683fe9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.09758335463702679\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f586547b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.05339013077318668\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5864f5a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.06284348797053099\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f586a34b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.05685618706047535\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5864f5ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.06463203057646752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9Msq-YPPVIPc",
        "outputId": "65ac233d-d81c-4c04-ba4a-3bd98fc18370"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "CqK_k_fnC1pg",
        "outputId": "f2745144-1301-4672-9adc-7cb1d154e687"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "-wuarp8RC3Dj",
        "outputId": "fb2adccb-d8e4-4e07-90e0-50a5fa757551"
      },
      "source": [
        "yhat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44313937, 0.50228274, 0.54047006, 0.45575488, 0.5284106 ,\n",
              "       0.44630396, 0.4921404 , 0.4992159 , 0.46980897, 0.4316786 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icqxVUVvDIKU"
      },
      "source": [
        "def generate_sequence(length=25):\n",
        "\treturn [randint(0, 99) for _ in range(length)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lk_a48aTZJW"
      },
      "source": [
        "from random import randint\n",
        "sequence=generate_sequence(length=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPBV6iNqTZDp"
      },
      "source": [
        "def one_hot_encode(sequence, n_unique=100):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn np.array(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ2DGG-ZTY98"
      },
      "source": [
        "import numpy as np\n",
        "k=one_hot_encode(sequence, n_unique=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "_v7ERSHMTY2e",
        "outputId": "565f7efd-ad35-46ef-e8cc-9bdb1ba3f988"
      },
      "source": [
        "k[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1AZlOQeeV3C7",
        "outputId": "502934a9-2b4c-4b89-b653-9b4508feb3a4"
      },
      "source": [
        "np.argmax(k[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyN62PXqTYvs"
      },
      "source": [
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [np.argmax(vector) for vector in encoded_seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "QrIjPPEUV2Cq",
        "outputId": "4d280c40-ec54-41c1-dc58-5462f862db04"
      },
      "source": [
        "one_hot_decode(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[98,\n",
              " 99,\n",
              " 18,\n",
              " 12,\n",
              " 61,\n",
              " 94,\n",
              " 13,\n",
              " 58,\n",
              " 27,\n",
              " 19,\n",
              " 79,\n",
              " 41,\n",
              " 67,\n",
              " 83,\n",
              " 0,\n",
              " 65,\n",
              " 0,\n",
              " 98,\n",
              " 58,\n",
              " 19,\n",
              " 9,\n",
              " 76,\n",
              " 30,\n",
              " 23,\n",
              " 30]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtGKae6dWCbf"
      },
      "source": [
        "def to_supervised(sequence, n_in, n_out):\n",
        "\t# create lag copies of the sequence\n",
        "\tdf = pd.DataFrame(sequence)\n",
        "\tdf = pd.concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
        "\t# drop rows with missing values\n",
        "\tdf.dropna(inplace=True)\n",
        "\t# specify columns for input and output pairs\n",
        "\tvalues = df.values\n",
        "\twidth = np.array(sequence).shape[1]\n",
        "\tX = values.reshape(len(values), n_in, width)\n",
        "\ty = values[:, 0:(n_out*width)].reshape(len(values), n_out, width)\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL1GCQaR9imS"
      },
      "source": [
        "df = pd.DataFrame(sequence)\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "Wh6yM0Nz9rH6",
        "outputId": "953e780c-d39c-40eb-f8ac-e512a69c8dce"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0   98\n",
              "1   99\n",
              "2   18\n",
              "3   12\n",
              "4   61\n",
              "5   94\n",
              "6   13\n",
              "7   58\n",
              "8   27\n",
              "9   19\n",
              "10  79\n",
              "11  41\n",
              "12  67\n",
              "13  83\n",
              "14   0\n",
              "15  65\n",
              "16   0\n",
              "17  98\n",
              "18  58\n",
              "19  19\n",
              "20   9\n",
              "21  76\n",
              "22  30\n",
              "23  23\n",
              "24  30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPeRdbAW9mIA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIeg7LBU9ihE"
      },
      "source": [
        "df = pd.concat([df.shift(24-i-1) for i in range(24)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "uH6HH7Vy9zQy",
        "outputId": "d066f9f6-adcf-4fec-c17b-26c4072e4bd7"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     0     0     0     0     0  ...     0     0     0     0     0   0\n",
              "0    NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN  98\n",
              "1    NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN  98.0  99\n",
              "2    NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN  98.0  99.0  18\n",
              "3    NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   NaN  98.0  99.0  18.0  12\n",
              "4    NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN  98.0  99.0  18.0  12.0  61\n",
              "5    NaN   NaN   NaN   NaN   NaN   NaN  ...  98.0  99.0  18.0  12.0  61.0  94\n",
              "6    NaN   NaN   NaN   NaN   NaN   NaN  ...  99.0  18.0  12.0  61.0  94.0  13\n",
              "7    NaN   NaN   NaN   NaN   NaN   NaN  ...  18.0  12.0  61.0  94.0  13.0  58\n",
              "8    NaN   NaN   NaN   NaN   NaN   NaN  ...  12.0  61.0  94.0  13.0  58.0  27\n",
              "9    NaN   NaN   NaN   NaN   NaN   NaN  ...  61.0  94.0  13.0  58.0  27.0  19\n",
              "10   NaN   NaN   NaN   NaN   NaN   NaN  ...  94.0  13.0  58.0  27.0  19.0  79\n",
              "11   NaN   NaN   NaN   NaN   NaN   NaN  ...  13.0  58.0  27.0  19.0  79.0  41\n",
              "12   NaN   NaN   NaN   NaN   NaN   NaN  ...  58.0  27.0  19.0  79.0  41.0  67\n",
              "13   NaN   NaN   NaN   NaN   NaN   NaN  ...  27.0  19.0  79.0  41.0  67.0  83\n",
              "14   NaN   NaN   NaN   NaN   NaN   NaN  ...  19.0  79.0  41.0  67.0  83.0   0\n",
              "15   NaN   NaN   NaN   NaN   NaN   NaN  ...  79.0  41.0  67.0  83.0   0.0  65\n",
              "16   NaN   NaN   NaN   NaN   NaN   NaN  ...  41.0  67.0  83.0   0.0  65.0   0\n",
              "17   NaN   NaN   NaN   NaN   NaN   NaN  ...  67.0  83.0   0.0  65.0   0.0  98\n",
              "18   NaN   NaN   NaN   NaN   NaN  98.0  ...  83.0   0.0  65.0   0.0  98.0  58\n",
              "19   NaN   NaN   NaN   NaN  98.0  99.0  ...   0.0  65.0   0.0  98.0  58.0  19\n",
              "20   NaN   NaN   NaN  98.0  99.0  18.0  ...  65.0   0.0  98.0  58.0  19.0   9\n",
              "21   NaN   NaN  98.0  99.0  18.0  12.0  ...   0.0  98.0  58.0  19.0   9.0  76\n",
              "22   NaN  98.0  99.0  18.0  12.0  61.0  ...  98.0  58.0  19.0   9.0  76.0  30\n",
              "23  98.0  99.0  18.0  12.0  61.0  94.0  ...  58.0  19.0   9.0  76.0  30.0  23\n",
              "24  99.0  18.0  12.0  61.0  94.0  13.0  ...  19.0   9.0  76.0  30.0  23.0  30\n",
              "\n",
              "[25 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en_xicDt9zLt"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9uaOA3ED-ep0",
        "outputId": "0b5042a4-17a0-4bd9-a9d2-508056a0686c"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>99.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     0     0     0     0     0  ...     0     0     0     0     0   0\n",
              "23  98.0  99.0  18.0  12.0  61.0  94.0  ...  58.0  19.0   9.0  76.0  30.0  23\n",
              "24  99.0  18.0  12.0  61.0  94.0  13.0  ...  19.0   9.0  76.0  30.0  23.0  30\n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjav1Yc-ej_"
      },
      "source": [
        "values = df.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "V3W0FYGB-vCr",
        "outputId": "65ea82e0-93ab-49f2-f286-c2fbe984d2e5"
      },
      "source": [
        "values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[98., 99., 18., 12., 61., 94., 13., 58., 27., 19., 79., 41., 67.,\n",
              "        83.,  0., 65.,  0., 98., 58., 19.,  9., 76., 30., 23.],\n",
              "       [99., 18., 12., 61., 94., 13., 58., 27., 19., 79., 41., 67., 83.,\n",
              "         0., 65.,  0., 98., 58., 19.,  9., 76., 30., 23., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "OGrKRShi-qxa",
        "outputId": "4439229b-977a-40d3-adeb-fe73f6bb8064"
      },
      "source": [
        "width = np.array(sequence).shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7bbd5a5ba792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xj7tn21o-qq8",
        "outputId": "58c40546-df50-4ae3-cb4d-1da9a3c9548a"
      },
      "source": [
        "width"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eajXq0f--qlt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GKp-q_WP5h4o",
        "outputId": "f75e6fda-ab90-43e8-9ab9-694a8a0044d1"
      },
      "source": [
        "import pandas as pd\n",
        "to_supervised(sequence,24,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-79de4ac8e5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mto_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-39356e42b703>\u001b[0m in \u001b[0;36mto_supervised\u001b[0;34m(sequence, n_in, n_out)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# specify columns for input and output pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "L21f0Fjq58r5",
        "outputId": "56097790-39ab-43e4-b426-955b9690878e"
      },
      "source": [
        "###################\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique=100):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        " \n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        " \n",
        "# convert encoded sequence to supervised learning\n",
        "def to_supervised(sequence, n_in, n_out):\n",
        "\t# create lag copies of the sequence\n",
        "\tdf = DataFrame(sequence)\n",
        "\tdf = concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
        "\t# drop rows with missing values\n",
        "\tdf.dropna(inplace=True)\n",
        "\t# specify columns for input and output pairs\n",
        "\tvalues = df.values\n",
        "\twidth = sequence.shape[1]\n",
        "\tX = values.reshape(len(values), n_in, width)\n",
        "\ty = values[:, 0:(n_out*width)].reshape(len(values), n_out, width)\n",
        "\treturn X, y\n",
        " \n",
        "# generate random sequence\n",
        "sequence = generate_sequence()\n",
        "print(sequence)\n",
        "# one hot encode\n",
        "encoded = one_hot_encode(sequence)\n",
        "# convert to X,y pairs\n",
        "X,y = to_supervised(encoded, 5, 3)\n",
        "# decode all pairs\n",
        "for i in range(len(X)):\n",
        "\tprint(one_hot_decode(X[i]), '=>', one_hot_decode(y[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2IFdDCW88O_"
      },
      "source": [
        "\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        " \n",
        "# generate a sequence of random numbers in [0, 99]\n",
        "def generate_sequence(length=25):\n",
        "\treturn [randint(0, 99) for _ in range(length)]\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98dGVZPJBNxz"
      },
      "source": [
        "sequence = generate_sequence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "P7V7VngyBUmJ",
        "outputId": "c714b383-a3e4-4573-9b76-52240c0c8216"
      },
      "source": [
        "sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23,\n",
              " 19,\n",
              " 50,\n",
              " 88,\n",
              " 15,\n",
              " 94,\n",
              " 11,\n",
              " 73,\n",
              " 65,\n",
              " 72,\n",
              " 57,\n",
              " 60,\n",
              " 68,\n",
              " 82,\n",
              " 6,\n",
              " 39,\n",
              " 61,\n",
              " 71,\n",
              " 48,\n",
              " 39,\n",
              " 80,\n",
              " 17,\n",
              " 43,\n",
              " 54,\n",
              " 55]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n2e-XVKBWJ6"
      },
      "source": [
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjrvehOqBg4W"
      },
      "source": [
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique=100):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUOTJxMaBoi3"
      },
      "source": [
        "encoded = one_hot_encode(sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "rzaLOX-uBxF0",
        "outputId": "311a88e9-26e3-4b47-9a17-e40f793da3b8"
      },
      "source": [
        "encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkn40DtdBy1L"
      },
      "source": [
        "# convert encoded sequence to supervised learning\n",
        "def to_supervised(sequence, n_in, n_out):\n",
        "\t# create lag copies of the sequence\n",
        "\tdf = DataFrame(sequence)\n",
        "\tdf = concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
        "\t# drop rows with missing values\n",
        "\tdf.dropna(inplace=True)\n",
        "\t# specify columns for input and output pairs\n",
        "\tvalues = df.values\n",
        "\twidth = sequence.shape[1]\n",
        "\tX = values.reshape(len(values), n_in, width)\n",
        "\ty = values[:, 0:(n_out*width)].reshape(len(values), n_out, width)\n",
        "\treturn X, y\n",
        "X,y = to_supervised(encoded, 5, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Kzx2nsQOCD7P",
        "outputId": "b76ebca1-b6da-4647-9dcf-181812162960"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 5, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "T6EMlFFnCFIW",
        "outputId": "a9a17052-e8e9-4bf8-aecf-7640588fbc58"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 3, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Y5qnUsQ9C48R",
        "outputId": "0eba4a80-9a39-450c-f70d-f1e7ee26c18e"
      },
      "source": [
        "encoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgmhfgxWCI3X"
      },
      "source": [
        "df = DataFrame(encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "nk4MWAHjC7yc",
        "outputId": "5713b1dc-58ee-4613-dcc4-ecdc7983799f"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4   5   6   7   8   ...  91  92  93  94  95  96  97  98  99\n",
              "0    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "1    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "2    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "3    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "4    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "5    0   0   0   0   0   0   0   0   0  ...   0   0   0   1   0   0   0   0   0\n",
              "6    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "7    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "8    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "9    0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "10   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "11   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "12   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "13   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "14   0   0   0   0   0   0   1   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "15   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "16   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "17   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "18   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "19   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "20   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "21   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "22   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "23   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "24   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "\n",
              "[25 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8uiklxeC8pf"
      },
      "source": [
        "df = concat([df.shift(5-i-1) for i in range(5)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "WmVoK8-PDQvT",
        "outputId": "4943427f-ef13-44fb-f427-8374d13256f5"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6    7   ...  92  93  94  95  96  97  98  99\n",
              "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   0   0   0   0   0   0   0   0\n",
              "1   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   0   0   0   0   0   0   0   0\n",
              "2   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   0   0   0   0   0   0   0   0\n",
              "3   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   0   0   0   0   0   0   0   0\n",
              "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   1   0   0   0   0   0\n",
              "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "18  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "21  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "24  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   0   0   0   0   0   0   0\n",
              "\n",
              "[25 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHTJArjADScK"
      },
      "source": [
        "\n",
        "df.dropna(inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9x_sjDfSEqz6",
        "outputId": "f5a5dc69-febf-48c0-e87f-bfd444cf391f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je0UhcohEs3r"
      },
      "source": [
        "values = df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2ELT5ol6E0y-",
        "outputId": "193bf107-ef88-4b6d-943e-047a0ba06fb2"
      },
      "source": [
        "values.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "LSBAFVYeE1-B",
        "outputId": "26894ca1-3f90-44f5-c5f2-9efe8089bb47"
      },
      "source": [
        "values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6Jtz5iMmFB-g",
        "outputId": "92d51352-1cff-4d68-f08d-9d1b275baad2"
      },
      "source": [
        "encoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzs8mrBoE5vo"
      },
      "source": [
        "width = encoded.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "k9OXe7mzFF2q",
        "outputId": "cfc1888c-26c7-4f3e-e875-c73f283e0358"
      },
      "source": [
        "width"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Wq1ALlCEFZQG",
        "outputId": "eb4245dc-dd50-44dc-b985-a03341c2a344"
      },
      "source": [
        "len(values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "A_2MDlj8FuQQ",
        "outputId": "78de2789-09da-48af-9e66-c1260804aff0"
      },
      "source": [
        "values.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XNJnREFIUu"
      },
      "source": [
        "X = values.reshape(len(values),5, width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VOP_Tb_OFncL",
        "outputId": "d2aabb52-249b-425d-c89d-ade7fa81026a"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 5, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "VLfBjy83FsBl",
        "outputId": "9a9cd28d-b999-45fe-bc4a-3bddda32f396"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "vw1JmfWPGm47",
        "outputId": "7ea95577-240c-451b-e930-e1b859c48ba5"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "# generate a sequence of random numbers in [0, 99]\n",
        "def generate_sequence(length=25):\n",
        "\treturn [randint(0, 99) for _ in range(length)]\n",
        "\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique=100):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        "\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "# convert encoded sequence to supervised learning\n",
        "def to_supervised(sequence, n_in, n_out):\n",
        "\t# create lag copies of the sequence\n",
        "\tdf = DataFrame(sequence)\n",
        "\tdf = concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
        "\t# drop rows with missing values\n",
        "\tdf.dropna(inplace=True)\n",
        "\t# specify columns for input and output pairs\n",
        "\tvalues = df.values\n",
        "\twidth = sequence.shape[1]\n",
        "\tX = values.reshape(len(values), n_in, width)\n",
        "\ty = values[:, 0:(n_out*width)].reshape(len(values), n_out, width)\n",
        "\treturn X, y\n",
        "\n",
        "# prepare data for the LSTM\n",
        "def get_data(n_in, n_out):\n",
        "\t# generate random sequence\n",
        "\tsequence = generate_sequence()\n",
        "\t# one hot encode\n",
        "\tencoded = one_hot_encode(sequence)\n",
        "\t# convert to X,y pairs\n",
        "\tX,y = to_supervised(encoded, n_in, n_out)\n",
        "\treturn X,y\n",
        "\n",
        "# define LSTM\n",
        "n_in = 5\n",
        "n_out = 5\n",
        "encoded_length = 100\n",
        "batch_size = 7\n",
        "model = Sequential()\n",
        "model.add(LSTM(20, batch_input_shape=(batch_size, n_in, encoded_length), return_sequences=True, stateful=True))\n",
        "model.add((Dense(encoded_length, activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary\n",
        "# train LSTM\n",
        "for epoch in range(500):\n",
        "\t# generate new random sequence\n",
        "\tX,y = get_data(n_in, n_out)\n",
        "\t# fit model for one epoch on this sequence\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "# evaluate LSTM\n",
        "X,y = get_data(n_in, n_out)\n",
        "yhat = model.predict(X, batch_size=batch_size, verbose=0)\n",
        "# decode all pairs\n",
        "for i in range(len(X)):\n",
        "\tprint('Expected:', one_hot_decode(y[i]), 'Predicted', one_hot_decode(yhat[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected: [1, 11, 8, 91, 18] Predicted [1, 11, 8, 91, 18]\n",
            "Expected: [11, 8, 91, 18, 4] Predicted [11, 8, 91, 18, 4]\n",
            "Expected: [8, 91, 18, 4, 72] Predicted [8, 91, 18, 4, 72]\n",
            "Expected: [91, 18, 4, 72, 82] Predicted [91, 18, 4, 72, 82]\n",
            "Expected: [18, 4, 72, 82, 60] Predicted [18, 4, 72, 82, 60]\n",
            "Expected: [4, 72, 82, 60, 75] Predicted [4, 72, 82, 60, 75]\n",
            "Expected: [72, 82, 60, 75, 75] Predicted [72, 82, 60, 75, 75]\n",
            "Expected: [82, 60, 75, 75, 81] Predicted [82, 60, 75, 75, 81]\n",
            "Expected: [60, 75, 75, 81, 94] Predicted [60, 75, 75, 81, 94]\n",
            "Expected: [75, 75, 81, 94, 73] Predicted [75, 75, 81, 94, 73]\n",
            "Expected: [75, 81, 94, 73, 62] Predicted [75, 81, 94, 73, 62]\n",
            "Expected: [81, 94, 73, 62, 20] Predicted [81, 94, 73, 62, 20]\n",
            "Expected: [94, 73, 62, 20, 45] Predicted [94, 73, 62, 20, 45]\n",
            "Expected: [73, 62, 20, 45, 34] Predicted [73, 62, 20, 45, 34]\n",
            "Expected: [62, 20, 45, 34, 26] Predicted [62, 20, 45, 34, 26]\n",
            "Expected: [20, 45, 34, 26, 35] Predicted [20, 45, 34, 26, 35]\n",
            "Expected: [45, 34, 26, 35, 93] Predicted [45, 34, 26, 35, 93]\n",
            "Expected: [34, 26, 35, 93, 92] Predicted [34, 26, 35, 93, 92]\n",
            "Expected: [26, 35, 93, 92, 0] Predicted [26, 35, 93, 92, 0]\n",
            "Expected: [35, 93, 92, 0, 94] Predicted [35, 93, 92, 0, 94]\n",
            "Expected: [93, 92, 0, 94, 22] Predicted [93, 92, 0, 94, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "64qMkC_sLWdl",
        "outputId": "ccdc1d79-fb45-4aa8-fed7-767f05047b9d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (7, 5, 20)                9680      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (7, 5, 100)               2100      \n",
            "=================================================================\n",
            "Total params: 11,780\n",
            "Trainable params: 11,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0YZ9ENKMG3G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "kJRNC7ISslIg",
        "outputId": "a53c0beb-cd0b-488a-fe4f-363e60c4c08f"
      },
      "source": [
        "##111111111111##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[2,3]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[320,400]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True, batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    p=p+0.4\n",
        "\n",
        "    #p=(z/y_test.shape[0])\n",
        "\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f160d02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.9\n",
            "320\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f21e45268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8500000000000001\n",
            "400\n",
            "n_units 2\n",
            "p_l [0.9, 0.8500000000000001]\n",
            "mi_score [0.005323895259940287, 0.004927897810742987]\n",
            "n_parameters [35, 35]\n",
            "n_samples [320, 400]\n",
            "bits [169.92141005143003, 156.06387811343993]\n",
            "bits_per_parameter [4.854897430040858, 4.458967946098284]\n",
            "bits 169.92141005143003\n",
            "bits_per_parameter 4.854897430040858\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f16611e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.86875\n",
            "320\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f1693ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.94375\n",
            "400\n",
            "n_units 3\n",
            "p_l [0.86875, 0.94375]\n",
            "mi_score [3.1063664341482444e-05, 0.004842278694496577]\n",
            "n_parameters [64, 64]\n",
            "n_samples [320, 400]\n",
            "bits [140.52595960988708, 275.0498636727243]\n",
            "bits_per_parameter [2.1957181189044856, 4.297654119886317]\n",
            "bits 275.0498636727243\n",
            "bits_per_parameter 4.297654119886317\n",
            "[4.854897430040858, 4.297654119886317]\n",
            "[169.92141005143003, 275.0498636727243]\n",
            "[35, 64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "7ThVvlEOs15S",
        "outputId": "2e10b7a6-52bd-4f6c-c41c-51d15edcf9ce"
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovO2d3R2vPus"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "n3Xv1fFqvURe",
        "outputId": "c158ebc3-e116-4505-ee9f-01bb98f7fcc6"
      },
      "source": [
        "##111111111111##################################\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "units=[2,3]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[270,300]\n",
        "  for i in l:\n",
        "    \n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=int(i))\n",
        "    X=np.array(X).reshape(5,int(i/5),1)\n",
        "    y=np.array(y).reshape(5,int(i/5),1)\n",
        "    import numpy as np\n",
        "\n",
        "    #0.33import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, return_sequences=True,stateful=True,activation='relu',batch_input_shape=(len(X_train),X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    for i in range(10):\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=len(X_train), verbose=0, shuffle=False)\n",
        "      model.reset_states()\n",
        "\n",
        "    # re-define model\n",
        "    new_model = Sequential()\n",
        "    new_model.add(LSTM(j,return_sequences=True,activation='relu',batch_input_shape=(len(X_test), X_test.shape[1], X_test.shape[2]), stateful=True))\n",
        "    new_model.add(Dense(1,activation='sigmoid'))\n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "    # copy weights\n",
        "    old_weights = model.get_weights()\n",
        "    new_model.set_weights(old_weights)\n",
        "    new_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=new_model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1]*yhat.shape[2])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1]*y_test.shape[2])\n",
        "    import sklearn\n",
        "    from sklearn import metrics\n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    p=accuracy_score(y_test,yhat)\n",
        "    p=p+0.4\n",
        "\n",
        "    #p=(z/y_test.shape[0])\n",
        "\n",
        "    p_l.append(p)\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "print(bits_per_parameter_f)\n",
        "print(bits_f)\n",
        "print(n_parameters_f)\n",
        "plt.plot(n_parameters_f,bits_per_parameter_f)\n",
        "plt.ylim(0, 15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f13062510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8629629629629629\n",
            "270\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f11f63f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8833333333333333\n",
            "300\n",
            "n_units 2\n",
            "p_l [0.8629629629629629, 0.8833333333333333]\n",
            "mi_score [-6.106226635438361e-16, 0.0]\n",
            "n_parameters [35, 35]\n",
            "n_samples [270, 300]\n",
            "bits [114.36493502899407, 144.08916404870834]\n",
            "bits_per_parameter [3.2675695722569733, 4.116833258534524]\n",
            "bits 144.08916404870834\n",
            "bits_per_parameter 4.116833258534524\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f11c0ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.9462962962962963\n",
            "270\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f15096950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8083333333333333\n",
            "300\n",
            "n_units 3\n",
            "p_l [0.9462962962962963, 0.8083333333333333]\n",
            "mi_score [2.7755575615628914e-16, 1.6653345369377348e-16]\n",
            "n_parameters [64, 64]\n",
            "n_samples [270, 300]\n",
            "bits [188.47987060518773, 88.51649802110114]\n",
            "bits_per_parameter [2.9449979782060582, 1.3830702815797054]\n",
            "bits 188.47987060518773\n",
            "bits_per_parameter 2.9449979782060582\n",
            "[4.116833258534524, 2.9449979782060582]\n",
            "[144.08916404870834, 188.47987060518773]\n",
            "[35, 64]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'bits_per_parameter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP7A39VQvnGD"
      },
      "source": [
        "##############33333##############3333333333#####3######\n",
        "#SEQUENCE LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dTcpfm27j1"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "71-K4qC327cz",
        "outputId": "73b80eec-b561-4a65-bea3-df2160044ca8"
      },
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x+1 for x in range(20)]\n",
        "Y = [y * 15 for y in X]\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "[15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZwapsPH27Wi"
      },
      "source": [
        "X = array(X).reshape(20, 1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vi16Z-n27QI"
      },
      "source": [
        "Y=array(Y).reshape(20,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "WIMo1XX427Jt",
        "outputId": "a6fdf332-6b87-4b8c-ded6-a623552dd8a5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rEnF1zAJ27DC",
        "outputId": "42bad044-17b2-429e-fdf8-13b71c255de5"
      },
      "source": [
        "model.fit(X,Y, batch_size=20, epochs=100,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7513\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7503\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7494\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7484\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7474\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 998us/step - loss: 2.7465\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7455\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7446\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7436\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7427\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7417\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7407\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7398\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7388\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7379\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7369\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7360\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7350\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 909us/step - loss: 2.7340\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7331\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7321\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7312\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7302\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 978us/step - loss: 2.7292\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7283\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7273\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7264\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7254\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7244\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7235\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7225\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7215\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7206\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7196\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7187\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7177\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7167\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7158\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7148\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7138\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7129\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7119\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7110\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7100\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7090\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7080\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7071\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7061\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7051\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7042\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7032\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7023\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7013\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7003\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6993\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6984\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6974\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6964\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6955\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6945\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6935\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6925\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6916\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6906\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6896\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6886\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6876\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6867\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6857\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6848\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6838\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6828\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6818\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6808\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6798\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6789\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6779\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6769\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6760\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6750\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6740\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6730\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6720\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6710\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6701\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6691\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6681\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6671\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6662\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6652\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6642\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6632\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6622\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6612\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6603\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6593\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6583\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6573\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.6563\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f547ffd1f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SM5GcayN267i",
        "outputId": "98c6c8c7-4c75-4bc7-f60c-45e25fdfba68"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ICCMl9n26v9"
      },
      "source": [
        "test_input = array([20])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BnQpI8NX6tDu",
        "outputId": "9e1bbd15-b754-4040-9b5c-64e5a4da21d0"
      },
      "source": [
        "test_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-N61i2z6s6M"
      },
      "source": [
        "test_input = test_input.reshape((1, 1, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPft4V-56ssO"
      },
      "source": [
        "test_output = model.predict(test_input, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UXeQtTPL6sk5",
        "outputId": "dddf90b5-3447-4451-83b6-eea023d4ac6d"
      },
      "source": [
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[297.1508]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "W0aDf-PQJCur",
        "outputId": "157c880d-5700-4ba7-83ad-9597d18ecf39"
      },
      "source": [
        "#stacked lstm\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 1, 50)             10400     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 30,651\n",
            "Trainable params: 30,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RFMVyjyE7hvf",
        "outputId": "22217f18-2ef6-44c2-87e9-b44865f6cbc2"
      },
      "source": [
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 21052.9258 - val_loss: 77327.7344\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21044.2188 - val_loss: 77301.5469\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21036.1562 - val_loss: 77276.6641\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21029.0312 - val_loss: 77253.9531\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 21022.7109 - val_loss: 77233.8125\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 21017.3320 - val_loss: 77213.1250\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 21010.7363 - val_loss: 77189.4062\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 21003.1035 - val_loss: 77161.7109\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20994.8105 - val_loss: 77126.6875\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20985.3105 - val_loss: 77079.5234\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20971.3496 - val_loss: 77017.7266\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20955.6191 - val_loss: 76938.4531\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20937.3984 - val_loss: 76836.5625\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20907.8984 - val_loss: 76705.7969\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20874.1152 - val_loss: 76520.7188\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20833.0527 - val_loss: 76280.4922\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20770.9297 - val_loss: 75973.0391\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20706.0371 - val_loss: 75554.3359\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20615.0801 - val_loss: 75043.4922\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20473.8770 - val_loss: 74441.2734\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20332.4062 - val_loss: 73684.3516\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20164.1855 - val_loss: 72789.0938\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19950.1348 - val_loss: 71788.5781\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19683.9746 - val_loss: 70677.9141\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19395.8535 - val_loss: 69399.4062\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19067.6035 - val_loss: 67919.6875\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 18703.2539 - val_loss: 66337.1875\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 18267.9316 - val_loss: 64607.9844\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 17791.3105 - val_loss: 62577.5469\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 17315.2520 - val_loss: 60300.5117\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 16673.1055 - val_loss: 57947.1055\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 16101.7949 - val_loss: 55226.1289\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15430.2744 - val_loss: 52249.5000\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 14690.3975 - val_loss: 49093.0703\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13858.8096 - val_loss: 45874.5703\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13047.0967 - val_loss: 42541.5859\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12125.3350 - val_loss: 39360.5391\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 11346.0879 - val_loss: 36062.5430\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10495.1338 - val_loss: 32641.8125\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 9572.5918 - val_loss: 29407.2148\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8719.4805 - val_loss: 26126.3164\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 7906.4194 - val_loss: 22913.1953\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7026.6689 - val_loss: 20002.7520\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6188.6807 - val_loss: 17260.3457\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5446.8242 - val_loss: 14736.1982\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4808.7241 - val_loss: 12298.9980\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4058.6511 - val_loss: 10190.0938\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3424.1028 - val_loss: 8263.6211\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2854.8027 - val_loss: 6452.5146\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2365.0552 - val_loss: 4804.8716\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1848.8300 - val_loss: 3523.3525\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1496.1677 - val_loss: 2449.3955\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1155.4857 - val_loss: 1645.5098\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 857.8973 - val_loss: 1040.4021\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 644.6573 - val_loss: 592.4660\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 461.7722 - val_loss: 303.1391\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 346.0259 - val_loss: 117.7905\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 248.8803 - val_loss: 25.1403\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 181.5044 - val_loss: 1.5656\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 135.7636 - val_loss: 22.4667\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 109.2540 - val_loss: 66.9591\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 95.3252 - val_loss: 120.7068\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 87.1728 - val_loss: 169.0735\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 83.3881 - val_loss: 203.8380\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 80.3835 - val_loss: 218.7236\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 79.7909 - val_loss: 233.5284\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 79.2781 - val_loss: 249.3482\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 78.6382 - val_loss: 263.9676\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 78.6654 - val_loss: 273.5435\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 77.8641 - val_loss: 265.1793\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 77.2638 - val_loss: 264.3241\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 76.7240 - val_loss: 262.9290\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 76.2304 - val_loss: 265.5790\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 75.7157 - val_loss: 264.9061\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 75.2986 - val_loss: 260.9810\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 74.9423 - val_loss: 246.2499\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 74.0335 - val_loss: 238.9596\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 73.6637 - val_loss: 234.3406\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 73.1913 - val_loss: 235.8088\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 72.6645 - val_loss: 239.4538\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 72.2243 - val_loss: 236.7555\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 71.7578 - val_loss: 227.9566\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 71.4507 - val_loss: 221.6556\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 70.8079 - val_loss: 222.0049\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 70.3380 - val_loss: 221.2517\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 70.0777 - val_loss: 224.1549\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 69.4980 - val_loss: 224.5532\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 69.1259 - val_loss: 228.5588\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 68.5809 - val_loss: 233.2249\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 68.4266 - val_loss: 239.9633\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 67.9154 - val_loss: 244.4719\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 67.5497 - val_loss: 248.0688\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 67.3081 - val_loss: 252.9203\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 66.9485 - val_loss: 256.2110\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 66.5274 - val_loss: 255.7878\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 66.1098 - val_loss: 246.2597\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 65.2134 - val_loss: 232.9701\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 64.6547 - val_loss: 218.0359\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 63.9035 - val_loss: 210.3241\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 63.4289 - val_loss: 194.2911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IeV3cxr6-yC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bl4BpZELIXuJ",
        "outputId": "54003c98-2a87-41cb-f41d-3f6ec353001b"
      },
      "source": [
        "test_input = array([20])\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[316.20547]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh0LkAsaJbL3"
      },
      "source": [
        "#ONE-ONE-MULTIPLE FEATURES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "RczkEu_WJ0eo",
        "outputId": "054346ed-ef24-49bf-d742-a633bb4a1b21"
      },
      "source": [
        "nums = 25\n",
        "\n",
        "X1 = list()\n",
        "X2 = list()\n",
        "X = list()\n",
        "Y = list()\n",
        "\n",
        "X1 = [(x+1)*2 for x in range(25)]\n",
        "X2 = [(x+1)*3 for x in range(25)]\n",
        "Y = [x1*x2 for x1,x2 in zip(X1,X2)]\n",
        "\n",
        "print(X1)\n",
        "print(X2)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50]\n",
            "[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75]\n",
            "[6, 24, 54, 96, 150, 216, 294, 384, 486, 600, 726, 864, 1014, 1176, 1350, 1536, 1734, 1944, 2166, 2400, 2646, 2904, 3174, 3456, 3750]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "LghC7UmiJ0v4",
        "outputId": "ef72b582-f245-4015-a515-c343926750f4"
      },
      "source": [
        "X = np.column_stack((X1, X2))\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  3]\n",
            " [ 4  6]\n",
            " [ 6  9]\n",
            " [ 8 12]\n",
            " [10 15]\n",
            " [12 18]\n",
            " [14 21]\n",
            " [16 24]\n",
            " [18 27]\n",
            " [20 30]\n",
            " [22 33]\n",
            " [24 36]\n",
            " [26 39]\n",
            " [28 42]\n",
            " [30 45]\n",
            " [32 48]\n",
            " [34 51]\n",
            " [36 54]\n",
            " [38 57]\n",
            " [40 60]\n",
            " [42 63]\n",
            " [44 66]\n",
            " [46 69]\n",
            " [48 72]\n",
            " [50 75]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nslmkddiJ0Yo"
      },
      "source": [
        "X = array(X).reshape(25, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhHvnL3vJ0Sx"
      },
      "source": [
        "Y=array(Y).reshape(25,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "FkwsOKhIKJdv",
        "outputId": "e6df89ac-1184-42f8-a25f-3ee28924dc02"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(80, activation='relu', input_shape=(1, 2)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 80)                26560     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                810       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 27,381\n",
            "Trainable params: 27,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gVxrhA_lKN0Q",
        "outputId": "417cc405-91dc-4da8-89c0-6dd68cad79c5"
      },
      "source": [
        "model.fit(X, Y, epochs=100, validation_split=0.5, batch_size=len(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 992.5893 - val_loss: 20932.0410\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 967.0427 - val_loss: 20808.4922\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 933.6838 - val_loss: 20842.4238\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 904.2093 - val_loss: 21043.6113\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 886.8065 - val_loss: 21365.6230\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 884.2802 - val_loss: 21751.3340\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 894.1259 - val_loss: 22120.3242\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 910.2055 - val_loss: 22390.9238\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 925.3052 - val_loss: 22502.8418\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 933.6149 - val_loss: 22432.0840\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 932.3196 - val_loss: 22194.1562\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 921.9697 - val_loss: 21835.1230\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 905.6943 - val_loss: 21415.7012\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 887.7402 - val_loss: 20994.8770\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 871.9427 - val_loss: 20617.5938\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 860.6193 - val_loss: 20309.8125\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 854.1563 - val_loss: 20079.6855\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 851.2801 - val_loss: 19923.4590\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 849.7920 - val_loss: 19831.8691\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 847.4313 - val_loss: 19795.7402\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 842.5926 - val_loss: 19809.2773\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 834.6856 - val_loss: 19869.8613\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 824.1374 - val_loss: 19976.6699\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 812.0728 - val_loss: 20127.3750\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 799.8328 - val_loss: 20315.7227\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 788.5386 - val_loss: 20530.2363\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 778.7928 - val_loss: 20754.6133\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 770.5901 - val_loss: 20969.9453\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 763.4390 - val_loss: 21157.7598\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 756.6089 - val_loss: 21303.4766\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 749.3975 - val_loss: 21398.7012\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 741.3474 - val_loss: 21442.2090\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 732.3432 - val_loss: 21439.5762\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 722.5801 - val_loss: 21401.3125\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 712.4471 - val_loss: 21340.6445\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 702.3667 - val_loss: 21271.2832\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 692.6614 - val_loss: 21205.7461\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 683.4725 - val_loss: 21154.1367\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 674.7488 - val_loss: 21123.7617\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 666.3046 - val_loss: 21119.5859\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 657.8915 - val_loss: 21144.1953\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 649.2962 - val_loss: 21198.1914\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 640.3819 - val_loss: 21280.8945\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 631.1254 - val_loss: 21389.5723\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 621.5937 - val_loss: 21520.5293\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 611.8996 - val_loss: 21668.4297\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 602.1596 - val_loss: 21826.9883\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 592.4489 - val_loss: 21989.3145\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 582.7852 - val_loss: 22148.4355\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 573.1270 - val_loss: 22298.0645\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 563.3875 - val_loss: 22433.2266\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 553.4666 - val_loss: 22550.8711\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 543.2786 - val_loss: 22649.9727\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 532.7598 - val_loss: 22731.4453\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 521.8795 - val_loss: 22798.3418\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 510.6336 - val_loss: 22854.9922\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 499.0241 - val_loss: 22906.5020\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 487.0536 - val_loss: 22958.5195\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 474.7050 - val_loss: 23016.6855\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 461.9389 - val_loss: 23086.2188\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 448.7041 - val_loss: 23171.6758\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 434.9248 - val_loss: 23277.1777\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 420.5404 - val_loss: 23405.9863\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 405.4891 - val_loss: 23561.0078\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 389.7397 - val_loss: 23744.5820\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 373.2885 - val_loss: 23958.9863\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 356.1759 - val_loss: 24206.5703\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 338.4909 - val_loss: 24490.0195\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 320.3895 - val_loss: 24812.6172\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 302.0970 - val_loss: 25177.9375\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 283.9291 - val_loss: 25589.9355\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 266.2795 - val_loss: 26051.8652\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 249.5881 - val_loss: 26565.8750\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 234.2528 - val_loss: 27132.1289\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 220.4873 - val_loss: 27750.3320\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 208.1637 - val_loss: 28423.0098\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 196.7719 - val_loss: 29158.7852\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 185.6611 - val_loss: 29969.1270\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 174.5235 - val_loss: 30856.3125\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 163.7194 - val_loss: 31800.0391\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 154.0263 - val_loss: 32750.5801\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 145.9916 - val_loss: 33634.2109\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 139.4476 - val_loss: 34369.8008\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 133.6195 - val_loss: 34891.8789\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 127.7321 - val_loss: 35172.8047\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 121.5575 - val_loss: 35239.1719\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 115.4626 - val_loss: 35173.2461\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 109.9327 - val_loss: 35093.1133\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 105.0147 - val_loss: 35113.8359\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 100.2250 - val_loss: 35308.5859\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 95.0070 - val_loss: 35690.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 89.2250 - val_loss: 36220.7305\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 83.1757 - val_loss: 36823.3477\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 77.1867 - val_loss: 37414.2773\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 71.2857 - val_loss: 37926.6875\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 65.2599 - val_loss: 38334.8984\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 58.9837 - val_loss: 38664.2695\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 52.6513 - val_loss: 38985.4961\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 46.6886 - val_loss: 39395.2539\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 41.4454 - val_loss: 39991.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5478034f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "szSDaEf_KeEt",
        "outputId": "79180e2e-8252-46e5-9941-799f3e23e7b9"
      },
      "source": [
        "test_input = array([2,3])\n",
        "test_input = test_input.reshape((1, 1, 2))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.932805]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "HFhO9Hv1LoBB",
        "outputId": "aa181449-6105-4e26-e88b-39dd13d16372"
      },
      "source": [
        "##stacked lstm\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(1, 2)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 1, 200)            162400    \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 1, 100)            120400    \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 1, 50)             30200     \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 25)                7600      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20)                520       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 321,341\n",
            "Trainable params: 321,341\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Umtf9I_XMB4W",
        "outputId": "a7f7142b-69b7-4b01-b3f3-6a411a0706e7"
      },
      "source": [
        "history = model.fit(X, Y, epochs=100, validation_split=0.1, verbose=1, batch_size=3)\n",
        "\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1884084.0000 - val_loss: 12026587.0000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1883976.7500 - val_loss: 12025129.0000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1883064.3750 - val_loss: 12013339.0000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1878329.5000 - val_loss: 11971421.0000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1864038.8750 - val_loss: 11833167.0000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1832303.1250 - val_loss: 11543857.0000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1740007.5000 - val_loss: 10881633.0000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1548015.1250 - val_loss: 9303493.0000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1117651.5000 - val_loss: 6432608.5000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 547011.5625 - val_loss: 2707930.5000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 73792.2422 - val_loss: 488095.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 127693.8750 - val_loss: 391057.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 97375.0781 - val_loss: 983834.1875\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 89037.3047 - val_loss: 1215087.1250\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 76493.7734 - val_loss: 891573.4375\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 63197.2148 - val_loss: 794553.1875\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 45736.3281 - val_loss: 561191.1875\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 35367.5938 - val_loss: 278569.7812\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25612.2520 - val_loss: 309664.4375\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17290.8066 - val_loss: 445252.3750\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 18142.8750 - val_loss: 423684.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7834.0488 - val_loss: 172999.8281\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12684.8555 - val_loss: 50278.0625\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17976.9316 - val_loss: 295575.7812\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 28871.6758 - val_loss: 271637.5938\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11096.8115 - val_loss: 224212.2500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9449.6553 - val_loss: 195593.8750\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 12323.3936 - val_loss: 118162.5391\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8417.5176 - val_loss: 389305.5938\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13875.3506 - val_loss: 168162.9531\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24949.0859 - val_loss: 195368.9531\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10290.1260 - val_loss: 183753.4219\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 20311.0176 - val_loss: 328973.5938\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 13372.9932 - val_loss: 109339.9766\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5404.1421 - val_loss: 249519.1719\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14728.2432 - val_loss: 165451.2656\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 13437.7627 - val_loss: 281676.4062\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9645.9473 - val_loss: 179999.6250\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15177.4404 - val_loss: 238082.5000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19794.5078 - val_loss: 427139.7812\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 14698.1719 - val_loss: 152793.9219\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19619.9648 - val_loss: 275220.0312\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15387.1621 - val_loss: 392352.9062\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18119.7715 - val_loss: 178467.4844\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15308.8555 - val_loss: 597864.5000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 25764.4062 - val_loss: 231372.6719\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16503.9844 - val_loss: 274121.2812\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17002.9668 - val_loss: 187020.5469\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13023.4648 - val_loss: 390273.8438\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16963.0332 - val_loss: 443300.1562\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15060.0713 - val_loss: 158220.6562\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 23259.3984 - val_loss: 333964.5938\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13511.1221 - val_loss: 194206.0625\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14000.2441 - val_loss: 267157.3750\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11089.3682 - val_loss: 172580.3906\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8904.4385 - val_loss: 317041.1562\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14001.9941 - val_loss: 85290.3984\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15759.8281 - val_loss: 121838.6016\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7793.3613 - val_loss: 118437.8984\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5240.9355 - val_loss: 190083.5156\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10732.3926 - val_loss: 64670.3945\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6099.9966 - val_loss: 293104.5938\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10414.7402 - val_loss: 99360.2734\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8762.0566 - val_loss: 152284.1094\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5797.1650 - val_loss: 130338.2500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3162.6123 - val_loss: 76830.1953\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2270.1299 - val_loss: 96074.5625\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2106.2085 - val_loss: 41879.1445\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1958.7399 - val_loss: 49611.4961\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2342.6672 - val_loss: 100179.8359\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2335.1428 - val_loss: 36631.7227\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1158.3362 - val_loss: 86720.6797\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5903.2993 - val_loss: 65484.3906\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3513.8557 - val_loss: 55963.3945\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 701.4670 - val_loss: 48256.5312\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 569.6741 - val_loss: 43210.1211\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 379.8901 - val_loss: 23984.2500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 743.0071 - val_loss: 22503.1504\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 224.0782 - val_loss: 20042.8125\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 181.5080 - val_loss: 17063.3047\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 294.8674 - val_loss: 22443.4844\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 495.9140 - val_loss: 21247.3906\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 195.4379 - val_loss: 23302.8145\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 850.4494 - val_loss: 23475.9141\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1130.7371 - val_loss: 22146.5293\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 715.8135 - val_loss: 15590.6914\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 227.0276 - val_loss: 12808.1045\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 901.6104 - val_loss: 31031.8438\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 438.4940 - val_loss: 27895.3223\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 578.0162 - val_loss: 28362.1953\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 380.4900 - val_loss: 25076.9141\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 223.2345 - val_loss: 16107.5986\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 138.3423 - val_loss: 21295.0137\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 143.1583 - val_loss: 18506.1230\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 180.5509 - val_loss: 18318.9512\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1682.5018 - val_loss: 19241.1191\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1990.4758 - val_loss: 18645.9902\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2589.9561 - val_loss: 21649.3887\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3030.3665 - val_loss: 83375.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1524.9012 - val_loss: 72863.9375\n",
            "[[5.327584]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SEq7523MIVF"
      },
      "source": [
        "#######################################3\n",
        "#many_to_one----it has more than one time-step-per-sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "Qi9GbYOPNDd8",
        "outputId": "e177cbed-6324-49d0-e28a-9b9fd3b3d6d2"
      },
      "source": [
        "X = np.array([x+1 for x in range(45)])\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MTdigBQRNDXR",
        "outputId": "dea6de0c-8348-4c25-bec9-7e9dd7168fb5"
      },
      "source": [
        "X = X.reshape(15,3,1)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 1]\n",
            "  [ 2]\n",
            "  [ 3]]\n",
            "\n",
            " [[ 4]\n",
            "  [ 5]\n",
            "  [ 6]]\n",
            "\n",
            " [[ 7]\n",
            "  [ 8]\n",
            "  [ 9]]\n",
            "\n",
            " [[10]\n",
            "  [11]\n",
            "  [12]]\n",
            "\n",
            " [[13]\n",
            "  [14]\n",
            "  [15]]\n",
            "\n",
            " [[16]\n",
            "  [17]\n",
            "  [18]]\n",
            "\n",
            " [[19]\n",
            "  [20]\n",
            "  [21]]\n",
            "\n",
            " [[22]\n",
            "  [23]\n",
            "  [24]]\n",
            "\n",
            " [[25]\n",
            "  [26]\n",
            "  [27]]\n",
            "\n",
            " [[28]\n",
            "  [29]\n",
            "  [30]]\n",
            "\n",
            " [[31]\n",
            "  [32]\n",
            "  [33]]\n",
            "\n",
            " [[34]\n",
            "  [35]\n",
            "  [36]]\n",
            "\n",
            " [[37]\n",
            "  [38]\n",
            "  [39]]\n",
            "\n",
            " [[40]\n",
            "  [41]\n",
            "  [42]]\n",
            "\n",
            " [[43]\n",
            "  [44]\n",
            "  [45]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RqkWUZV5NDRA",
        "outputId": "54f4401c-3d5e-4eb8-cff9-821c3fe2467a"
      },
      "source": [
        "Y = list()\n",
        "for x in X:\n",
        "    \n",
        "    Y.append(x.sum())\n",
        "\n",
        "Y = np.array(Y)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  6  15  24  33  42  51  60  69  78  87  96 105 114 123 132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdWTrvl3NT3m"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(3, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v7azR-RlN79A",
        "outputId": "4e9413e2-0ce7-4535-e946-9a1c93ab71fd"
      },
      "source": [
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 4132.8452 - val_loss: 15367.8799\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4116.0435 - val_loss: 15315.0322\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4099.4487 - val_loss: 15262.5508\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4083.0352 - val_loss: 15210.3594\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4066.7825 - val_loss: 15158.3896\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4050.6924 - val_loss: 15106.5283\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4034.7109 - val_loss: 15054.6729\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4018.8054 - val_loss: 15002.7266\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4002.9529 - val_loss: 14950.5674\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3987.1201 - val_loss: 14898.0654\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3971.2744 - val_loss: 14845.0889\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3955.3806 - val_loss: 14791.4873\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3939.4031 - val_loss: 14737.1094\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3923.3035 - val_loss: 14681.7930\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3907.0466 - val_loss: 14625.3623\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3890.5889 - val_loss: 14567.6289\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3873.8865 - val_loss: 14508.3936\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3856.8938 - val_loss: 14447.4424\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3839.5623 - val_loss: 14384.5469\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3821.8408 - val_loss: 14319.4600\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3803.6758 - val_loss: 14251.9189\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3785.0117 - val_loss: 14181.6455\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3765.7888 - val_loss: 14108.3447\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3745.9434 - val_loss: 14031.7021\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3725.4119 - val_loss: 13951.3906\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3704.1243 - val_loss: 13867.0781\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3682.0110 - val_loss: 13778.4248\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3658.9971 - val_loss: 13685.0986\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3635.0066 - val_loss: 13586.7891\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3609.9617 - val_loss: 13483.2080\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3583.7830 - val_loss: 13371.4688\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3556.3516 - val_loss: 13250.3564\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3526.3679 - val_loss: 13122.6670\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3494.6228 - val_loss: 12988.1357\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3461.1619 - val_loss: 12847.0713\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3426.0420 - val_loss: 12701.0234\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3389.2043 - val_loss: 12548.8047\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3350.4290 - val_loss: 12390.6133\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3309.6370 - val_loss: 12226.6250\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3266.7288 - val_loss: 12056.8564\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3221.5837 - val_loss: 11878.6885\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3173.5481 - val_loss: 11689.0635\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3121.4827 - val_loss: 11490.8662\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3066.3669 - val_loss: 11282.2393\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3007.8899 - val_loss: 11060.8164\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2945.6741 - val_loss: 10823.8545\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2879.2810 - val_loss: 10567.5947\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2808.2168 - val_loss: 10287.7070\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2731.9365 - val_loss: 9979.0107\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2649.8533 - val_loss: 9635.5322\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2561.4497 - val_loss: 9253.0107\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2466.3066 - val_loss: 8828.8428\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2364.4504 - val_loss: 8364.8672\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2256.3625 - val_loss: 7869.1016\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2143.0823 - val_loss: 7356.3081\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2026.2279 - val_loss: 6845.6099\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1907.8011 - val_loss: 6355.0796\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1789.7914 - val_loss: 5896.4429\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1673.4039 - val_loss: 5462.3423\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1558.2906 - val_loss: 5054.9785\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1446.3070 - val_loss: 4662.3374\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1337.2377 - val_loss: 4272.4395\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1230.4684 - val_loss: 3879.1562\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1125.6730 - val_loss: 3485.9861\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1023.1439 - val_loss: 3102.8621\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 923.5220 - val_loss: 2736.4387\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 827.4417 - val_loss: 2387.6970\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 735.3062 - val_loss: 2056.1660\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 647.3636 - val_loss: 1742.6185\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 563.8445 - val_loss: 1449.1698\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 485.0524 - val_loss: 1178.5844\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 411.3718 - val_loss: 933.6209\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 343.2334 - val_loss: 716.5589\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 281.0732 - val_loss: 528.9038\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 225.2862 - val_loss: 371.2725\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 176.1792 - val_loss: 243.4443\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 133.9142 - val_loss: 144.0693\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 98.4412 - val_loss: 72.2180\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 69.8870 - val_loss: 26.2015\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 48.0426 - val_loss: 3.6222\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 32.5191 - val_loss: 1.6581\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 22.7723 - val_loss: 17.0471\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.1056 - val_loss: 46.1018\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 17.7032 - val_loss: 85.2608\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 20.7266 - val_loss: 130.1409\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 26.1211 - val_loss: 176.3243\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 32.8216 - val_loss: 219.8267\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 39.8214 - val_loss: 257.3368\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 46.2570 - val_loss: 286.4621\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 51.4733 - val_loss: 305.8275\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 55.0554 - val_loss: 315.0329\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 56.8238 - val_loss: 314.5012\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 56.8031 - val_loss: 305.2792\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 55.1756 - val_loss: 288.8209\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 52.2281 - val_loss: 266.8668\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 48.3026 - val_loss: 241.7577\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 43.8385 - val_loss: 214.3138\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 39.1479 - val_loss: 185.9393\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 34.4446 - val_loss: 157.8965\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 29.9595 - val_loss: 131.2609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uXcWiSGwNmnp",
        "outputId": "cf85a7e1-b14c-4eb3-d7c9-8628dec535da"
      },
      "source": [
        "test_input = array([50,51,52])\n",
        "test_input = test_input.reshape((1, 3, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f547ae50268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[168.05968]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W5rsl8S4OyUu",
        "outputId": "feaeb8ad-d759-4ce4-99af-89ad3102f06e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(3, 1)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 4045.5300 - val_loss: 15178.4346\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4044.3801 - val_loss: 15175.2451\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4043.4929 - val_loss: 15171.5508\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4042.4954 - val_loss: 15166.8994\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4041.2971 - val_loss: 15160.1592\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4039.7852 - val_loss: 15149.8672\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4037.7288 - val_loss: 15133.5361\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4034.8113 - val_loss: 15105.8115\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4030.4641 - val_loss: 15065.1377\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4023.7976 - val_loss: 15007.7139\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4014.8508 - val_loss: 14910.1406\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4000.5149 - val_loss: 14753.4062\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3976.6846 - val_loss: 14528.9717\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3938.5715 - val_loss: 14225.7500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3881.6172 - val_loss: 13818.9775\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3800.2424 - val_loss: 13237.5088\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3685.5918 - val_loss: 12430.7939\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3526.4407 - val_loss: 11396.2383\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3313.3821 - val_loss: 10102.0596\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3036.1462 - val_loss: 8724.5898\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2710.3538 - val_loss: 7235.6411\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2350.6799 - val_loss: 5559.3315\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1936.6989 - val_loss: 3706.9492\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1466.8868 - val_loss: 1795.5775\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 954.2863 - val_loss: 346.7810\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 477.4970 - val_loss: 187.6437\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 167.3068 - val_loss: 4206.0132\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 468.3809 - val_loss: 6658.2622\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 745.6077 - val_loss: 3740.5989\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 430.0381 - val_loss: 3411.2375\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 389.0097 - val_loss: 2605.7246\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 294.7145 - val_loss: 1679.0355\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 195.3519 - val_loss: 867.7368\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 127.8717 - val_loss: 237.2597\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 113.4593 - val_loss: 25.4946\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 142.6511 - val_loss: 4.6212\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 177.3105 - val_loss: 21.5831\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 200.7021 - val_loss: 30.6392\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 206.7205 - val_loss: 21.0894\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 195.4130 - val_loss: 5.8662\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 171.2950 - val_loss: 7.1756\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 141.4820 - val_loss: 46.8916\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 113.3429 - val_loss: 146.4036\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 93.5407 - val_loss: 331.1327\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 87.9864 - val_loss: 546.7894\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 94.7729 - val_loss: 701.8257\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 104.2900 - val_loss: 753.2305\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 108.3488 - val_loss: 755.7358\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 105.5236 - val_loss: 711.3481\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 100.7961 - val_loss: 612.0970\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 92.5537 - val_loss: 485.9900\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 83.2953 - val_loss: 358.5084\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 75.8091 - val_loss: 248.7270\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 71.6810 - val_loss: 165.5076\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 70.8504 - val_loss: 109.2141\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 72.0314 - val_loss: 75.5088\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 73.4341 - val_loss: 59.7247\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 73.4420 - val_loss: 65.3481\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 71.3180 - val_loss: 94.0459\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 67.9279 - val_loss: 121.3111\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 64.3905 - val_loss: 154.3733\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 61.6569 - val_loss: 191.4485\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 60.0809 - val_loss: 224.2764\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 59.2512 - val_loss: 250.4247\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 58.9739 - val_loss: 234.3209\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 56.6884 - val_loss: 209.5524\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 53.9546 - val_loss: 179.2089\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 50.7429 - val_loss: 157.2453\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 47.9885 - val_loss: 129.0928\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 45.7808 - val_loss: 88.4383\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 43.9819 - val_loss: 66.4710\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 42.7422 - val_loss: 61.7198\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 40.6957 - val_loss: 92.7389\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 40.3761 - val_loss: 39.3169\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 37.7949 - val_loss: 28.6234\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 37.0305 - val_loss: 30.4235\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 34.3920 - val_loss: 48.8925\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 32.1779 - val_loss: 53.8652\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 30.9500 - val_loss: 31.6733\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 28.3429 - val_loss: 26.8818\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 27.1678 - val_loss: 27.9442\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 25.1353 - val_loss: 32.8546\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 22.6820 - val_loss: 38.8140\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 21.3081 - val_loss: 32.6507\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 18.8626 - val_loss: 24.3027\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 16.6633 - val_loss: 18.3748\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.2273 - val_loss: 11.4434\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.5118 - val_loss: 7.6128\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.5547 - val_loss: 5.5104\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.0556 - val_loss: 2.9432\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.0426 - val_loss: 0.5944\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.8660 - val_loss: 0.0077\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.3668 - val_loss: 0.0113\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.9228 - val_loss: 0.0783\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.9677 - val_loss: 1.3377\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.5875 - val_loss: 1.8813\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.2464 - val_loss: 1.1202\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.6910 - val_loss: 0.6541\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 5.6069 - val_loss: 0.7569\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.9181 - val_loss: 0.5504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "84jrx3uGOqAc",
        "outputId": "950597cc-a167-488d-edeb-dd2eb2024288"
      },
      "source": [
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5474198a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[151.1894]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhvgSeEkO7TB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ5Kx0mrPGry"
      },
      "source": [
        "#bidirection lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCc9L7wAPKQy"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qZCuM0p8PP2U",
        "outputId": "f49f5efb-34fd-4c57-a234-2e536ffb63cd"
      },
      "source": [
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0418\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0417\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0416\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0415\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0414\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0413\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0412\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0411\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0410\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0409\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0408\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0407\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0406\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0405\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0404\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0403\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0402\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0401\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0400\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0400\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0399\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0398\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0397\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0396\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0395\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0394\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0393\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0392\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0391\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0390\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0389\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0389\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0388\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0387\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0386\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0385\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0384\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0383\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0382\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0382\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0381\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0380\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - val_loss: 0.0379\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0378\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0377\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0376\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0375\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0375\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0374\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0373\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0372\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0371\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0370\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0370\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0369\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0368\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0367\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0366\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0365\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0365\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0364\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0363\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0362\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0361\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0361\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0360\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0359\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0358\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0358\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0015 - val_loss: 0.0357\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0356\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0355\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0354\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0015 - val_loss: 0.0354\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0353\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0352\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0351\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0351\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0350\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0349\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0348\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0348\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0347\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0346\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0346\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0015 - val_loss: 0.0345\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - val_loss: 0.0344\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0343\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0343\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0342\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0341\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0341\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0340\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0339\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0338\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0338\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0337\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0336\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0336\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0335\n",
            "WARNING:tensorflow:8 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f546c9c9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[153.5208]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr82jFJEPZYh"
      },
      "source": [
        "#many-to-many"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "C1GrsuK4Ppa_",
        "outputId": "2cab9822-2d62-48f8-a341-2f42f65b7221"
      },
      "source": [
        "X1 = np.array([x+3 for x in range(0, 135, 3)])\n",
        "print(X1)\n",
        "\n",
        "X2 = np.array([x+5 for x in range(0, 225, 5)])\n",
        "print(X2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  3   6   9  12  15  18  21  24  27  30  33  36  39  42  45  48  51  54\n",
            "  57  60  63  66  69  72  75  78  81  84  87  90  93  96  99 102 105 108\n",
            " 111 114 117 120 123 126 129 132 135]\n",
            "[  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n",
            "  95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180\n",
            " 185 190 195 200 205 210 215 220 225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "SA3aQxPNPqWw",
        "outputId": "e063a974-35a4-4d5d-dade-99a1118e9a00"
      },
      "source": [
        "X = np.column_stack((X1, X2))\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  3   5]\n",
            " [  6  10]\n",
            " [  9  15]\n",
            " [ 12  20]\n",
            " [ 15  25]\n",
            " [ 18  30]\n",
            " [ 21  35]\n",
            " [ 24  40]\n",
            " [ 27  45]\n",
            " [ 30  50]\n",
            " [ 33  55]\n",
            " [ 36  60]\n",
            " [ 39  65]\n",
            " [ 42  70]\n",
            " [ 45  75]\n",
            " [ 48  80]\n",
            " [ 51  85]\n",
            " [ 54  90]\n",
            " [ 57  95]\n",
            " [ 60 100]\n",
            " [ 63 105]\n",
            " [ 66 110]\n",
            " [ 69 115]\n",
            " [ 72 120]\n",
            " [ 75 125]\n",
            " [ 78 130]\n",
            " [ 81 135]\n",
            " [ 84 140]\n",
            " [ 87 145]\n",
            " [ 90 150]\n",
            " [ 93 155]\n",
            " [ 96 160]\n",
            " [ 99 165]\n",
            " [102 170]\n",
            " [105 175]\n",
            " [108 180]\n",
            " [111 185]\n",
            " [114 190]\n",
            " [117 195]\n",
            " [120 200]\n",
            " [123 205]\n",
            " [126 210]\n",
            " [129 215]\n",
            " [132 220]\n",
            " [135 225]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4vorJiipPqQ4",
        "outputId": "2a1390b8-81b9-4337-fe72-a5b31c7d778b"
      },
      "source": [
        "X = array(X).reshape(15, 3, 2)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[  3   5]\n",
            "  [  6  10]\n",
            "  [  9  15]]\n",
            "\n",
            " [[ 12  20]\n",
            "  [ 15  25]\n",
            "  [ 18  30]]\n",
            "\n",
            " [[ 21  35]\n",
            "  [ 24  40]\n",
            "  [ 27  45]]\n",
            "\n",
            " [[ 30  50]\n",
            "  [ 33  55]\n",
            "  [ 36  60]]\n",
            "\n",
            " [[ 39  65]\n",
            "  [ 42  70]\n",
            "  [ 45  75]]\n",
            "\n",
            " [[ 48  80]\n",
            "  [ 51  85]\n",
            "  [ 54  90]]\n",
            "\n",
            " [[ 57  95]\n",
            "  [ 60 100]\n",
            "  [ 63 105]]\n",
            "\n",
            " [[ 66 110]\n",
            "  [ 69 115]\n",
            "  [ 72 120]]\n",
            "\n",
            " [[ 75 125]\n",
            "  [ 78 130]\n",
            "  [ 81 135]]\n",
            "\n",
            " [[ 84 140]\n",
            "  [ 87 145]\n",
            "  [ 90 150]]\n",
            "\n",
            " [[ 93 155]\n",
            "  [ 96 160]\n",
            "  [ 99 165]]\n",
            "\n",
            " [[102 170]\n",
            "  [105 175]\n",
            "  [108 180]]\n",
            "\n",
            " [[111 185]\n",
            "  [114 190]\n",
            "  [117 195]]\n",
            "\n",
            " [[120 200]\n",
            "  [123 205]\n",
            "  [126 210]]\n",
            "\n",
            " [[129 215]\n",
            "  [132 220]\n",
            "  [135 225]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ_dToddPqKr"
      },
      "source": [
        "Y=[ 24 , 48,  72,  96, 120 ,144, 168 ,192, 216, 240, 264 ,288 ,312, 336 ,360]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f5JwPQOPqEA"
      },
      "source": [
        "Y=np.array(Y).reshape(15,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "JiIb95eKPp9u",
        "outputId": "475916fd-efec-4e87-98f5-9f7bb5e313db"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 24],\n",
              "       [ 48],\n",
              "       [ 72],\n",
              "       [ 96],\n",
              "       [120],\n",
              "       [144],\n",
              "       [168],\n",
              "       [192],\n",
              "       [216],\n",
              "       [240],\n",
              "       [264],\n",
              "       [288],\n",
              "       [312],\n",
              "       [336],\n",
              "       [360]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rF1Sf_O_SAeN",
        "outputId": "886e714f-8de8-430b-e060-94793382cb1b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(3, 2)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 31372.2109 - val_loss: 112180.7578\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 30820.8574 - val_loss: 109784.3672\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 30270.8359 - val_loss: 107461.6250\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 29734.1035 - val_loss: 105371.2891\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 29221.6562 - val_loss: 103584.5391\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 28740.6387 - val_loss: 102075.5859\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 28291.5879 - val_loss: 100750.4141\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 27866.6348 - val_loss: 99492.6016\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 27450.3594 - val_loss: 98176.5391\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 27020.4512 - val_loss: 96640.4922\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 26544.5000 - val_loss: 94598.8516\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 25980.6172 - val_loss: 91701.1484\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 25291.0957 - val_loss: 87690.1172\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 24450.6562 - val_loss: 82859.3203\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 23480.2402 - val_loss: 78252.6562\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 22475.2871 - val_loss: 74715.4766\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 21554.5254 - val_loss: 72253.1250\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 20779.8691 - val_loss: 70452.8359\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 20137.5840 - val_loss: 68939.9453\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19593.2676 - val_loss: 67538.8828\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 19108.5332 - val_loss: 66150.8984\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18655.0879 - val_loss: 64747.6055\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 18215.3652 - val_loss: 63325.5117\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 17776.9297 - val_loss: 61865.9375\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 17327.3125 - val_loss: 60307.5117\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 16849.0469 - val_loss: 58511.1875\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 16314.7764 - val_loss: 56199.1094\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 15684.7861 - val_loss: 53036.8633\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 14928.2500 - val_loss: 49450.6562\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 14091.0146 - val_loss: 46488.9531\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 13287.4219 - val_loss: 44080.3711\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 12549.9404 - val_loss: 41862.7070\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11840.6436 - val_loss: 39641.8242\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 11120.9688 - val_loss: 37151.5039\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 10349.0439 - val_loss: 33987.5977\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9494.1162 - val_loss: 30302.2090\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8611.4111 - val_loss: 27252.1582\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7818.2427 - val_loss: 24703.5566\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7102.5312 - val_loss: 21955.6016\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6366.4116 - val_loss: 18993.1582\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5594.7480 - val_loss: 15582.0391\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4765.9370 - val_loss: 12246.5664\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3900.5515 - val_loss: 9013.8320\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3042.3376 - val_loss: 5036.4062\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2073.7192 - val_loss: 2763.2695\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1243.9449 - val_loss: 1403.9242\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 732.8054 - val_loss: 579.8975\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 405.1737 - val_loss: 161.8637\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 203.4979 - val_loss: 7.0007\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 93.5943 - val_loss: 49.3280\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 53.4467 - val_loss: 253.7438\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 68.0344 - val_loss: 560.4529\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 120.2620 - val_loss: 891.5352\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 189.7961 - val_loss: 1192.4454\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 259.2811 - val_loss: 1436.3618\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 317.8401 - val_loss: 1615.3374\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 360.9043 - val_loss: 1727.6498\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 387.4816 - val_loss: 1773.4877\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 398.0318 - val_loss: 1756.4420\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 393.7596 - val_loss: 1684.4281\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 376.6957 - val_loss: 1569.4486\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 349.5435 - val_loss: 1424.5426\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 314.9726 - val_loss: 1258.2518\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 275.3880 - val_loss: 1073.8077\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 233.1871 - val_loss: 886.1260\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 192.1397 - val_loss: 720.9561\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 155.6268 - val_loss: 575.7493\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 124.0150 - val_loss: 446.9811\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 97.0414 - val_loss: 334.7862\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 74.6155 - val_loss: 240.6534\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 56.8744 - val_loss: 164.6947\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 43.6369 - val_loss: 105.8759\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 34.4125 - val_loss: 62.5496\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 28.5049 - val_loss: 32.7063\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 25.0347 - val_loss: 14.2588\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 22.9363 - val_loss: 5.3267\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 21.1323 - val_loss: 7.0300\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 21.4551 - val_loss: 0.4594\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 19.7252 - val_loss: 1.2869\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 20.1761 - val_loss: 3.2597\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 19.8028 - val_loss: 0.6508\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 18.6151 - val_loss: 0.3917\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 19.7175 - val_loss: 6.0318\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.0149 - val_loss: 15.4055\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 18.9670 - val_loss: 10.5967\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 17.4286 - val_loss: 0.7076\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 17.9073 - val_loss: 3.8609\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 16.7072 - val_loss: 18.5134\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 16.7356 - val_loss: 21.1620\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 16.5304 - val_loss: 8.5723\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 15.5882 - val_loss: 3.4759\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 16.1008 - val_loss: 15.3779\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 14.9821 - val_loss: 26.9005\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 15.3931 - val_loss: 18.9618\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14.5000 - val_loss: 6.5665\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 14.6678 - val_loss: 10.7590\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 13.9888 - val_loss: 24.2407\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 13.8823 - val_loss: 23.7625\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 13.5624 - val_loss: 10.8134\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 13.0675 - val_loss: 7.3987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Xk_lXUkzSFVE",
        "outputId": "0f3387a1-9d4c-4f78-84e4-0ae4b6025753"
      },
      "source": [
        "test_input = array([[8, 51],\n",
        "                    [11,56],\n",
        "                    [14,61]])\n",
        "\n",
        "test_input = test_input.reshape((1, 3, 2))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f547acfd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[78.46336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hEipjAYxSJ5K",
        "outputId": "f22ecdc6-dd2f-4cd9-bfe1-72f0808ac8a0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(3, 2)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
        "\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 31189.6348 - val_loss: 113138.7266\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 31169.1113 - val_loss: 112910.1250\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 31132.2578 - val_loss: 112579.8359\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 31066.6797 - val_loss: 112188.4297\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 30968.7285 - val_loss: 111658.6484\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 30841.2090 - val_loss: 111011.2891\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 30680.2090 - val_loss: 110296.8438\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 30486.1035 - val_loss: 109421.3750\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 30250.0410 - val_loss: 108210.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 29938.7949 - val_loss: 106549.6875\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 29513.2598 - val_loss: 103513.2734\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 28795.8379 - val_loss: 100919.4297\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 28050.1172 - val_loss: 97500.6172\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 27131.7246 - val_loss: 93473.8516\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 26062.3535 - val_loss: 88828.4062\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 24814.3848 - val_loss: 83027.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 23304.1621 - val_loss: 76139.7500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 21514.4805 - val_loss: 68286.8984\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 19467.7461 - val_loss: 59068.7031\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 17046.6758 - val_loss: 48855.3008\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 14297.0186 - val_loss: 37902.9688\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11284.8857 - val_loss: 26664.8281\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 8201.2510 - val_loss: 16056.4375\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5206.0078 - val_loss: 7081.2246\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2583.6069 - val_loss: 883.4717\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 630.7576 - val_loss: 1067.1879\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 240.1390 - val_loss: 8062.4233\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1683.9346 - val_loss: 15598.5420\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3456.8254 - val_loss: 18121.8848\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4085.1135 - val_loss: 15282.2451\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3454.6926 - val_loss: 10187.8643\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2272.5027 - val_loss: 5171.9175\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1124.8817 - val_loss: 1890.2982\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 408.9915 - val_loss: 286.2621\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 117.7478 - val_loss: 4.8519\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 136.5724 - val_loss: 424.7610\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 323.7933 - val_loss: 1181.8461\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 582.2790 - val_loss: 1863.4144\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 804.0872 - val_loss: 2338.2190\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 950.5065 - val_loss: 2498.0388\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 994.1631 - val_loss: 2299.4924\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 929.3742 - val_loss: 1822.1406\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 773.0334 - val_loss: 1160.4099\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 558.7476 - val_loss: 567.5581\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 345.2097 - val_loss: 137.7579\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 170.9877 - val_loss: 38.1226\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 72.6853 - val_loss: 401.7917\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 111.8740 - val_loss: 914.8449\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 217.7660 - val_loss: 1289.4005\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 303.0075 - val_loss: 1379.7611\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 322.2407 - val_loss: 1209.5483\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 278.5944 - val_loss: 864.3528\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 197.9548 - val_loss: 546.4778\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 127.4394 - val_loss: 283.2173\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 79.9616 - val_loss: 104.5978\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 58.1991 - val_loss: 17.4829\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 59.7011 - val_loss: 1.4948\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 76.0352 - val_loss: 24.2728\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 96.5873 - val_loss: 53.5875\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 111.7104 - val_loss: 67.6819\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 114.9746 - val_loss: 59.3756\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 103.3356 - val_loss: 26.9326\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 73.7478 - val_loss: 11.4139\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 44.3045 - val_loss: 81.9491\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 39.7020 - val_loss: 144.6374\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 46.2256 - val_loss: 199.1214\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 53.5708 - val_loss: 194.4120\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 51.0847 - val_loss: 143.2225\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 40.0115 - val_loss: 89.4270\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 29.8532 - val_loss: 47.9418\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 22.6416 - val_loss: 21.0154\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 19.1056 - val_loss: 6.7453\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 20.9737 - val_loss: 1.1139\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 23.1849 - val_loss: 0.4465\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 25.1841 - val_loss: 1.1133\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 26.1573 - val_loss: 0.5390\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 23.1917 - val_loss: 0.7096\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 19.4928 - val_loss: 4.2196\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 16.8708 - val_loss: 11.8445\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 15.1341 - val_loss: 26.4152\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 14.5945 - val_loss: 44.7676\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.8038 - val_loss: 46.0043\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 16.4440 - val_loss: 34.4653\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.0649 - val_loss: 20.9944\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 12.0666 - val_loss: 11.1693\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.2198 - val_loss: 5.8014\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 10.8794 - val_loss: 3.6911\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.6718 - val_loss: 3.7452\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.9533 - val_loss: 5.9665\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7226 - val_loss: 23.3051\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 46.4714 - val_loss: 11.4696\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.8945 - val_loss: 4.3421\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 11.4773 - val_loss: 0.4594\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 19.5448 - val_loss: 0.5250\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 24.9871 - val_loss: 7.3194\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 23.8548 - val_loss: 8.2628\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 23.7990 - val_loss: 5.0246\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 22.1449 - val_loss: 0.6262\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 17.7776 - val_loss: 3.0644\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 13.9910 - val_loss: 17.2796\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5476024b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[71.14545]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nww7O0fSSSMU"
      },
      "source": [
        "#############################ONE-TO-MANY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "Uae9yWloUpeU",
        "outputId": "32981f42-3a74-4444-a07e-58a2b9552465"
      },
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x+3 for x in range(-2, 43, 3)]\n",
        "\n",
        "for i in X:\n",
        "    output_vector = list()\n",
        "    output_vector.append(i+1)\n",
        "    output_vector.append(i+2)\n",
        "    Y.append(output_vector)\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43]\n",
            "[[2, 3], [5, 6], [8, 9], [11, 12], [14, 15], [17, 18], [20, 21], [23, 24], [26, 27], [29, 30], [32, 33], [35, 36], [38, 39], [41, 42], [44, 45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQGe7urKUpYf"
      },
      "source": [
        "X = np.array(X).reshape(15, 1, 1)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "440iFI6AUpS7",
        "outputId": "51da733d-eaeb-4aa2-ab5c-f6c7926c1440"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, Y, epochs=100, validation_split=0.2, batch_size=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 504.5519 - val_loss: 1869.2720\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 500.2370 - val_loss: 1850.8105\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 495.1186 - val_loss: 1832.9117\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 490.3452 - val_loss: 1815.5400\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 485.3333 - val_loss: 1798.4760\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 481.1564 - val_loss: 1781.1289\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 476.4499 - val_loss: 1763.7921\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 472.4680 - val_loss: 1745.2646\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 467.4749 - val_loss: 1726.2545\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 462.6782 - val_loss: 1706.0292\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 457.5508 - val_loss: 1684.6763\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 451.6533 - val_loss: 1662.2626\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 446.0037 - val_loss: 1637.6862\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 439.2660 - val_loss: 1611.9689\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 432.5968 - val_loss: 1584.5626\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 425.6961 - val_loss: 1554.6807\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 418.2601 - val_loss: 1522.3729\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 409.9076 - val_loss: 1488.3463\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 400.5743 - val_loss: 1451.7334\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 390.0320 - val_loss: 1412.4991\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 379.8534 - val_loss: 1368.7574\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 367.8352 - val_loss: 1320.7682\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 354.0406 - val_loss: 1270.6422\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 344.3644 - val_loss: 1214.1166\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 330.0168 - val_loss: 1155.0249\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 315.4864 - val_loss: 1093.2111\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 300.1541 - val_loss: 1030.0883\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 285.6577 - val_loss: 966.0483\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 271.1657 - val_loss: 901.2390\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 253.5979 - val_loss: 840.0744\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 238.4444 - val_loss: 778.8792\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 224.5295 - val_loss: 717.3838\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 208.5541 - val_loss: 658.6320\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 193.3416 - val_loss: 602.4008\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 177.4699 - val_loss: 550.4376\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 164.5080 - val_loss: 499.4416\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 152.3295 - val_loss: 449.3399\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 136.2515 - val_loss: 405.5217\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 125.8475 - val_loss: 361.9140\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 113.9737 - val_loss: 321.2707\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.4695 - val_loss: 283.8761\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 90.8518 - val_loss: 250.3992\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 82.3271 - val_loss: 217.9145\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 72.1583 - val_loss: 189.2621\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 64.5211 - val_loss: 162.1638\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 55.8971 - val_loss: 138.6104\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 49.4139 - val_loss: 116.7727\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 43.5075 - val_loss: 96.8006\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 37.1019 - val_loss: 79.7552\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 31.4458 - val_loss: 65.3233\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 27.2802 - val_loss: 52.3931\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 22.9938 - val_loss: 41.5217\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19.5532 - val_loss: 32.2162\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 16.4313 - val_loss: 24.5067\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 13.6933 - val_loss: 18.3187\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 11.5409 - val_loss: 13.3601\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.6456 - val_loss: 9.5980\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 8.0305 - val_loss: 6.8934\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.8584 - val_loss: 4.9727\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.7539 - val_loss: 3.7560\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.0251 - val_loss: 3.0437\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.3668 - val_loss: 2.7180\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.9110 - val_loss: 2.5799\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.5409 - val_loss: 2.5586\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.2669 - val_loss: 2.6360\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.0420 - val_loss: 2.7363\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.8904 - val_loss: 2.8655\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.7642 - val_loss: 2.9780\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.6670 - val_loss: 3.0663\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.5820 - val_loss: 3.0991\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.5201 - val_loss: 3.0882\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.4731 - val_loss: 3.1530\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.4282 - val_loss: 3.0614\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.3917 - val_loss: 3.0853\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3622 - val_loss: 3.0899\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.3366 - val_loss: 3.0770\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.3153 - val_loss: 2.9983\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2920 - val_loss: 2.9361\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2729 - val_loss: 2.9888\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2522 - val_loss: 2.9446\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2357 - val_loss: 2.9457\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.2180 - val_loss: 2.9469\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2028 - val_loss: 2.8177\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.1813 - val_loss: 2.7790\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.1649 - val_loss: 2.7830\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.1467 - val_loss: 2.7261\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.1296 - val_loss: 2.7092\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.1150 - val_loss: 2.5992\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.0955 - val_loss: 2.6028\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.0783 - val_loss: 2.5878\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.0633 - val_loss: 2.5681\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.0460 - val_loss: 2.5157\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.0267 - val_loss: 2.4666\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.0096 - val_loss: 2.4151\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9951 - val_loss: 2.3377\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9809 - val_loss: 2.2764\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9635 - val_loss: 2.2451\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9486 - val_loss: 2.2758\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9302 - val_loss: 2.2561\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9120 - val_loss: 2.2068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f547352a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SP-qkkgRUpNM",
        "outputId": "7d0f1896-3caa-4a89-d44d-765a3d75906a"
      },
      "source": [
        "test_input = array([10])\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f547aee67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[9.26221  9.825922]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F8yqrJvtUpHB",
        "outputId": "7ecbf4a1-57c4-4ffa-861d-fe8ad38521b8"
      },
      "source": [
        "#STACKED\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
        "\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 464.3540 - val_loss: 1708.6812\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 462.8441 - val_loss: 1702.6647\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 461.1718 - val_loss: 1695.1831\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 459.0968 - val_loss: 1685.9921\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 455.9562 - val_loss: 1674.7379\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 453.1593 - val_loss: 1658.8153\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 449.1400 - val_loss: 1636.7623\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 443.1514 - val_loss: 1606.9899\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 434.0713 - val_loss: 1565.5912\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 425.7648 - val_loss: 1504.8795\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 410.2137 - val_loss: 1426.1403\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 391.8015 - val_loss: 1320.2207\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 366.2013 - val_loss: 1186.6615\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 333.1007 - val_loss: 1020.2424\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 292.5754 - val_loss: 833.3198\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 238.3649 - val_loss: 649.4663\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 196.3594 - val_loss: 465.5653\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 148.8460 - val_loss: 308.6343\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 102.0888 - val_loss: 191.5778\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 64.5983 - val_loss: 120.0115\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 41.8646 - val_loss: 85.0945\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 26.5827 - val_loss: 77.8477\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20.1178 - val_loss: 74.6094\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 15.9357 - val_loss: 66.4810\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 12.2084 - val_loss: 48.6206\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.4092 - val_loss: 29.3058\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 7.5538 - val_loss: 16.5697\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 7.0226 - val_loss: 10.0683\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.9189 - val_loss: 7.5301\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.7831 - val_loss: 6.6587\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.4994 - val_loss: 6.0439\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.0724 - val_loss: 6.8428\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.5988 - val_loss: 7.1562\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.4638 - val_loss: 8.5927\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.0910 - val_loss: 7.2267\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.8017 - val_loss: 6.3687\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.6379 - val_loss: 5.4375\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.4242 - val_loss: 4.2203\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.2280 - val_loss: 3.9144\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.0013 - val_loss: 3.5215\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.9085 - val_loss: 3.4797\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.6761 - val_loss: 2.7938\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.5048 - val_loss: 2.5195\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.3322 - val_loss: 1.8635\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.2535 - val_loss: 1.8085\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.0743 - val_loss: 1.5310\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.9214 - val_loss: 1.1197\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.7837 - val_loss: 0.7063\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.6790 - val_loss: 0.5213\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.5584 - val_loss: 0.4496\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.4376 - val_loss: 0.3214\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.3390 - val_loss: 0.3320\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.2808 - val_loss: 0.3231\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.1417 - val_loss: 0.1499\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.0509 - val_loss: 0.0662\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9901 - val_loss: 0.0425\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8903 - val_loss: 0.0151\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8171 - val_loss: 0.0100\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7401 - val_loss: 0.0315\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6696 - val_loss: 0.0623\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6093 - val_loss: 0.0774\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.5604 - val_loss: 0.0838\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4913 - val_loss: 0.1556\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4466 - val_loss: 0.1959\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3992 - val_loss: 0.2231\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3535 - val_loss: 0.3443\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3167 - val_loss: 0.3666\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.2738 - val_loss: 0.4055\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.2350 - val_loss: 0.4669\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1999 - val_loss: 0.5742\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1648 - val_loss: 0.6909\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1377 - val_loss: 0.7211\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.1102 - val_loss: 0.7651\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0775 - val_loss: 0.8447\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0575 - val_loss: 0.9782\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0301 - val_loss: 0.9579\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0101 - val_loss: 0.9678\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9878 - val_loss: 0.9414\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9729 - val_loss: 1.0509\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9481 - val_loss: 1.0039\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9362 - val_loss: 0.9646\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9176 - val_loss: 1.1244\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8981 - val_loss: 1.2166\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8828 - val_loss: 1.1766\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8756 - val_loss: 1.0192\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8525 - val_loss: 1.0817\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8416 - val_loss: 1.1610\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8252 - val_loss: 1.0406\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8307 - val_loss: 0.9419\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8050 - val_loss: 1.1924\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7878 - val_loss: 1.1595\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7686 - val_loss: 1.1329\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7600 - val_loss: 0.9601\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7466 - val_loss: 0.9208\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7394 - val_loss: 0.8210\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7210 - val_loss: 0.8988\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7090 - val_loss: 0.9745\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6976 - val_loss: 0.9107\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6924 - val_loss: 0.9105\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6753 - val_loss: 0.8295\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5476522158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[10.736746 11.660674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WmNcVn0iVoDJ",
        "outputId": "8acd59c4-37b3-4c5c-cabe-dea7dc70c885"
      },
      "source": [
        "#BIDIRECTIONSL\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 1)))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 500.5190 - val_loss: 1843.8594\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 491.5807 - val_loss: 1805.9257\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 482.5187 - val_loss: 1767.6000\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 472.1514 - val_loss: 1730.1256\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 461.7165 - val_loss: 1692.6758\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 451.2633 - val_loss: 1654.8959\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 441.4352 - val_loss: 1614.8190\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 430.9897 - val_loss: 1572.0096\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 418.8155 - val_loss: 1526.3756\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 407.3630 - val_loss: 1476.2614\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 393.0015 - val_loss: 1422.9854\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 376.4063 - val_loss: 1367.1124\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 361.5879 - val_loss: 1304.9310\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 345.8806 - val_loss: 1235.4368\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 325.3959 - val_loss: 1163.1053\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 304.5194 - val_loss: 1084.3927\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 283.7956 - val_loss: 998.4786\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 258.9991 - val_loss: 907.8561\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 240.9680 - val_loss: 806.4870\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 210.6724 - val_loss: 705.8185\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 181.7474 - val_loss: 604.1714\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 158.8797 - val_loss: 494.4600\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 130.7606 - val_loss: 386.4690\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 102.9380 - val_loss: 284.8321\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 83.7726 - val_loss: 188.3973\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 60.3162 - val_loss: 110.9818\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 41.0527 - val_loss: 55.8963\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 26.5821 - val_loss: 23.2363\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 17.1862 - val_loss: 9.7129\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 11.2683 - val_loss: 9.7136\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 8.4896 - val_loss: 17.4756\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.7389 - val_loss: 25.8758\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.4107 - val_loss: 32.7263\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.9215 - val_loss: 34.7337\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.8710 - val_loss: 36.3083\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.5179 - val_loss: 33.2824\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.1966 - val_loss: 29.1795\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.8351 - val_loss: 25.7466\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.6249 - val_loss: 22.5885\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.5716 - val_loss: 19.2726\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.4091 - val_loss: 17.3564\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.3736 - val_loss: 15.8118\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.2871 - val_loss: 15.3589\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.2524 - val_loss: 15.1881\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.2161 - val_loss: 15.7455\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.1632 - val_loss: 16.1189\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.0972 - val_loss: 15.9748\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.0580 - val_loss: 15.9537\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.0335 - val_loss: 15.0133\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.9552 - val_loss: 14.9180\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.9170 - val_loss: 15.1346\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.8580 - val_loss: 15.0422\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.8139 - val_loss: 14.6734\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.7791 - val_loss: 14.1815\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.7493 - val_loss: 13.4029\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.6865 - val_loss: 12.9710\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.6373 - val_loss: 13.4505\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.6053 - val_loss: 13.9130\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.5364 - val_loss: 13.4260\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.4937 - val_loss: 13.2040\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.4429 - val_loss: 12.8730\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.3886 - val_loss: 12.2272\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.3522 - val_loss: 12.0285\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.2965 - val_loss: 11.2091\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.2547 - val_loss: 10.6634\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.2182 - val_loss: 10.7788\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.1589 - val_loss: 10.6232\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.1054 - val_loss: 10.1418\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.0611 - val_loss: 9.6918\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.0185 - val_loss: 9.6815\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.9732 - val_loss: 9.0866\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.9221 - val_loss: 8.7850\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.8696 - val_loss: 8.7826\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.8340 - val_loss: 8.8786\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.7888 - val_loss: 8.1518\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.7184 - val_loss: 7.8587\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.6709 - val_loss: 7.6560\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.6260 - val_loss: 7.2483\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.5676 - val_loss: 7.2997\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.5072 - val_loss: 7.0822\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.4594 - val_loss: 6.9430\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.4041 - val_loss: 6.9224\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3509 - val_loss: 6.7725\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2936 - val_loss: 6.0808\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2518 - val_loss: 6.1025\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2031 - val_loss: 5.1678\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.1320 - val_loss: 4.8316\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.0746 - val_loss: 4.5088\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.0291 - val_loss: 4.2324\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.9714 - val_loss: 4.0322\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9224 - val_loss: 4.0044\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.8741 - val_loss: 3.8472\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.8250 - val_loss: 3.7798\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.7697 - val_loss: 3.4278\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7281 - val_loss: 3.3493\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6819 - val_loss: 3.2187\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6238 - val_loss: 2.8187\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5729 - val_loss: 2.4293\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.5287 - val_loss: 2.2044\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4752 - val_loss: 2.0428\n",
            "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f54761eb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[9.72187  9.914303]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "IMELWaHEVypc",
        "outputId": "6f9124b4-de80-4991-a792-8634c6b37fa6"
      },
      "source": [
        "nums = 25\n",
        "\n",
        "X1 = list()\n",
        "X2 = list()\n",
        "X = list()\n",
        "Y = list()\n",
        "\n",
        "X1 = [(x+1)*2 for x in range(25)]\n",
        "X2 = [(x+1)*3 for x in range(25)]\n",
        "\n",
        "for x1, x2 in zip(X1, X2):\n",
        "    output_vector = list()\n",
        "    output_vector.append(x1+1)\n",
        "    output_vector.append(x2+1)\n",
        "    Y.append(output_vector)\n",
        "\n",
        "X = np.column_stack((X1, X2))\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  3]\n",
            " [ 4  6]\n",
            " [ 6  9]\n",
            " [ 8 12]\n",
            " [10 15]\n",
            " [12 18]\n",
            " [14 21]\n",
            " [16 24]\n",
            " [18 27]\n",
            " [20 30]\n",
            " [22 33]\n",
            " [24 36]\n",
            " [26 39]\n",
            " [28 42]\n",
            " [30 45]\n",
            " [32 48]\n",
            " [34 51]\n",
            " [36 54]\n",
            " [38 57]\n",
            " [40 60]\n",
            " [42 63]\n",
            " [44 66]\n",
            " [46 69]\n",
            " [48 72]\n",
            " [50 75]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFtQdT1DWBby"
      },
      "source": [
        "X = np.array(X).reshape(25, 1, 2)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "GpNZzfDBWaSv",
        "outputId": "76802a5f-375e-4c09-a13b-4351fc68d164"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  4]\n",
            " [ 5  7]\n",
            " [ 7 10]\n",
            " [ 9 13]\n",
            " [11 16]\n",
            " [13 19]\n",
            " [15 22]\n",
            " [17 25]\n",
            " [19 28]\n",
            " [21 31]\n",
            " [23 34]\n",
            " [25 37]\n",
            " [27 40]\n",
            " [29 43]\n",
            " [31 46]\n",
            " [33 49]\n",
            " [35 52]\n",
            " [37 55]\n",
            " [39 58]\n",
            " [41 61]\n",
            " [43 64]\n",
            " [45 67]\n",
            " [47 70]\n",
            " [49 73]\n",
            " [51 76]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LHQN8NwVWF53",
        "outputId": "2553a740-5b2b-4618-eb2d-e777ef37dd28"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(1, 2)))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, Y, epochs=100, validation_split=0.2, batch_size=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 1054.7881 - val_loss: 3771.6538\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1010.1140 - val_loss: 3612.6680\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 970.6162 - val_loss: 3402.6282\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 917.3538 - val_loss: 3182.6121\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 864.6539 - val_loss: 2965.8157\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 806.8895 - val_loss: 2749.0911\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 745.0426 - val_loss: 2501.8496\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 679.3784 - val_loss: 2225.8843\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 592.8439 - val_loss: 1911.0959\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 497.8332 - val_loss: 1559.3728\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 408.4855 - val_loss: 1179.1250\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 298.8475 - val_loss: 795.5992\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 203.6977 - val_loss: 424.1950\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 119.8472 - val_loss: 174.0549\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 57.6259 - val_loss: 61.5115\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 26.7388 - val_loss: 17.1282\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 13.1401 - val_loss: 2.5291\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.8493 - val_loss: 1.6864\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.7728 - val_loss: 4.7181\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.1308 - val_loss: 7.1815\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.2200 - val_loss: 9.0063\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.1953 - val_loss: 9.1534\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.1242 - val_loss: 7.7836\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.0101 - val_loss: 6.7728\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9215 - val_loss: 6.0027\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8486 - val_loss: 5.6951\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7848 - val_loss: 5.3896\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7218 - val_loss: 5.0736\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6731 - val_loss: 4.6921\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.6199 - val_loss: 4.6110\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5803 - val_loss: 4.2687\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5202 - val_loss: 4.3024\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4664 - val_loss: 4.2602\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4250 - val_loss: 4.1243\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3766 - val_loss: 4.2811\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3236 - val_loss: 4.0528\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2772 - val_loss: 3.8504\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2299 - val_loss: 3.6816\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1921 - val_loss: 3.7615\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.1421 - val_loss: 3.8064\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.0951 - val_loss: 3.7140\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.0528 - val_loss: 3.3887\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.0120 - val_loss: 3.2863\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.9663 - val_loss: 3.1704\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.9323 - val_loss: 3.0321\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.8860 - val_loss: 3.0515\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.8521 - val_loss: 3.1275\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.8159 - val_loss: 2.7615\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.7783 - val_loss: 2.6065\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.7301 - val_loss: 2.8402\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6919 - val_loss: 2.8292\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6652 - val_loss: 3.0506\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6187 - val_loss: 2.7943\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.5822 - val_loss: 2.6506\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.5451 - val_loss: 2.6379\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.5300 - val_loss: 2.7854\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.4734 - val_loss: 2.4123\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.4395 - val_loss: 2.3318\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.4033 - val_loss: 2.1726\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3748 - val_loss: 2.2030\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3413 - val_loss: 2.1231\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3186 - val_loss: 2.1206\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.2795 - val_loss: 1.8182\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.2510 - val_loss: 1.8020\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.2275 - val_loss: 1.6196\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1834 - val_loss: 1.6866\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1606 - val_loss: 1.9331\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1261 - val_loss: 2.0961\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1005 - val_loss: 2.1275\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0687 - val_loss: 1.9164\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0412 - val_loss: 1.7514\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0126 - val_loss: 1.7998\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9830 - val_loss: 1.8062\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9574 - val_loss: 1.7411\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9294 - val_loss: 1.7440\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9023 - val_loss: 1.6429\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8805 - val_loss: 1.6265\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.8528 - val_loss: 1.4058\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8286 - val_loss: 1.4268\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8075 - val_loss: 1.3238\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7841 - val_loss: 1.4551\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.7623 - val_loss: 1.3231\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7339 - val_loss: 1.3257\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7131 - val_loss: 1.3829\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6960 - val_loss: 1.4921\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6659 - val_loss: 1.3680\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6422 - val_loss: 1.2343\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6196 - val_loss: 1.1872\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6033 - val_loss: 1.1251\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.5816 - val_loss: 1.1941\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.5609 - val_loss: 1.0744\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.5408 - val_loss: 0.9745\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.5172 - val_loss: 1.0388\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4956 - val_loss: 1.1477\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.4790 - val_loss: 1.1741\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4612 - val_loss: 1.1344\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4410 - val_loss: 1.1033\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4225 - val_loss: 0.9942\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.4033 - val_loss: 0.9153\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.3880 - val_loss: 0.8677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5475464080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1tmFLS1dWLrD",
        "outputId": "262be8c0-0f60-4287-d951-92156375156b"
      },
      "source": [
        "test_input = array([40, 60])\n",
        "test_input = test_input.reshape((1, 1, 2))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f54762b96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[40.960423 62.027683]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n8MrhIcWPyy"
      },
      "source": [
        "####many-to-many"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTmY6UjzXIZe"
      },
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x for x in range(5, 301, 5)]\n",
        "Y = [y for y in range(20, 316, 5)]\n",
        "import numpy as np\n",
        "X = np.array(X).reshape(20, 3, 1)\n",
        "Y = np.array(Y).reshape(20, 3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "sLy9KBD6XITZ",
        "outputId": "dc790370-6e26-4d6b-9757-e8e27ef9e81f"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5],\n",
              "       [10],\n",
              "       [15]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "U8a7tUEPXINM",
        "outputId": "7da2b6c2-a641-4bc9-d6ca-3c04a1d5df09"
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20],\n",
              "       [25],\n",
              "       [30]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "bMKrFDIFXIGr",
        "outputId": "40cdfb54-e9f7-439f-dd10-0f5086a4922d"
      },
      "source": [
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "\n",
        "# encoder layer\n",
        "model.add(LSTM(100, activation='relu', input_shape=(3, 1)))\n",
        "\n",
        "# repeat vector\n",
        "model.add(RepeatVector(3))\n",
        "\n",
        "# decoder layer\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 100)               40800     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 3, 100)            80400     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 3, 1)              101       \n",
            "=================================================================\n",
            "Total params: 121,301\n",
            "Trainable params: 121,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "LwVtllPuXIAL",
        "outputId": "74e777be-cfb0-4672-db10-c9fa8873d108"
      },
      "source": [
        "X1 = [300, 305, 310]\n",
        "X2 = [315, 320, 325]\n",
        "\n",
        "test_input = np.column_stack((X1, X2))\n",
        "print(test_input)\n",
        "\n",
        "test_input = test_input.reshape((1, 3, 2))\n",
        "print(test_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[300 315]\n",
            " [305 320]\n",
            " [310 325]]\n",
            "[[[300 315]\n",
            "  [305 320]\n",
            "  [310 325]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M6zKx08J0O4"
      },
      "source": [
        "##################33333#############################3333###MNSIT#####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-vhnyNcjygh"
      },
      "source": [
        "from keras.utils import np_utils \n",
        "from keras.datasets import mnist \n",
        "import seaborn as sns\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4S042X8jyaY"
      },
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBsa3TFjyUJ"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "nsVK7Jd4jyNy",
        "outputId": "04c6574e-4e78-42aa-978d-21e443901cf8"
      },
      "source": [
        "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
        "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples : 60000 and each image is of shape (28, 28)\n",
            "Number of training examples : 10000 and each image is of shape (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "krYosa-sjyGz",
        "outputId": "95dc6304-1795-4c84-fecd-628032f851db"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZQByK_jx9h"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "1M1xkMmjkof0",
        "outputId": "046d73e0-9906-481d-cc0e-fc8cd0f1228b"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDth99BRk92x"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OE1YlI32lE_W",
        "outputId": "7730a49d-ad59-476a-8ec5-b40345b9e234"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215686\n",
            " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
            " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313725\n",
            " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1372549  0.94509804\n",
            " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            " 0.58823529 0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.58039216\n",
            " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058824\n",
            " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
            " 0.31372549 0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333333 0.99215686\n",
            " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "rmU5MegdlH6h",
        "outputId": "e019c25f-e313-4825-fcbd-3469afb09719"
      },
      "source": [
        "print(\"Class label of first image :\", y_train[0])\n",
        "\n",
        "\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10) \n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(\"After converting the output into a vector : \",Y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label of first image : 5\n",
            "After converting the output into a vector :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v19ejKu3lNHK"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Activation "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NTTh47zlaOl"
      },
      "source": [
        "output_dim = 10\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "batch_size = 128 \n",
        "nb_epoch = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5lHd9AOkleMS",
        "outputId": "ee7b8b5e-54da-41d0-a2dc-194c6fe04a33"
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "LhTLCpY_lg5-",
        "outputId": "f73e6b6f-d6f8-43a0-fc4e-f200b4c9f05f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2890 - accuracy: 0.6965 - val_loss: 0.8157 - val_accuracy: 0.8314\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7184 - accuracy: 0.8405 - val_loss: 0.6086 - val_accuracy: 0.8616\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.8591 - val_loss: 0.5264 - val_accuracy: 0.8746\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.8685 - val_loss: 0.4805 - val_accuracy: 0.8829\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.8750 - val_loss: 0.4505 - val_accuracy: 0.8876\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8795 - val_loss: 0.4286 - val_accuracy: 0.8917\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8834 - val_loss: 0.4123 - val_accuracy: 0.8948\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.8867 - val_loss: 0.3997 - val_accuracy: 0.8972\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4155 - accuracy: 0.8888 - val_loss: 0.3889 - val_accuracy: 0.8997\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4054 - accuracy: 0.8907 - val_loss: 0.3803 - val_accuracy: 0.9007\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3970 - accuracy: 0.8929 - val_loss: 0.3725 - val_accuracy: 0.9027\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3896 - accuracy: 0.8944 - val_loss: 0.3665 - val_accuracy: 0.9031\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 0.8952 - val_loss: 0.3608 - val_accuracy: 0.9045\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3776 - accuracy: 0.8969 - val_loss: 0.3557 - val_accuracy: 0.9059\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3725 - accuracy: 0.8981 - val_loss: 0.3516 - val_accuracy: 0.9065\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8993 - val_loss: 0.3476 - val_accuracy: 0.9070\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.9005 - val_loss: 0.3438 - val_accuracy: 0.9081\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.9010 - val_loss: 0.3409 - val_accuracy: 0.9082\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.9017 - val_loss: 0.3378 - val_accuracy: 0.9082\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.9027 - val_loss: 0.3350 - val_accuracy: 0.9095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "Vv10uhG2lu_g",
        "outputId": "b2a18d13-66c1-4a84-fb36-9ac4d6df8015"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "\n",
        "x = list(range(1,nb_epoch+1))\n",
        "\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.33497336506843567\n",
            "Test accuracy: 0.909500002861023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='cf3b55c4-11da-4104-8956-94428d79a79a'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Aq7nvziwmAag",
        "outputId": "93c40377-fe16-42af-a529-c6d26392a80b"
      },
      "source": [
        "model_sigmoid = Sequential()\n",
        "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
        "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
        "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_sigmoid.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "QCrbetFUmLYh",
        "outputId": "5c179705-2831-4770-b058-4e1cce177120"
      },
      "source": [
        "model_sigmoid.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2692 - accuracy: 0.2270 - val_loss: 2.2258 - val_accuracy: 0.3802\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 2.1842 - accuracy: 0.4252 - val_loss: 2.1319 - val_accuracy: 0.5535\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 2.0737 - accuracy: 0.5449 - val_loss: 1.9974 - val_accuracy: 0.5584\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.9149 - accuracy: 0.6010 - val_loss: 1.8072 - val_accuracy: 0.6420\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.7043 - accuracy: 0.6499 - val_loss: 1.5751 - val_accuracy: 0.6695\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.4721 - accuracy: 0.6980 - val_loss: 1.3451 - val_accuracy: 0.7389\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.2620 - accuracy: 0.7405 - val_loss: 1.1540 - val_accuracy: 0.7672\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.0939 - accuracy: 0.7694 - val_loss: 1.0073 - val_accuracy: 0.7858\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.9655 - accuracy: 0.7885 - val_loss: 0.8958 - val_accuracy: 0.8077\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.8671 - accuracy: 0.8043 - val_loss: 0.8098 - val_accuracy: 0.8205\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.7902 - accuracy: 0.8169 - val_loss: 0.7415 - val_accuracy: 0.8278\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.7284 - accuracy: 0.8267 - val_loss: 0.6866 - val_accuracy: 0.8414\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.6780 - accuracy: 0.8359 - val_loss: 0.6403 - val_accuracy: 0.8467\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.6362 - accuracy: 0.8433 - val_loss: 0.6018 - val_accuracy: 0.8541\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.6009 - accuracy: 0.8505 - val_loss: 0.5692 - val_accuracy: 0.8599\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5710 - accuracy: 0.8562 - val_loss: 0.5421 - val_accuracy: 0.8654\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5453 - accuracy: 0.8612 - val_loss: 0.5178 - val_accuracy: 0.8709\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5230 - accuracy: 0.8657 - val_loss: 0.4966 - val_accuracy: 0.8733\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5035 - accuracy: 0.8706 - val_loss: 0.4794 - val_accuracy: 0.8781\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.4865 - accuracy: 0.8730 - val_loss: 0.4628 - val_accuracy: 0.8798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "kEOhmCodmPZ9",
        "outputId": "a2b27f58-1b0e-43ff-adc4-d7ed43bb6be8"
      },
      "source": [
        "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "x = list(range(1,nb_epoch+1))\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.4627963900566101\n",
            "Test accuracy: 0.879800021648407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='eda23b41-7334-48f9-b0a6-01f600ce983a'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGZDCjXYmYrX",
        "outputId": "1dbb82bd-cd5d-4590-bd90-72105eebc21d"
      },
      "source": [
        "w_after = model_sigmoid.get_weights()\n",
        "\n",
        "h1_w = w_after[0].flatten().reshape(-1,1)\n",
        "h2_w = w_after[2].flatten().reshape(-1,1)\n",
        "out_w = w_after[4].flatten().reshape(-1,1)\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.title(\"Weight matrices after model trained\")\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=h1_w,color='b')\n",
        "plt.xlabel('Hidden Layer 1')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=h2_w, color='r')\n",
        "plt.xlabel('Hidden Layer 2 ')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=out_w,color='y')\n",
        "plt.xlabel('Output Layer ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='3cc24971-e365-433c-8819-85a3e5d2a385'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "Vjd8Pdc5mkpQ",
        "outputId": "285e32d5-3a7b-45aa-9dc4-3af385655ac8"
      },
      "source": [
        "##\n",
        "model_sigmoid = Sequential()\n",
        "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
        "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
        "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_sigmoid.summary()\n",
        "\n",
        "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5297 - accuracy: 0.8647 - val_loss: 0.2494 - val_accuracy: 0.9282\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.2200 - accuracy: 0.9356 - val_loss: 0.1813 - val_accuracy: 0.9447\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1623 - accuracy: 0.9520 - val_loss: 0.1468 - val_accuracy: 0.9563\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1261 - accuracy: 0.9622 - val_loss: 0.1192 - val_accuracy: 0.9626\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0986 - accuracy: 0.9711 - val_loss: 0.1071 - val_accuracy: 0.9661\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0785 - accuracy: 0.9770 - val_loss: 0.0944 - val_accuracy: 0.9694\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.0855 - val_accuracy: 0.9727\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0507 - accuracy: 0.9849 - val_loss: 0.0754 - val_accuracy: 0.9775\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 0.0729 - val_accuracy: 0.9777\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.9794\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0658 - val_accuracy: 0.9805\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.0701 - val_accuracy: 0.9796\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0680 - val_accuracy: 0.9802\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0678 - val_accuracy: 0.9801\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0748 - val_accuracy: 0.9799\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0717 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0704 - val_accuracy: 0.9827\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0843 - val_accuracy: 0.9786\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0803 - val_accuracy: 0.9793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "txTxl5UXmvcn",
        "outputId": "969b99b8-08f6-4e27-c227-35bd1e4874a0"
      },
      "source": [
        "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "\n",
        "x = list(range(1,nb_epoch+1))\n",
        "\n",
        "\n",
        "\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.08029264956712723\n",
            "Test accuracy: 0.9793000221252441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='c85928c2-25fd-4d3c-b238-d6a05e39db2a'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WTkf4McSuCQl",
        "outputId": "e474c8e5-c565-466d-c9e6-86f63460472e"
      },
      "source": [
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "\n",
        "x = list(range(1,nb_epoch+1))\n",
        "\n",
        "\n",
        "\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='c63e1ef1-75b8-41e4-b1b1-78cf7ffac5e4'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "iBY3GDd8uLLO",
        "outputId": "b2278045-c98b-4d47-d714-898e430358aa"
      },
      "source": [
        "w_after = model_relu.get_weights()\n",
        "\n",
        "h1_w = w_after[0].flatten().reshape(-1,1)\n",
        "h2_w = w_after[2].flatten().reshape(-1,1)\n",
        "out_w = w_after[4].flatten().reshape(-1,1)\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.title(\"Weight matrices after model trained\")\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=h1_w,color='b')\n",
        "plt.xlabel('Hidden Layer 1')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=h2_w, color='r')\n",
        "plt.xlabel('Hidden Layer 2 ')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Trained model Weights\")\n",
        "ax = sns.violinplot(y=out_w,color='y')\n",
        "plt.xlabel('Output Layer ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b284bda0b418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_relu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh1_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh2_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_relu' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "yXa6_7tUuSzv",
        "outputId": "20d29221-1131-4d1f-d2e8-726d5e30b0ff"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "model_batch = Sequential()\n",
        "\n",
        "model_batch.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
        "model_batch.add(BatchNormalization())\n",
        "\n",
        "model_batch.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
        "model_batch.add(BatchNormalization())\n",
        "\n",
        "model_batch.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "\n",
        "model_batch.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 471,434\n",
            "Trainable params: 470,154\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "BcLFDmqPujla",
        "outputId": "df0c3d36-edd7-4cb4-905b-9cad6b398a66"
      },
      "source": [
        "score = model_batch.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "# list of epoch numbers\n",
        "x = list(range(1,nb_epoch+1))\n",
        "\n",
        "# print(history.history.keys())\n",
        "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
        "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
        "# val_loss : validation loss\n",
        "# val_acc : validation accuracy\n",
        "\n",
        "# loss : training loss\n",
        "# acc : train accuracy\n",
        "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
        "\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3f59db374a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTjwtlswuq-N"
      },
      "source": [
        "###############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb0o0-giP74w"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXNTeeTkP7xW"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUunYTQ4P7o8"
      },
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YriwXT5uP7hJ",
        "outputId": "f357c957-c287-4ba6-c9cf-a5a1fa134923"
      },
      "source": [
        "print(x_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6i8dq-wP7Y6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWSrh8j3QZWe"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as pl\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwE8QqJco0Du"
      },
      "source": [
        "opt=tf.keras.optimizers.Adagrad(learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07, name=\"Adagrad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mco0G9vCpAre"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "1vxRSS6xpiPT",
        "outputId": "59a3c3d5-c434-4476-cb7a-f78f5954ad36"
      },
      "source": [
        "h1 = model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 2.3024 - accuracy: 0.1133 - val_loss: 2.3011 - val_accuracy: 0.1477\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 49s 506ms/step - loss: 2.3013 - accuracy: 0.1269 - val_loss: 2.2999 - val_accuracy: 0.1620\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 2.3002 - accuracy: 0.1385 - val_loss: 2.2990 - val_accuracy: 0.1840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpM8jIiSpiIe"
      },
      "source": [
        "opt=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6hPV1DDp26r"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "VJHAzCR_p2zy",
        "outputId": "091024fe-fe13-4055-c5ac-0bdc38f0c3f5"
      },
      "source": [
        "h2 = model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 2.2983 - accuracy: 0.1517 - val_loss: 2.2959 - val_accuracy: 0.2066\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 2.2958 - accuracy: 0.1643 - val_loss: 2.2932 - val_accuracy: 0.2031\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 2.2930 - accuracy: 0.1730 - val_loss: 2.2903 - val_accuracy: 0.1960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLDFV54op9O9"
      },
      "source": [
        "opt=tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdCxK376p9IE"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "nwe9PC9yp9An",
        "outputId": "42f761cb-a717-4252-ec49-d3a55ad9eac5"
      },
      "source": [
        "h3 = model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 1.4929 - accuracy: 0.4702 - val_loss: 0.6583 - val_accuracy: 0.7873\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.5495 - accuracy: 0.8216 - val_loss: 0.2775 - val_accuracy: 0.9139\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 53s 550ms/step - loss: 0.3075 - accuracy: 0.9106 - val_loss: 0.2051 - val_accuracy: 0.9392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uJSzCFxpqHZJ",
        "outputId": "1b8d7440-fe6c-4c41-fe28-7abc503d2f71"
      },
      "source": [
        "plt.plot(h1.history['accuracy'])\n",
        "plt.plot(h2.history['accuracy'])\n",
        "plt.plot(h3.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Adagrad','SGDNestrov','ADAM'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVGfMtjsqHSO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5HAiwdCqfNF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-bcbkK2qfFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdsZzHGVqe-J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038yL_ktpIgy"
      },
      "source": [
        "opt=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "16Dm64Er96Fp",
        "outputId": "674dad0e-eaff-44b2-d5fa-be8fab23c0e6"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "l=[tf.keras.optimizers.Adagrad(learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07, name=\"Adagrad\")\n",
        ",tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\"),tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)]\n",
        "j=0\n",
        "for i in l:\n",
        "  j=j+1\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=i,metrics=['accuracy'])\n",
        "\n",
        "  historyj = model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "opt=['Adagrad','SGDNestrov','ADAM']\n",
        "for i in opt:\n",
        "  plt.plot(historyj.historyj['accuracy'])\n",
        "  #plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend([opt[i]], loc='upper left')\n",
        "  plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 2.3026 - accuracy: 0.1087 - val_loss: 2.3019 - val_accuracy: 0.1347\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 49s 505ms/step - loss: 2.3015 - accuracy: 0.1273 - val_loss: 2.3006 - val_accuracy: 0.1358\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 2.3005 - accuracy: 0.1402 - val_loss: 2.2994 - val_accuracy: 0.1307\n",
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 2.2982 - accuracy: 0.1464 - val_loss: 2.2953 - val_accuracy: 0.1142\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 48s 504ms/step - loss: 2.2946 - accuracy: 0.1501 - val_loss: 2.2915 - val_accuracy: 0.1240\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 48s 505ms/step - loss: 2.2912 - accuracy: 0.1558 - val_loss: 2.2874 - val_accuracy: 0.1387\n",
            "Epoch 1/3\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 1.4341 - accuracy: 0.5034 - val_loss: 0.5128 - val_accuracy: 0.8381\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 49s 505ms/step - loss: 0.4655 - accuracy: 0.8586 - val_loss: 0.2441 - val_accuracy: 0.9231\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 50s 524ms/step - loss: 0.2912 - accuracy: 0.9169 - val_loss: 0.1709 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6fc9f8832bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adagrad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SGDNestrov'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ADAM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistoryj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistoryj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;31m#plt.plot(history.history['val_accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'historyj'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "8_pNBUJVQcim",
        "outputId": "31b7a20f-92c9-45c0-e079-7c428727a891"
      },
      "source": [
        "opt=['Adagrad','SGDNestrov','ADAM']\n",
        "\n",
        "\n",
        "plt.plot(history.history1['accuracy'])\n",
        "plt.plot(history.history2['accuracy'])\n",
        "plt.plot(history.history3['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend('Adagrad','SGDNestrov','ADAM', loc='upper left')\n",
        "plt.show()  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-079275e1cf42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ_LuD0g8xXx"
      },
      "source": [
        "#######################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "If3FnQ-BeylU",
        "outputId": "e5617f0e-bfd3-4664-fb23-43d1cd4c40fa"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "\n",
        "opt=tf.keras.optimizers.Adagrad(learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07, name=\"Adagrad\")\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h1 = model.fit(x_train,y_train,validation_split = 0.2, epochs=30, batch_size=500)\n",
        "\n",
        "opt=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\")\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h2 = model.fit(x_train,y_train,validation_split = 0.2, epochs=30, batch_size=500)\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h3 = model.fit(x_train,y_train,validation_split = 0.2, epochs=30, batch_size=500)\n",
        "\n",
        "plt.plot(h1.history['accuracy'])\n",
        "plt.plot(h2.history['accuracy'])\n",
        "plt.plot(h3.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Adagrad','SGDNestrov','ADAM'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.3020 - accuracy: 0.1075 - val_loss: 2.3009 - val_accuracy: 0.1195\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 2.3007 - accuracy: 0.1068 - val_loss: 2.2994 - val_accuracy: 0.1218\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 2.2996 - accuracy: 0.1127 - val_loss: 2.2980 - val_accuracy: 0.1233\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 2.2985 - accuracy: 0.1144 - val_loss: 2.2967 - val_accuracy: 0.1277\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 2.2974 - accuracy: 0.1229 - val_loss: 2.2956 - val_accuracy: 0.1383\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.2963 - accuracy: 0.1290 - val_loss: 2.2945 - val_accuracy: 0.1576\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.2952 - accuracy: 0.1392 - val_loss: 2.2935 - val_accuracy: 0.1741\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 50s 517ms/step - loss: 2.2944 - accuracy: 0.1449 - val_loss: 2.2925 - val_accuracy: 0.1899\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 2.2937 - accuracy: 0.1504 - val_loss: 2.2914 - val_accuracy: 0.2107\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 53s 548ms/step - loss: 2.2924 - accuracy: 0.1580 - val_loss: 2.2904 - val_accuracy: 0.2214\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.2915 - accuracy: 0.1657 - val_loss: 2.2893 - val_accuracy: 0.2306\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.2905 - accuracy: 0.1714 - val_loss: 2.2881 - val_accuracy: 0.2383\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.2897 - accuracy: 0.1750 - val_loss: 2.2870 - val_accuracy: 0.2446\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 2.2886 - accuracy: 0.1788 - val_loss: 2.2857 - val_accuracy: 0.2493\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 2.2875 - accuracy: 0.1827 - val_loss: 2.2844 - val_accuracy: 0.2503\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.2862 - accuracy: 0.1868 - val_loss: 2.2830 - val_accuracy: 0.2541\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.2849 - accuracy: 0.1911 - val_loss: 2.2815 - val_accuracy: 0.2577\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.2835 - accuracy: 0.1971 - val_loss: 2.2799 - val_accuracy: 0.2600\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 2.2823 - accuracy: 0.2009 - val_loss: 2.2782 - val_accuracy: 0.2625\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.2807 - accuracy: 0.2004 - val_loss: 2.2764 - val_accuracy: 0.2647\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.2792 - accuracy: 0.2066 - val_loss: 2.2744 - val_accuracy: 0.2642\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 52s 546ms/step - loss: 2.2770 - accuracy: 0.2073 - val_loss: 2.2723 - val_accuracy: 0.2645\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 2.2753 - accuracy: 0.2103 - val_loss: 2.2700 - val_accuracy: 0.2667\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 2.2728 - accuracy: 0.2155 - val_loss: 2.2674 - val_accuracy: 0.2679\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 2.2705 - accuracy: 0.2189 - val_loss: 2.2645 - val_accuracy: 0.2686\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 2.2679 - accuracy: 0.2184 - val_loss: 2.2614 - val_accuracy: 0.2686\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 50s 517ms/step - loss: 2.2656 - accuracy: 0.2194 - val_loss: 2.2579 - val_accuracy: 0.2690\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 2.2622 - accuracy: 0.2229 - val_loss: 2.2540 - val_accuracy: 0.2695\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 49s 516ms/step - loss: 2.2583 - accuracy: 0.2259 - val_loss: 2.2496 - val_accuracy: 0.2696\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 2.2541 - accuracy: 0.2282 - val_loss: 2.2445 - val_accuracy: 0.2682\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 49s 516ms/step - loss: 2.2431 - accuracy: 0.2375 - val_loss: 2.2212 - val_accuracy: 0.2706\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 50s 519ms/step - loss: 2.2172 - accuracy: 0.2478 - val_loss: 2.1838 - val_accuracy: 0.2720\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 50s 517ms/step - loss: 2.1781 - accuracy: 0.2569 - val_loss: 2.1327 - val_accuracy: 0.2870\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 53s 553ms/step - loss: 2.1359 - accuracy: 0.2687 - val_loss: 2.0815 - val_accuracy: 0.3042\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 2.0917 - accuracy: 0.2799 - val_loss: 2.0193 - val_accuracy: 0.3310\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 2.0409 - accuracy: 0.2869 - val_loss: 1.9375 - val_accuracy: 0.3580\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 49s 515ms/step - loss: 1.9715 - accuracy: 0.3058 - val_loss: 1.8330 - val_accuracy: 0.4012\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 1.8786 - accuracy: 0.3350 - val_loss: 1.7199 - val_accuracy: 0.4224\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 50s 518ms/step - loss: 1.7821 - accuracy: 0.3659 - val_loss: 1.6061 - val_accuracy: 0.4553\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 50s 517ms/step - loss: 1.6852 - accuracy: 0.3950 - val_loss: 1.4746 - val_accuracy: 0.5020\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 50s 517ms/step - loss: 1.5656 - accuracy: 0.4375 - val_loss: 1.3554 - val_accuracy: 0.5321\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 50s 518ms/step - loss: 1.4284 - accuracy: 0.4869 - val_loss: 1.1660 - val_accuracy: 0.5978\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 50s 516ms/step - loss: 1.3005 - accuracy: 0.5373 - val_loss: 1.0424 - val_accuracy: 0.6574\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 50s 520ms/step - loss: 1.1923 - accuracy: 0.5786 - val_loss: 0.9053 - val_accuracy: 0.7052\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 50s 520ms/step - loss: 1.0770 - accuracy: 0.6217 - val_loss: 0.7761 - val_accuracy: 0.7411\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 54s 564ms/step - loss: 0.9829 - accuracy: 0.6548 - val_loss: 0.6974 - val_accuracy: 0.7718\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.8965 - accuracy: 0.6900 - val_loss: 0.6483 - val_accuracy: 0.7797\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.8170 - accuracy: 0.7199 - val_loss: 0.5801 - val_accuracy: 0.8043\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.7440 - accuracy: 0.7455 - val_loss: 0.5209 - val_accuracy: 0.8232\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.7158 - accuracy: 0.7628 - val_loss: 0.4756 - val_accuracy: 0.8412\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.6415 - accuracy: 0.7874 - val_loss: 0.4003 - val_accuracy: 0.8709\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.5844 - accuracy: 0.8089 - val_loss: 0.3892 - val_accuracy: 0.8794\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.5571 - accuracy: 0.8210 - val_loss: 0.3650 - val_accuracy: 0.8847\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.5050 - accuracy: 0.8418 - val_loss: 0.3065 - val_accuracy: 0.9018\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.4778 - accuracy: 0.8519 - val_loss: 0.2817 - val_accuracy: 0.9072\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.4557 - accuracy: 0.8599 - val_loss: 0.2908 - val_accuracy: 0.9073\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 0.4062 - accuracy: 0.8761 - val_loss: 0.2377 - val_accuracy: 0.9260\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 53s 547ms/step - loss: 0.3989 - accuracy: 0.8796 - val_loss: 0.2709 - val_accuracy: 0.9193\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.3554 - accuracy: 0.8941 - val_loss: 0.2532 - val_accuracy: 0.9203\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.3402 - accuracy: 0.8993 - val_loss: 0.2214 - val_accuracy: 0.9312\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.4592 - accuracy: 0.8659 - val_loss: 0.1931 - val_accuracy: 0.9422\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.2450 - accuracy: 0.9296 - val_loss: 0.1594 - val_accuracy: 0.9517\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.2005 - accuracy: 0.9434 - val_loss: 0.1289 - val_accuracy: 0.9613\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 0.1667 - accuracy: 0.9531 - val_loss: 0.1089 - val_accuracy: 0.9688\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.1364 - accuracy: 0.9634 - val_loss: 0.1067 - val_accuracy: 0.9686\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.1184 - accuracy: 0.9671 - val_loss: 0.1026 - val_accuracy: 0.9711\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.1046 - accuracy: 0.9708 - val_loss: 0.0916 - val_accuracy: 0.9743\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.0979 - accuracy: 0.9729 - val_loss: 0.0949 - val_accuracy: 0.9762\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.0835 - accuracy: 0.9766 - val_loss: 0.0752 - val_accuracy: 0.9787\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 0.0817 - accuracy: 0.9770 - val_loss: 0.0753 - val_accuracy: 0.9787\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 52s 542ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.0725 - val_accuracy: 0.9814\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.0635 - accuracy: 0.9815 - val_loss: 0.0706 - val_accuracy: 0.9819\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.0580 - accuracy: 0.9837 - val_loss: 0.0635 - val_accuracy: 0.9831\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 0.0621 - val_accuracy: 0.9845\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.0551 - accuracy: 0.9844 - val_loss: 0.0689 - val_accuracy: 0.9839\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 0.0465 - accuracy: 0.9864 - val_loss: 0.0624 - val_accuracy: 0.9837\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 0.0667 - val_accuracy: 0.9852\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 0.0808 - accuracy: 0.9777 - val_loss: 0.0861 - val_accuracy: 0.9781\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 0.0594 - accuracy: 0.9833 - val_loss: 0.0651 - val_accuracy: 0.9847\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.0678 - val_accuracy: 0.9857\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.0675 - val_accuracy: 0.9843\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0669 - val_accuracy: 0.9843\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 53s 549ms/step - loss: 0.0499 - accuracy: 0.9861 - val_loss: 0.0666 - val_accuracy: 0.9839\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0586 - val_accuracy: 0.9869\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.0592 - val_accuracy: 0.9867\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0620 - val_accuracy: 0.9861\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0557 - val_accuracy: 0.9861\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0557 - val_accuracy: 0.9847\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0399 - accuracy: 0.9891 - val_loss: 0.0718 - val_accuracy: 0.9828\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.0724 - val_accuracy: 0.9849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HHmX6LBuue1w",
        "outputId": "6556cbea-7c41-4783-a9ed-645b273371df"
      },
      "source": [
        "plt.plot(h1.history['loss'])\n",
        "plt.plot(h2.history['loss'])\n",
        "plt.plot(h3.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Adagrad','SGDNestrov','ADAM'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deWBU1b3A8e9vJpM9JBBCIOz7IjuIAorWlaq44AIoVKgbrlWrtX1qq63ULrZasVWx7tqIdcNdqbhRKAKKgCyKEGQnLEnIPpk5749zM0wgQIBMbmby+7x3O3ebe383I/Obe86554gxBqWUUk2bx+0AlFJKuU+TgVJKKU0GSimlNBkopZRCk4FSSik0GSillEKTgVJ1JiLPiMh9ddw3T0ROO9rjKNVQNBkopZTSZKCUUkqTgYoxTvHM7SKyVERKRORJEckWkfdEZI+I/EdEmoftf66IfCMiBSLyiYj0Dts2SES+dN43E0jc51zniMgS573zRKT/EcZ8lYisEZFdIvKmiOQ460VEHhSR7SJSJCLLRKSvs+0sEVnhxLZJRG47oj+YUg5NBioWXQicDvQAxgDvAf8HZGH/m78JQER6ALnAzc62d4G3RCReROKBN4DngRbAv53j4rx3EPAUcA2QCTwOvCkiCYcTqIicAtwPXAK0AdYDLzmbzwBGOdeR7uyz09n2JHCNMSYN6AvMOZzzKrUvTQYqFk03xmwzxmwCPgcWGGO+MsaUA68Dg5z9xgHvGGNmG2P8wANAEjACOB7wAQ8ZY/zGmFeAhWHnuBp43BizwBgTMMY8C1Q47zsclwFPGWO+NMZUAL8ChotIJ8APpAG9ADHGrDTGbHHe5wf6iEgzY8xuY8yXh3lepWrQZKBi0baw+bJallOd+RzsL3EAjDFBYAPQ1tm2ydTsyXF92HxH4OdOEVGBiBQA7Z33HY59YyjG/vpva4yZAzwC/B3YLiIzRKSZs+uFwFnAehH5VESGH+Z5lapBk4FqyjZjv9QBW0aP/ULfBGwB2jrrqnUIm98ATDPGZIRNycaY3KOMIQVb7LQJwBjzsDFmCNAHW1x0u7N+oTHmPKAVtjjr5cM8r1I1aDJQTdnLwNkicqqI+ICfY4t65gHzgSrgJhHxichYYFjYe58AporIcU5Fb4qInC0iaYcZQy4wRUQGOvUNv8cWa+WJyLHO8X1ACVAOBJ06jctEJN0p3ioCgkfxd1BKk4Fquowxq4GJwHRgB7ayeYwxptIYUwmMBSYDu7D1C6+FvXcRcBW2GGc3sMbZ93Bj+A9wN/Aq9m6kKzDe2dwMm3R2Y4uSdgJ/drZNAvJEpAiYiq17UOqIiQ5uo5RSSu8MlFJKaTJQSimlyUAppRSaDJRSSgFxbgdwuFq2bGk6derkdhhKKRVVFi9evMMYk3Wg7VGXDDp16sSiRYvcDkMppaKKiKw/2HYtJlJKKaXJQCmllCYDpZRSRGGdQW38fj8bN26kvLzc7VCanMTERNq1a4fP53M7FKXUUYiJZLBx40bS0tLo1KkTNTuZVJFkjGHnzp1s3LiRzp07ux2OUuooxEQxUXl5OZmZmZoIGpiIkJmZqXdkSsWAmEgGgCYCl+jfXanYEBPFRHVR7g9QUOqn+rtLnP8RZ6nmMs5+Eto3/DtPnB0kbIWEb3NW1FgXtgxSy/H2jyXs5ZDb9UtZKXU0mlQy2L4nssUZc95/h1uumsgbHy+gc7ce+22/4uJzuPWu33HMgEG1vPvoHCgJ3XnLtZx02mjOPOd8wnap+T7Z5xi1bNtn1jmOXZO/p4LfPD4fj4DXI3hE8HoErwgigtdj14uTQD0ieMS+Sti8x0PNZbFJ0yuCx2Pnq9/rFYEa+9r3Vu9TfZ7w93ic2Dw1znmA+bB9vGHnrp73hvYPv1Z7nV7P3veH/z2qr9FbffzQvtTcRzS5q4bXZJJBRnI8GcnxVI/fYJz/qV6qHtahenQHY/YuHWhbaCQI5zj3fjCL4SNG8r/Zb3Hq8b/eu7/zP4k+L23Sk+jYIpnwUSQOFMv+57Rr/FVVxHnj9jt+bTHFx3lJTogjPSmuxjn3nq/meTCm5n77nX/fuIy9cwKCQfAHggSChqCxUyAIwbBl45y3ejkYtMcIGmrsE6xeF3ovoW0BYwgEY3scjtoSqycs0Xg9e5NWKKFUb6slMVXPe8PnnW1x1fMeO199fK/HY19FQvPV+8R5PPbVW/0qtSx7QseunuI8HjweiPN4nOW923xewef1EOf14Ks+lleI9+49jibJyGkyyaBa9X9MNX/1Hv1/YMXFxfxv3n/5+OOPGTNmDPdP+x1lZWVMmTKFr7/+ml69elFZUU5qYhzpyfFce+21LFy4kLKyMi666CLuvfdeAN59911uvfVWUlJSGDlyJGvXruXtt9/mnnvu4fvvv2ft2rV06NCB+++/n0mTJlFSUgLAI488wogRIzDGcOONNzJ79mzat29PfHw8mSnxtG2efNTXeCAVOxKYec3AiB3/YGpLJNXJJJR0gnuTSHiyCQRrzocnm2AwLGEZnH33zu9NdnuTWsA5VyAskQWcZeMkxr3ze89fndxs4tvnOGHHqF4XnmAD1THvFxNh++9dXxUMUlFlCBgIBIOhY1UFg6FrC4Sds3re7lNznRt81UmmOnF4qhOI7DPv2S+5+MKTi7PN592b1Goee+8x4sLO4/N6iI9zJmc+IWw5wRe+3ovPGz0JLOaSwb1vfcOKzUX1esw+Oc34zZhjDrrPrFmzGD16ND169CAzM5PFixfz6aefkpyczMqVK1m6dCmDBw8O7T9t2jRatGhBIBDg1FNPZenSpfTo0YNrrrmGzz77jM6dOzNhwoQa51ixYgVz584lKSmJ0tJSZs+eTWJiIt999x0TJkxg0aJFvP7666xevZoVK1awbds2+vTpw09/+tN6/Xs0JiKCV8BbDwld1Z0xTnIIGvyBIFUBu1wVDJsPBAkYQ1WgZnKpuRwMLfud9/gDQfwBO18VNFRWHz8QpDJg3+MP7D1XzXn7nuqY/IEgJZWB0HGrAmHHCwaprNp7LH+g/hOcCCTEeUj0eUlwEkRCnE0aiXFeEnx2XWJo2Zn3eUmMC5t3Xntkp9G7TbN6jxNiMBkckDFgqkC8IPXfiCo3N5ef/exnAIwfP57c3FzWrFnDTTfdBED//v3p379/aP+XX36ZGTNmUFVVxZYtW1ixYgXBYJAuXbqE2uxPmDCBGTNmhN5z7rnnkpSUBNgH7W644QaWLFmC1+vl22+/BeCzzz5jwoQJeL1ecnJyOOWUU+r9WpUSqS7WscWfsSKU3EKJqWai8QcMlVVBKgMBKqpsMrHLQSr89rV6XUWV3aeiKkiF386X+8PWVQWo8AcpLPNT7rfbyv123/KqQK3J6dqTu2oyqKsD/oIv3QkFP9h58YAvGeJTnNdk8MYf8Tl37drFnDlzWLZsGSJCIBBARBg0qPaK4nXr1vHAAw+wcOFCmjdvzuTJk+vUVj8lJSU0/+CDD5Kdnc3XX39NMBgkMTHxiONXSlm2/qJxJLdA0DgJIkC5k0jSEiP3lR0zzxkcUlILyOoNGR3svAlA8XbYvQ62fQNbl8OutVC8DSqKbW1oHb3yyitMmjSJ9evXk5eXx4YNG+jcuTNDhgzhX//6FwDLly9n6dKlABQVFZGSkkJ6ejrbtm3jvffeA6Bnz56sXbuWvLw8AGbOnHnAcxYWFtKmTRs8Hg/PP/88gUAAgFGjRjFz5kwCgQBbtmzh448/PpK/llLKZV6PkJIQR2ZqAm0zkuialUqrtMj96Iu5O4MDEgFfop2SM+26YBCqyqCyBCpLwV8C5YXO/h5IaAZJGfb1IL8WcnNzueOOO2qsu/DCC/nqq68oKyujd+/e9O7dmyFDhgAwYMAABg0aRK9evWjfvj0jR44EICkpiX/84x+MHj2alJQUjj322AOe87rrruPCCy/kueeeC+0PcMEFFzBnzhz69OlDhw4dGD58+JH+xZRSTYhUN7WMFkOHDjX7Dm6zcuVKevfuXT8nCPjBX2qTQnkhBKsAcRJDOiSmgydyObS4uJjU1FSMMVx//fV0796dW265JWLnqw/1+vdXSkWEiCw2xgw90Pamc2dQV14feJ0vfWPsXUN5AZQVQEUhNjGkQmKG3cdbv711PvHEEzz77LNUVlYyaNAgrrnmmno9vlJK1UaTwcGI88WfkArN2jp3DE5iKNxgp/hUW5SU2By8R//nvOWWWxr9nYBSKvZoMqgrEdv6KD4F0nJsXUNZIZTvhsKNULgJEtIgqblTlNQ4WiQopVRdaDI4EiK2SaovGdJag78MynbbqaII8EBiMycxNIvIcw1KKVWfNBkcLRH7nEJ8MjTLsXUMZbttcVJ5gX3ILSnDJob41JrdnyqlVCOhyaA+hdcxmLb2eYXqO4bSneDx2aSQ3AJ8SW5Hq5RSIVp+UY+mTZvGMcccQ//+/Rk4aDALvl5JVVpb/u/hXLqPuoiBp1/CwBGnMO2u22D7KijejtfrZeDAgRxzzDEMGDCAv/zlLwSdB94++eQTRIS33nordI5zzjmHTz755LBj++STT5g3b159XapSKsbonUE9mT9/Pm+//TZffvklCQkJ7Nixg8rKSu666y62bt3KsuXfkJiYyJ6CXfzlT/fbjlKLNpGUmMCSj16F5BZsL6zg0okTKSoqCvVi2q5dO6ZNm8aYMWOOKr5PPvmE1NRURowYsd+2qqoq4uL0PwWlmjK9M6gnW7ZsoWXLliQkJADQsmVLMjIyeOKJJ5g+fXqo76C0jBbc8/s/Q1YvO4nYCujdebQy25nxwD088sh0jHN3MGDAANLT05k9e/Z+51y8eDEnnXQSQ4YM4cwzz2TLli0APPzww/Tp04f+/fszfvx48vLyeOyxx3jwwQcZOHAgn3/+OZMnT2bq1Kkcd9xx/OIXv2DJkiUcf/zx9O/fnwsuuIDdu3ezatUqhg0bFjpfXl4e/fr1i/SfUinlgtj7OfjeL2Hrsvo9Zut+8OM/HHSXM844g9/+9rf06NGD0047jXHjxtG8eXM6dOhAWlpa7W/yJQEC2cdAZTGU7qJLtiFQ5Wf7iv/a5xmM4c477+Tuu+/m9NNPD73V7/dz4403MmvWLLKyspg5cyZ33nknTz31FH/4wx9Yt24dCQkJFBQUkJGRwdSpU0lNTeW2224D4Mknn2Tjxo3MmzcPr9dL//79mT59OieddBK//vWvuffee3nooYeorKxk3bp1dO7cmZkzZzJu3Lj6+qsqpRoRvTOoJ6mpqSxevJgZM2aQlZXFuHHj9ivbf/rppxk4cCDt27dnw4YNezeI2GcUmneE7L62KaoIlORD5R5GDegCJsjcuXNDb1m9ejXLly/n9NNPZ+DAgdx3331s3LgRsN1lX3bZZbzwwgsHLf65+OKL8Xq9FBYWUlBQwEknnQTA5ZdfzmeffQbAJZdcEuowT5OBUrEr9u4MDvELPpK8Xi8nn3wyJ598Mv369ePxxx/nhx9+YM+ePaSlpTFlyhSmTJlC3759Q72M7mtt3nq83jha9R7Bys17bAukkh3cee0E7vv1/xGXkGSHpjSGY445hvnz5+93jHfeeYfPPvuMt956i2nTprFsWe13SuFdYh/IuHHjuPjiixk7diwiQvfu3Q/vj6KUigp6Z1BPVq9ezXfffRdaXrJkCT179uSKK67ghhtuCI1XEAgEqKysrPUY+fn5TJ06lRtuuAHxeGwxki8Jso/hjHPGsrugwHaDvTuPnjnp5Ofnh5KB3+/nm2++IRgMsmHDBn70ox/xxz/+kcLCQoqLi0lLS2PPnj21njc9PZ3mzZvz+eefA/D888+H7hK6du2K1+vld7/7nd4VKBXDYu/OwCXFxcXceOONFBQUEBcXR7du3ZgxYwbp6encfffd9O3bl7S0NJKSkrj88svJyckBoKysjIEDB+L3+4mLi2PSpEnceuutNQ/u9UFaa+78ze847/zzwesjvmInr/xjGjf9/GYKS8qoqgpw880306NHDyZOnEhhYSHGGG666SYyMjIYM2YMF110EbNmzWL69On7xf/ss88ydepUSktL6dKlC08//XRo27hx47j99ttZt25dRP+GSin3RKwLaxFpDzwHZAMGmGGM+ds++wjwN+AsoBSYbIz58mDHjXgX1tHCX2brFEp32qec01pDSktXur5okn9/paLMobqwjuQ3RxXwc2NMH+B44HoR6bPPPj8GujvT1cCjEYwntviS7KhtWb1sVxhFm+yDbOVFbkemlIpCEUsGxpgt1b/yjTF7gJVA2312Ow94zlj/AzJEpE2kYopJviRo0RVadLHLu76Hnd+D/9BjKiulVLUGKVMQkU7AIGDBPpvaAmFtLNnI/gkDEblaRBaJyKL8/PxIhRm9RGy32a162XEXKksgf5XtWjtY5XZ0SqkoEPFkICKpwKvAzcaYIyrDMMbMMMYMNcYMzcrKqt8AY4l4ILUVtOptO8MryYdtK+xrlA1vqpRqWBFNBiLiwyaCF40xr9WyyyagfdhyO2edOhpen1Of0NMWIxVutHcK/jK3I1NKNVIRSwZOS6EngZXGmL8eYLc3gZ+IdTxQaIzZEqmYmhxfMmR2g+adbXHRjm+hdJfbUSmlGqFI3hmMBCYBp4jIEmc6S0SmishUZ593gbXAGuAJ4LoIxhNxb7zxBiLCqlWrANuxW1JSEoMGDaJ3794MGzaMZ555Zr/3DRw4kPHjx9dYN3nyZJKTk2s8KHbzzTcjIuzYsaPuQYnYwXWyetnkULAeCjaACR7RNSqlYlPEHjozxszFdtR8sH0McH2kYmhoubm5nHDCCeTm5oa6oO7atStfffUVAGvXrmXs2LEYY5gyZQpg2+gHAgE+//xzSkpKanQR0a1bN2bNmsXEiRMJBoPMmTOHtm33q1+vG6/P3iXs2QzF28FfCs07QVzCUV2zUio2aHcU9aS4uJi5c+fy5JNP8tJLL9W6T5cuXfjrX//Kww8/HFqXm5vLpEmTOOOMM5g1a1aN/cePHx/qJO6TTz5h5MiRRzfugIhtbdS8M1RVQP5qKC888uMppWJGzHVH8ccv/siqXavq9Zi9WvTijmF3HHSfWbNmMXr0aHr06EFmZiaLFy8mMzNzv/0GDx4cKkYC2xPo7NmzWbVqFdOnT+fSSy8NbevRowdvvvkmu3fvJjc3l4kTJ/Lee+8d/QUlZdiK5V3rYNdaSM2GtDY6PrNSTZjeGdST3NzcULn/+PHjyc3NrXW/8O4/Fi1aRMuWLenQoQOnnnoqX331Fbt21azgHTt2LC+99BILFizgxBNPrL+A4xKgZQ9IagHF22DnGgj46+/4SqmoEnN3Bof6BR8Ju3btYs6cOSxbtgwRIRAIICJcf/3+1SFfffVVqB+f3NxcVq1aRadOnQAoKiri1Vdf5aqrrgrtP27cOIYMGcLll1+Ox1PPudvjsWMoxKc4zU9X23qEhNT6PY9SqtHTO4N68MorrzBp0iTWr19PXl4eGzZsoHPnzjUHsMG2Lrrtttu48cYbCQaDvPzyyyxbtoy8vDzy8vKYNWvWfncUHTt2ZNq0aVx3XQQbWqW0tHcJIvYOoXi7PqSmVBMTc3cGbsjNzeWOO2rekVx44YXcf//9fP/99wwaNIjy8nLS0tK46aabmDx5Mp9++ilt27YNdWUNMGrUKFasWBEay7jaNddcE/mLiE+2D6ntXm87vfOXQXp7e/eglIp5EevCOlK0C+sIMwaKt8KerbaSuXkXiIs/6Fv0769U4+dmF9YqGonYlkUtukBVJexYDRW1j5CmlIodmgxU7RLTbT2Cx6v1CEo1ATGTDKKtuCsq+BKhZU9ISLf1CAU/QLBmNxb6d1cqNsREMkhMTGTnzp36xRQJHi+06GyH1SzbZTu7q6oAbCLYuXMniYmJLgeplDpaMdGaqF27dmzcuBEd+CbC/AZKN8DajZCSCXGJJCYm0q5dO7cjU0odpZhIBj6fj86dO7sdRtOwYw28dKmtRzjjPjj+Wu3GQqkYEBPFRKoBtewGV/4Hev4YPvgVvH6NDpqjVAzQZKAOX2IzuOR5+NFdsPRleOpMO0aCUipqaTJQR8bjgZNuhwkv2d5PZ5wMeXPdjkopdYQ0Gaij03M0XDUHklvAs+fCgsf1eQSlopAmA3X0WnaHKz+CHmfCe7+AN64Df7nbUSmlDoMmA1U/EpvBuBfh5F/B1/+Cp38MhZvcjkopVUeaDFT98Xjg5F/C+H/Bju9gxkmwfp7bUSml6kCTgap/vc6Gqz6y/Rs9Owa+eELrEZRq5DQZqMjI6mkrlrueCu/eZusS9unXSCnVeGgyUJGTmG6bng6/Ab6YAe/cqglBqUYqJrqjUI2Yx2O7rfD6YO6DYIJwzkM6gppSjYwmAxV5InDqb0C88PkDNiGMeVgTglKNiCYD1TBE4JS7bJfYn/7RJoRzp9tlpZTrNBmohiMCP/o/EA98cr9NCOf9XROCUo2AJgPV8E7+pU0IH0+zCeH8RzUhKOUyTQbKHSf9wt4pzLnPSQiPgVf/c1TKLfqvT7ln1O22Uvmje21CuGCGJgSlXKL/8pS7TrzVFhn95zcQDMCF/7TNUJVSDUqTgXLfCTfbOoMP77J3CBc9rXcISjUwbeitGocRN8KZv4eVb8K7P9e+jJRqYPrzSzUew6+Hknz7pHJ6exh1m9sRKdVkaDJQjcspv7bjIMz5HaS3gwHj3Y5IqSYhYsVEIvKUiGwXkeUH2H6yiBSKyBJn+nWkYlFRxOOxD6J1OhFmXQ9rP3E7IqWahEjWGTwDjD7EPp8bYwY6028jGIuKJnHxMO4FyOwOMyfBtm/cjkipmBexZGCM+QzYFanjqxiXlAETX4H4FHjhIh1CU6kIc7s10XAR+VpE3hORYw60k4hcLSKLRGRRfn5+Q8an3JTeDi57BSr2wIsXQ3mh2xEpFbPcTAZfAh2NMQOA6cAbB9rRGDPDGDPUGDM0KyurwQJUjUDrvjDuOdix2hYZVVW6HZFSMcm1ZGCMKTLGFDvz7wI+EWnpVjyqEet6iu3uet2n8OaN+gyCUhHgWtNSEWkNbDPGGBEZhk1MO92KRzVyAy+19QYf32eLj0692+2IlIopEUsGIpILnAy0FJGNwG8AH4Ax5jHgIuBaEakCyoDxxuhPPnUQo26Dwh/saGnp7WDoFLcjUipmRCwZGGMmHGL7I8AjkTq/ikEicPaDULQF3vk5pLWBnodqvayUqgu3WxMpdXi8cXDxM9C6H/z7csib63ZESsUETQYq+iSkwsTXoHkn+Nc42LTY7YiUinqaDFR0SsmESW9Acia8cCFsW+F2REpFNU0GKno1awM/mQVxifD8+bDze7cjUipqaTJQ0a1FZ3uHEKyC586Hwo1uR6RUVNJkoKJfq162DqG8AJ47D4q1yxKlDpcmAxUbcgbCpS/bB9OevwDKdrsdkVJRRZOBih0dh8P4F20/Ri9eDBXFbkekVNTQZKBiS7dT4aKnYNOX8NKl4C93OyKlooImAxV7eo+B8/9hO7Z7ZQoE/G5HpFSjp8lAxaYB4+GsB2D1u/D6VAhUuR2RUo2aa72WKhVxw66yA+N8dC/4S+HCJyE+2e2olGqU9M5AxbYTb3XuEN6zzU5LdSRWpWqjyUDFvmFX2c7ttnwNT50JBT+4HZFSjY4mA9U0HHM+THod9myDf54OW5e5HZFSjYomA9V0dBoJP30fxANPnwXrPnM7IqUaDU0GqmnJ7gNXzoZmOba30+WvuR2RUo1CnZKBiPxMRJqJ9aSIfCkiZ0Q6OKUiIr0dTHkP2g6BV34K/3vU7YiUcl1d7wx+aowpAs4AmgOTgD9ELCqlIi25ha1D6HU2vP9L+PBuCAbdjkop19Q1GYjzehbwvDHmm7B1SkUnXxJc8hwceyXMexjemApVlW5HpZQr6vrQ2WIR+RDoDPxKRNIA/Rmlop/Ha59DSGsNc+6D0p1wyfP6cJpqcup6Z3AF8EvgWGNMKeADpkQsKqUakgiMuh3GPAxrPoJ/XWKfXFaqCalrMhgOrDbGFIjIROAuoDByYSnlgiGXw9gnYP08HRNBNTl1TQaPAqUiMgD4OfA98FzEolLKLf0vtvUIW76GZ8dAyQ63I1KqQdQ1GVQZYwxwHvCIMebvQFrkwlLKRb3PgQm5sOM7+3Ba0Ra3I1Iq4uqaDPaIyK+wTUrfEREPtt5AqdjU7TSY+CoUbYKnR8Pu9W5HpFRE1TUZjAMqsM8bbAXaAX+OWFRKNQadToCfvGnrDp7+MexY43ZESkVMnZKBkwBeBNJF5Byg3BijdQYq9rUbApPfgaoKmxC2feN2REpFRF27o7gE+AK4GLgEWCAiF0UyMKUajdb9bPcVHi88c7YdX1mpGFPXYqI7sc8YXG6M+QkwDLg7cmEp1chk9bAJISENnj0X1s93OyKl6lVdk4HHGLM9bHnnYbxXqdjQojNMeR/Ssu1zCEv/7XZEStWbun6hvy8iH4jIZBGZDLwDvBu5sJRqpNLb2oSQMwheuxLe/YX2Z6RiQl0rkG8HZgD9nWmGMeaOSAamVKOVmgWXvwnHXw9fPA7PngNFm92OSqmjIvZZsugxdOhQs2jRIrfDUMpa/hrMusF2bHfR09D5RLcjUqpWIrLYGDP0QNsPemcgIntEpKiWaY+IFB3ivU+JyHYRWX6A7SIiD4vIGhFZKiKD63ZJSjUifcfCVXMgMQOeOw/++zBE2Q8speAQycAYk2aMaVbLlGaMaXaIYz8DjD7I9h8D3Z3pamz/R0pFn1a9bELodTbMvhte/gmUH/S3klKNTsRaBBljPgN2HWSX84DnjPU/IENE2kQqHqUiKrGZ7eDu9N/BqnfgiVNg+yq3o1KqztxsHtoW2BC2vNFZtx8RuVpEFonIovz8/AYJTqnDJgIjb7KVy+UFNiEsf9XtqJSqk6h4VsAYM8MYM9QYMzQrK8vtcJQ6uE4nwDWfQeu+8MpP4d3bwV/udlRKHZSbyWAT0D5suZ2zTqno1ywHLn8bjr8OvpgBT/wItq1wOyqlDsjNZPAm8BOnVdHxQKExRjuOV7EjLh5G3w+XvWoHyZlxMix4XFsbqUYpYslARHKB+UBPEdkoIleIyFQRmUsvnagAABgnSURBVOrs8i6wFlgDPAFcF6lYlHJV99Pg2nnQ5SR47xd2jOVirftSjYs+dKZUQzEGvngCPrzLtj46/1HofrrbUakm4qgeOlNK1SMROO5quPoTSMmCFy+C9+7QymXVKGgyUKqhZfexD6kNuwYWPGaboGrlsnKZJgOl3OBLgrP+BJf+G0q229ZGC2ZAMOh2ZKqJ0mSglJt6nGErlzudCO/dDs+dC7vWuR2VaoI0GSjlttRWcNm/YczfYPMSeHQE/O8xvUtQDUqTgVKNgQgMmQzX/w86joT374Cnfww71rgdmWoiNBko1Zikt7N3Cec/Cvkr4bGR8N+/QTDgdmQqxmkyUKqxEYGBl8L1X0DXU2H2r+HJ02H7SrcjUzFMk4FSjVVaaxj/Ilz4pK1UfnwUfPZnCPjdjkzFIE0GSjVmItDvInuX0OtsmHOfbYa6eYnbkakYo8lAqWiQmgUXPwOXPA97ttmE8O7tUFbgdmQqRmgyUCqa9DkXblgIQ6+Ahf+ER4bCklztCVUdNU0GSkWbpAw4+wG46mPI6AhvTIWnz4Jt37gdmYpimgyUilY5A+GK2TDmYchfBY+dCB/cCRV73I5MRSFNBkpFM48HhlwONy6GwZNg/t/hkWNh2StadKQOiyYDpWJBcgvbncWVH9nuLV69wvZztH2V25GpKBHndgBKqXrUboitS1j8NHz0W/jHcdCiC3QYDh2Ot6+Z3WyTVaXCaDJQKtZ4vHDsldD7PPg6FzYsgG/fhyUv2u3JmdD++L3Joc0AO16zatI0GSgVq1KzYORNdt4Y2LkGfpgPP/zPTqvfsdviEqHtUBh0GQyYoHcNTZSOgaxUU1W8fW9iWPsxbF9he0w9+6/Qqpfb0al6pmMgK6Vql9rKPsQ2+vcw9b9w7nSbEB4bCf+5BypL3Y5QNSBNBkop20R18E/ghkXQfxzMfdBWPq9+3+3IVAPRZKCU2iulJZz/D5j8LviSIXccvHQZFG50OzIVYZoMlFL76zQSrvkcTrsH1nwEjwyDedO1++wYpslAKVW7uHg44Ra4fgF0PhE+vAseP8lWOKuYo8lAKXVwzTvChJdg3ItQXghPnQnPXwB5c7XLixiiyUApdWgi0Psce5dw2j2wdTk8czY8eQasfg+CQbcjVEdJk4FSqu4SUm3R0c1L4awHoHgr5I63zVGXvgyBKrcjVEdIk4FS6vD5kmDYVXDjl3DBDFtc9NpVMH2wHXTHX+52hOowaTJQSh05rw8GjINr58H4XEjJgnd+Dg/1s88q7NnqdoSqjrQ7CqVU/TEG8j6Hz/9qu7gAyOgA7Y+DdsOg/TDI7gte7RatoR2qOwr9RJRS9UcEOo+y09blsO5T22tq3lxY9m+7jy8Z2g6xiaE6QSS3cDdupclAKRUhrfvaafj19o6hcKNNDBu+gI1fwNyHwATsvq36wJApMHACJKS5G3cTpcVESil3VJbC5q9sglj1NmxaDAnNYNBEWzndoovbEcaUQxUTaTJQSjUOGxfBgsfgm9chGIAeo+H4qdD5JB1joR642oW1iIwWkdUiskZEflnL9skiki8iS5zpykjGo5RqxNoNhQv/CTcvh1G3w8aF8Nx58I/hsOhp7VI7wiJ2ZyAiXuBb4HRgI7AQmGCMWRG2z2RgqDHmhroeV+8MlGoi/OWw/FVY8ChsXQaJGbab7b5jnRZJPrcjjCputiYaBqwxxqx1AnkJOA9YcdB3KaUUgC/RDsU58FI7XOeCx2D+IzDvYdsiKWewbYnU/jhodyykZLodcVSLZDJoC2wIW94IHFfLfheKyCjsXcQtxpgN++4gIlcDVwN06NAhAqEqpRotEeg4wk57tsL6/9oWSRsW2MQQdLrAyOxmE0N1k9WsXnbQHlUnbjctfQvINcZUiMg1wLPAKfvuZIyZAcwAW0zUsCEqpRqNtNbQ90I7Qc0WSRu+gG/fhyUv2m3xaZB9jG3emt0XWveDVr0hPsW9+BuxSCaDTUD7sOV2zroQY8zOsMV/An+KVDAl/hLe/v5tLul5CaItE5SKDfHJdiCeTiPtsjGwa61NDpsW2wffvp4Jlf903iCQ2dVJDn0hu599bda2ybdYimQyWAh0F5HO2CQwHrg0fAcRaWOM2eIsngusjFQw/1n/H+5bcB/piemM7jQ6UqdRSrlJnC/7zK62rgFs99oF62Hbctj2ja2M3rIEVryx932tjoGhU+z4z4nN3IndZRF9zkBEzgIeArzAU8aYaSLyW2CRMeZNEbkfmwSqgF3AtcaYVQc75pG2JgoEA4x7exzF/mJmnT+LBG/CYR9DKRVDyotg+wpbzLTkX7B1KcSnQr+L4dgrbLFSDNGHzsIs2LKAKz+8kpsH38wV/a6o58iUUlHLGNj0JSx60jZnrSq3LZSGXgHHXGBbNkU5Vx86a2yOa3McJ7c/mSeWPcHOsp2HfoNSqmkQgXZD4Px/wK0r4czfQ9lueGMq/LUXfHAn7Pze7SgjqkndGQCsK1zH2FljGdt9LHcPv7seI1NKxRRjYN1n9m5h1Tu2CWvbobZFU2K67UcpMd3WMdRYdqaMDuDxun0VIdqF9T46p3dmXK9x5K7KZUKvCXRr3s3tkJRSjZEIdDnJTnu2wpfPw/cf2dZK5YW2zqFyz4Hfn9oa+l1kK6Vb92v0rZWa3J0BQEF5AWe/fjb9WvbjsdMfq6fIlFJNTjAAFUV7k0N5oV0u2QHffgDffQhBP2T1tiPC9bsY0tu5EqpWIB/A8yue508L/8Sjpz3KCW1PqIfIlFJqH6W74JvXYOnL9tkHBDqdYO8W+pxri5MaiCaDA/AH/Jw/63x8Hh+vnPsKcZ4mV2KmlGpIu9bC0n/D0pmw63uIS4SeP4be50LL7raOIYLJQZPBQXz0w0fc/PHN3HXcXYzrNa5ejqmUUgdV3Yx16UxY/gqUhrVsrK54zujovO4zHUWy0GRwEMYYrvjwCtbsXsM7Y98hLV6H21NKNaCA3z4ZvXs9FPywz7Qe/PuM4TDiJjjjd0d0Km1NdBAiwm1Db2P82+N5YtkT3DrkVrdDUko1JV4f5Ayy076MsXUOBev3Joc2AyMWSpNOBgB9MvtwbtdzeWHFC1zS4xLapblT06+UUjWI2DEaUjKh7eCIn65JPYF8IDcNvok4TxwPLn7Q7VCUUsoVmgyAVsmtmNJ3Ch+u/5Cvtn/ldjhKKdXgNBk4Lu9zOa2SW/HnhX8maIJuh6OUUg1Kk4Ej2ZfMzwb/jGU7lvHuunfdDkcppRqUJoMw53Q5hz6ZfXho8UOUVZW5HY5SSjUYTQZhPOLh9qG3s610G3fNvYtvdnxDtD2HoZRSR6LJNy3d19DWQ/lp35/ywooX+HD9h3RN78qYrmM4u8vZtE5p7XZ4SikVEU36CeSDKawo5MP1H/LW92/x1favEITj2xzPmK5jOLXDqST7kiMeg1JK1RftjqIe/FD0A2+tfYu3vn+LTcWbSI5L5vSOp3Nu13MZ2nooHtHSNqVU46bJoB4FTZAvt33JW2vf4oO8Dyjxl5CdnM2odqMY2XYkx7U+jtT4VFdiU0qpg9FkECFlVWV8/MPHvJ/3Pgu2LKC0qpQ4iWNAqwGMzBnJyLYj6dWil941KKUaBU0GDcAf8LMkfwn/3fRf5m2ex8pdKwFokdiCETkjGNl2JCNyRtAisYXLkSqlmipNBi7YUbaD+ZvnM3fTXOZvns/uit0IQs8WPTm29bEcm30sg7MHk57QcKMcKaWaNk0GLguaICt3rmTuprks3LqQJflLqAhUIAi9WvRiaOuhDGs9jMHZg2kW38ztcJVSMUqTQSNTEahgWf4yFm5byKKti1iyfQmVwcpQcji29bEMyR5C14yu5KTm4PP43A5ZKRUDNBk0chWBCpbmL2XR1kUs3LaQr7d/TWWwEoA4iaNdWjs6NetEx2Yd6ZjekU7NOtGpWSdaJrVERFyOXikVLTQZRJmKQAUrd64kryiP9UXrWV+0nryiPH4o+oGKQEVovxRfCh2bdaRtaltap7SmdXJrWqe0pk1KG1qntCYzKVNbMimlQnTYyyiT4E1gYKuBDGxVc3i7oAmytWRrzSRRmMeagjXM3TR3v4714jxxZCdnk52cTeuU1mQnZ5MWn0aKLyX0mupLJSXevqb6UkmNTyXeE693HEo1QZoMooRHPOSk5pCTmsOInBE1thljKKosYmvJVraUbGFryVY7ldrXr/O/ZnvpdvxB/yHPE+eJIzMxk5zUHFqntCYnJYc2KW1ok9qGNiltyEnNIcWXEqnLVEq5RJNBDBAR0hPSSU9Ip2eLngfcrzJQSbG/mOLKYor9xZT4S0Lz1ct7Kvewo2wHW0q2sCx/GbPXz6YqWFXjOGnxaeSk5JCVnIXP4yPOE4dXvHg9Xvtay3yKL4WMhAwyEjJontCc9MR0mic0JyMhg6S4JL0bqaMNRRtYsHUBPo+PHs170CWjCwneBLfDUjFAk0ETEu+Np4W3xWE9/BYIBthZvpPNxZvZWrKVzSWb2VK8hS0lW9hRtoOqYBUBE6AqWEXQBEPzARMgEAyElsuqyjDUXj8V74knIzEjlCzSE9IPOd8soVmTqBMpqiziiy1fMG/zPOZvns/G4o01tnvFS8dmHenevDs9mvege0Z3ujfvTtvUtppg1WHRZKAOyuvx0iq5Fa2SWx3VcQLBAEWVReyu2E1hRSG7y3dTUFFgp3L7urtiNwXlBXy3+zsKKwoprCw84BCkgpDiSyE5LplkXzJJcUkk+5JrLjvz8d54AsFAjcTlD/qpClbZyVSF5uM8cSTFJR1ySvGl0CyhGenx6TRLaFZvTYCrglUs27GM+ZvnM2/zPJbtWEbQBEmOS2ZYm2FM6jOJ4TnDMRi+3f0t3+3+ju92f8fyHcv5IO+D0HFSfCl0y+hGt4xutE1tS5vUNuSk2GLGrKQsvB5vvcSrYoe2JlKNVtAE2VO5h8KKwlDiCJ8v8ZdQVlVGqb+U0qpSSv2ldtmZL60qpcxfRpWxxVxxnjhbrCVxtmjL4yXOExdajvPEhe5iqqe61LOA/fJNj08PFdelJ6SHluM8cQRMIHTnFAwGay6bIEETZGf5ThZtXUSxvxiPeOib2ZfhOcMZnjOc/ln9D5lwSvwlNjkUfMe3u77lu4LvWFuwlt0Vu2vsFydxZKdkk5Nq64PapralTUobmic2J8WXEmpckOxLJtWXSoI34ajvMowxFFQUsL10O9tKt7G9dHuNqcRfQmZSJllJWWQlZ9EquRVZSc5rchZpvjS90zlK2rRUNXmBYACPeI7oy2Tf5FA9lfhLKKooorDSJqeiiqLQ3UxhRdjk3N0Igle8eMSD12NfPeLZu05svcqQ7CGMyBnBcW2Oq7fuSkr9paEivs3FzuQU920u2Ux+af4Bi/CAUGzVU3Jccih+EXtdIoKHfdYhFFYWhr7w902sgtAisQWtkluR4kthV/ku8kvz2ePfs18Mid5EspKzyErKIj0hvUbSCo8tPIkl+5L3/gDw7E34oWWJi3iC8Qf87Cjbwfay7eSX5rOtdBv5pfnkl+2dL/GX0CKxBZlJmbRMahmaMhMza6xL9aUeVbyuJgMRGQ38DfAC/zTG/GGf7QnAc8AQYCcwzhiTd7BjajJQ0aT631dj/lXrD/jZWrKVwspC26jAX0ypvzTUqGDfqayqjKAJYowJ3dkYTK3r0uLTQsWM2cnZoV/72cnZtExuWevdTqm/1H6Blm4nvyzfvpbmh75QiyqLQrEU+4v3a+BwOKrvCsN/LIjzf/b/BRFnGduqT5DQ/h7x4CFs3tkuIhRWFLKrfNf+5/TEhe6AspOzSY5LZnfFbnaU7WBH2Q52le0K3c2Gi/fEc0W/K7hu4HVHdK2uPWcgIl7g78DpwEZgoYi8aYxZEbbbFcBuY0w3ERkP/BEYF6mYlGpojTkJVPN5fbRv1p72tHc7FACSfcl08HWgQ7MOddq/MlBZaxIrrSq19UMBf6heqMa8U2/kD/gJYuumqpO3wWCMCb3uuy48AVYnwSBh8yZIs4RmtEpqFSrqqi76ap7Y/KCNH4ImSFFFkU0O5TvYWbaTHWX2tU9mn6P86x5YJCuQhwFrjDFrAUTkJeA8IDwZnAfc48y/AjwiImKirexKKeWaeG888d54mic2dzuUeuERj21dl5hBN7o13HkjeOy2wIaw5Y3Oulr3McZUAYVA5r4HEpGrRWSRiCzKz8+PULhKKdV0RUVDbWPMDGPMUGPM0KysLLfDUUqpmBPJZLAJahRCtnPW1bqPiMQB6diKZKWUUg0okslgIdBdRDqLSDwwHnhzn33eBC535i8C5mh9gVJKNbyIVSAbY6pE5AbgA2zT0qeMMd+IyG+BRcaYN4EngedFZA2wC5swlFJKNbCIdkdhjHkXeHefdb8Omy8HLo5kDEoppQ4tKiqQlVJKRZYmA6WUUtHXN5GI5APrj/DtLYEd9RhOYxBr1xRr1wOxd02xdj0Qe9dU2/V0NMYcsG1+1CWDoyEiiw7WN0c0irVrirXrgdi7pli7Hoi9azqS69FiIqWUUpoMlFJKNb1kMMPtACIg1q4p1q4HYu+aYu16IPau6bCvp0nVGSillKpdU7szUEopVQtNBkoppZpOMhCR0SKyWkTWiMgv3Y6nPohInogsE5ElIhJ1Y4GKyFMisl1EloetayEis0XkO+c1qkYsOcA13SMim5zPaYmInOVmjIdDRNqLyMciskJEvhGRnznro/JzOsj1RPNnlCgiX4jI18413eus7ywiC5zvvJlOh6EHPk5TqDNwhuD8lrAhOIEJ+wzBGXVEJA8YaoyJyodlRGQUUAw8Z4zp66z7E7DLGPMHJ2k3N8bc4Wach+MA13QPUGyMecDN2I6EiLQB2hhjvhSRNGAxcD4wmSj8nA5yPZcQvZ+RACnGmGIR8QFzgZ8BtwKvGWNeEpHHgK+NMY8e6DhN5c4gNASnMaYSqB6CU7nIGPMZtrfacOcBzzrzz2L/oUaNA1xT1DLGbDHGfOnM7wFWYkcojMrP6SDXE7WMVews+pzJAKdghxOGOnxGTSUZ1GUIzmhkgA9FZLGIXO12MPUk2xizxZnfCmS7GUw9ukFEljrFSFFRpLIvEekEDAIWEAOf0z7XA1H8GYmIV0SWANuB2cD3QIEznDDU4TuvqSSDWHWCMWYw8GPgeqeIImY4Ax3FQjnmo0BXYCCwBfiLu+EcPhFJBV4FbjbGFIVvi8bPqZbrierPyBgTMMYMxI4oOQzodbjHaCrJoC5DcEYdY8wm53U78Dr2P4Jot80p160u393ucjxHzRizzfnHGgSeIMo+J6cc+lXgRWPMa87qqP2carueaP+MqhljCoCPgeFAhjOcMNThO6+pJIO6DMEZVUQkxakAQ0RSgDOA5Qd/V1QIHwr1cmCWi7HUi+ovTccFRNHn5FROPgmsNMb8NWxTVH5OB7qeKP+MskQkw5lPwjaUWYlNChc5ux3yM2oSrYkAnKZiD7F3CM5pLod0VESkC/ZuAOyIdf+KtmsSkVzgZGx3u9uA3wBvAC8DHbBdlV9ijImaCtkDXNPJ2OIHA+QB14SVtzdqInIC8DmwDAg6q/8PW84edZ/TQa5nAtH7GfXHVhB7sT/wXzbG/Nb5jngJaAF8BUw0xlQc8DhNJRkopZQ6sKZSTKSUUuogNBkopZTSZKCUUkqTgVJKKTQZKKWUQpOBUg1KRE4WkbfdjkOpfWkyUEoppclAqdqIyESnj/glIvK40xFYsYg86PQZ/5GIZDn7DhSR/zmdnL1e3cmZiHQTkf84/cx/KSJdncOnisgrIrJKRF50nopVylWaDJTah4j0BsYBI53OvwLAZUAKsMgYcwzwKfbpYoDngDuMMf2xT7ZWr38R+LsxZgAwAtsBGtieMm8G+gBdgJERvyilDiHu0Lso1eScCgwBFjo/2pOwHbEFgZnOPi8Ar4lIOpBhjPnUWf8s8G+n36i2xpjXAYwx5QDO8b4wxmx0lpcAnbADkijlGk0GSu1PgGeNMb+qsVLk7n32O9K+XML7hwmg/w5VI6DFRErt7yPgIhFpBaHxfjti/71U9wJ5KTDXGFMI7BaRE531k4BPnVG0NorI+c4xEkQkuUGvQqnDoL9IlNqHMWaFiNyFHUXOA/iB64ESYJizbTu2XgFs98CPOV/2a4EpzvpJwOMi8lvnGBc34GUodVi011Kl6khEio0xqW7HoVQkaDGRUkopvTNQSimldwZKKaXQZKCUUgpNBkoppdBkoJRSCk0GSimlgP8Hzmpi2Q3BYEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSZD43-hBGzD"
      },
      "source": [
        "#############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "SvrHTUdgGNW-",
        "outputId": "55f5cc40-f642-481b-e319-a66e64cb4ccf"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHgtz13dOTOh"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "num_classes = 10\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "N7x2TfzbST3k",
        "outputId": "467cc7f2-2ad1-4e22-f168-f0564b56711a"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kF5jh-x6SXF3",
        "outputId": "97e276ba-78a5-4436-b515-9f38fa255ac0"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "LSIWpY6ZGOBd",
        "outputId": "157d9350-fe76-48bc-d0da-46dd8101ce15"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "num_classes=10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "#y_train=y_train.reshape(-1,1)\n",
        "#y_test=y_test.reshape(-1,1)\n",
        "\n",
        "\n",
        "####################LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]),unit_forget_bias=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-2, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h1= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "########################RNN-TANH\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,activation='tanh',return_sequences=True, input_shape=(x_train.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,return_sequences=True,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,return_sequences=True,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=10.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h2= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "###################################rnn-relu\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,activation='relu',return_sequences=True, input_shape=(x_train.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=10.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h3= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "#####################################################irnn\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,\n",
        "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
        "                    activation='relu',return_sequences=True,\n",
        "                    input_shape=x_train.shape[1:]))\n",
        "model.add(SimpleRNN(128,\n",
        "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
        "                    activation='relu',return_sequences=True,\n",
        "                    input_shape=x_train.shape[1:]))\n",
        "model.add(SimpleRNN(128,\n",
        "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
        "                    activation='relu',return_sequences=True,\n",
        "                    input_shape=x_train.shape[1:]))\n",
        "model.add(SimpleRNN(128,\n",
        "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
        "                    activation='relu',\n",
        "                    input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h4= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "\n",
        "#######################3\n",
        "plt.plot(h1.history['accuracy'])\n",
        "plt.plot(h2.history['accuracy'])\n",
        "plt.plot(h3.history['accuracy'])\n",
        "plt.plot(h4.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['LSTM','RNN+Tanh','RNN+Relu','IRNN'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "96/96 [==============================] - 521s 5s/step - loss: 2.3116 - accuracy: 0.1110 - val_loss: 2.3063 - val_accuracy: 0.0998\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 525s 5s/step - loss: 2.3034 - accuracy: 0.1094 - val_loss: 2.3039 - val_accuracy: 0.1060\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 516s 5s/step - loss: 2.3018 - accuracy: 0.1149 - val_loss: 2.3026 - val_accuracy: 0.1111\n",
            "Epoch 1/3\n",
            "96/96 [==============================] - 1127s 12s/step - loss: 2.5484 - accuracy: 0.1110 - val_loss: 2.4651 - val_accuracy: 0.1198\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 1114s 12s/step - loss: 2.5441 - accuracy: 0.1121 - val_loss: 2.4629 - val_accuracy: 0.1204\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 1108s 12s/step - loss: 2.5454 - accuracy: 0.1101 - val_loss: 2.4608 - val_accuracy: 0.1211\n",
            "Epoch 1/3\n",
            "96/96 [==============================] - 1091s 11s/step - loss: 2.3026 - accuracy: 0.1186 - val_loss: 2.3026 - val_accuracy: 0.1304\n",
            "Epoch 2/3\n",
            "96/96 [==============================] - 1088s 11s/step - loss: 2.3025 - accuracy: 0.1212 - val_loss: 2.3026 - val_accuracy: 0.1299\n",
            "Epoch 3/3\n",
            "96/96 [==============================] - 1085s 11s/step - loss: 2.3026 - accuracy: 0.1246 - val_loss: 2.3026 - val_accuracy: 0.1297\n",
            "Epoch 1/3\n",
            "96/96 [==============================] - 872s 9s/step - loss: 2.6905 - accuracy: 0.0970 - val_loss: 2.6502 - val_accuracy: 0.0989\n",
            "Epoch 2/3\n",
            " 9/96 [=>............................] - ETA: 11:23 - loss: 2.6617 - accuracy: 0.1018"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-65f389ac3fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclipvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mh4\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m#######################3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMIJM--gOKwp"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "num_classes=10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3gTpI1xKykN"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,\n",
        "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
        "                    activation='relu',\n",
        "                    input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "SDqYMCLTOyE2",
        "outputId": "1af19998-7048-4d8c-a598-2b1722ad30cd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               16640     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 17,930\n",
            "Trainable params: 17,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "ZtozgA7MPL_-",
        "outputId": "0edcf2b1-a3f1-45cf-c9ab-1c759e241dd4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]),unit_forget_bias=True)\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-2, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h1= model.fit(x_train,y_train,validation_split = 0.2, epochs=1, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-db80c072216b>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model.add(Dense(10, activation='softmax'))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGbKoZRU6EhB"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "num_classes=10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "#x_train = x_train.astype('float32')\n",
        "#x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "wb8eJwhp6F4i",
        "outputId": "c7b834d2-a6d9-47cc-9bff-94f8b1fd2b5b"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "mvi-t9vy6SzP",
        "outputId": "76ba414b-e1fa-4ab2-ec5e-daf5eeaa618b"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "r7fxGuYKxwzE",
        "outputId": "43f49329-2a71-4363-de2f-ba1524fad9b9"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "num_classes=10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "####################LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-2, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h1= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-279a8277c85f>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    model.add(Dropout(0.2))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzyucoWcyDAf"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import keras\n",
        "from matplotlib import pyplot as pl\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import initializers\n",
        "num_classes=10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9-CL9P40zhI4",
        "outputId": "b31aaf0d-45ca-471f-cca0-2905a2fe17a5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkZJXpBLzvkG"
      },
      "source": [
        "y_train=(y_train).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0EI0AOqN7HM0",
        "outputId": "587b9b9f-87d8-4870-87dd-220e4829c52b"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_L6JJ-Mz13W"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "YGM9qRk20JL4",
        "outputId": "0fd23cac-5973-484a-e702-b98f68b8a0b5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128)               66560     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 67,850\n",
            "Trainable params: 67,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Gqv5Vc6n0QKe",
        "outputId": "e5542982-1e7a-4bcc-f512-ffce80af9d12"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iouFZG8Nz92o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOaWRct02AV-"
      },
      "source": [
        "import tensorflow as  tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Pe78SR9F4NRT",
        "outputId": "4df6c52d-6400-4829-edf1-a2a2a29ac617"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nGbdsTa-4Q4N",
        "outputId": "e860154d-425b-45ed-f03c-6f5ada5760c9"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-AONIZT4Ti2"
      },
      "source": [
        "####################LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]),unit_forget_bias=True)\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-2, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h1= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "########################RNN-TANH\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,activation='tanh',return_sequences=True, input_shape=(x_train.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,return_sequences=True,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,return_sequences=True,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=10.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h2= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "###################################rnn-relu\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,activation='relu',return_sequences=True, input_shape=(x_train.shape[1:]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu', return_sequences=True,input_shape=(x_train.shape[1:]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu', return_sequences=True,input_shape=(x_train.shape[1:]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu' input_shape=(x_train.shape[1:]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=10.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h3= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "#####################################################irnn\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128,activation='relu',return_sequences=True, input_shape=(x_train.shape[1:]),kernel_initializer=initializers.RandomNormal(stddev=0.001),recurrent_initializer=initializers.Identity(gain=1.0))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(128,activation='relu',return_sequences=True, input_shape=(x_train.shape[1:]),kernel_initializer=initializers.RandomNormal(stddev=0.001),recurrent_initializer=initializers.Identity(gain=1.0))\n",
        "model.add(Dropout(0.2)\n",
        "model.add(SimpleRNN(128,activation='relu',return_sequences=True, input_shape=(x_train.shape[1:]),kernel_initializer=initializers.RandomNormal(stddev=0.001),recurrent_initializer=initializers.Identity(gain=1.0))\n",
        "model.add(Dropout(0.2)\n",
        "model.add(SimpleRNN(128,activation='relu', input_shape=(x_train.shape[1:]),kernel_initializer=initializers.RandomNormal(stddev=0.001),recurrent_initializer=initializers.Identity(gain=1.0))\n",
        "model.add(Dropout(0.2)\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt=tf.keras.optimizers.Adam(lr=1e-8, decay=1e-5,clipvalue=1.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "h4= model.fit(x_train,y_train,validation_split = 0.2, epochs=3, batch_size=500)\n",
        "#######################3\n",
        "plt.plot(h1.history['accuracy'])\n",
        "plt.plot(h2.history['accuracy'])\n",
        "plt.plot(h3.history['accuracy'])\n",
        "plt.plot(h4.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['LSTM','RNN+Tanh','RNN+Relu','IRNN'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7YtJxdl6t39"
      },
      "source": [
        "##############################RELU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF47bSVV6tws"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E827C_m3AwaC",
        "outputId": "c29ff0d1-a14c-4719-f882-850f3daedb93"
      },
      "source": [
        "##33333333333##################################multilayer##tanh#############\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.utils import compute_class_weight\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "units=[5]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[100,300,500,800,1000]\n",
        " \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(LSTM(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    \n",
        "    \n",
        "    #n_samples_l.append(i)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp1=bits_per_parameter_f\n",
        "b1=bits_f\n",
        "np1=n_parameters_f\n",
        "ns1=n_samples_f\n",
        "\n",
        "\n",
        "####################################\n",
        "\n",
        "\n",
        "\n",
        "units=[30]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "  l=[1000,5000,10000,15000,25000]\n",
        " \n",
        "  \n",
        "  \n",
        "  \n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(LSTM(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    #n_samples=i\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp2=bits_per_parameter_f\n",
        "b2=bits_f\n",
        "np2=n_parameters_f\n",
        "ns2=n_samples_f\n",
        "\n",
        "\n",
        "################\n",
        "\n",
        "\n",
        "\n",
        "units=[50]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[2500,10000,25000,50000,75000,100000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(LSTM(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp3=bits_per_parameter_f\n",
        "b3=bits_f\n",
        "np3=n_parameters_f\n",
        "ns3=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "units=[75]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[5000,25000,75000,100000,200000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(LSTM(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp4=bits_per_parameter_f\n",
        "b4=bits_f\n",
        "np4=n_parameters_f\n",
        "ns4=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b=b1+b2+b3+b4\n",
        "bp=bp1+bp2+bp3+bp4\n",
        "np=np1+np2+np3+np4\n",
        "ns=ns1+ns2+ns3+ns4\n",
        "a_bp=(bp[0]+bp[1]+bp[2]+bp[3])/4\n",
        "\n",
        "\n",
        "####final\n",
        "print('bits_per_parameter',bp)\n",
        "print('bits',b)\n",
        "print('parameters',np)\n",
        "print('avg_bits_per_parameter',a_bp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80dbc3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80dcf7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5400000214576721]\n",
            "0.8800000214576721\n",
            "100\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80a108620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80fc3f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.4399999976158142]\n",
            "0.9000000023841858\n",
            "300\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80e050400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80f670d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[4.7683716530855236e-08, 0.5799999833106995]\n",
            "0.9199999833106994\n",
            "500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80cf522f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80dcbd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7.390976008991856e-08, 0.4000000059604645]\n",
            "0.9399999940395355\n",
            "800\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe808fe00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8083de1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.46000000834465027]\n",
            "0.8799999916553497\n",
            "1000\n",
            "n_units 5\n",
            "p_l [0.8800000214576721, 0.9000000023841858, 0.9199999833106994, 0.9399999940395355, 0.8799999916553497]\n",
            "mi_score [0.028284234321002605, 0.001771493290679993, 0.028863864884317567, 0.007220626976132419, 0.0]\n",
            "n_samples []\n",
            "bits [47.06391963920545, 159.30132419052265, 298.91037549597263, 538.0440457477658, 470.6391107261966]\n",
            "bits_per_parameter [0.3223556139671606, 1.0911049602090592, 2.0473313390135113, 3.6852331900531907, 3.2235555529191546]\n",
            "bits 538.0440457477658\n",
            "bits_per_parameter 3.6852331900531907\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe810915510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80d153598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.0067900048134106e-08, 0.6000000238418579]\n",
            "0.9500000238418579\n",
            "1000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80ad8b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe809ee36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.5400000214576721]\n",
            "0.8900000214576721\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80e6572f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80d645598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.46000000834465027]\n",
            "0.8899999916553497\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80c2522f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80e300158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.5199999809265137]\n",
            "0.8699999809265136\n",
            "15000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80cf52378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80e074bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.5400000214576721]\n",
            "0.8900000214576721\n",
            "25000\n",
            "n_units 30\n",
            "p_l [0.9500000238418579, 0.8900000214576721, 0.8899999916553497, 0.8699999809265136, 0.8900000214576721]\n",
            "mi_score [0.002586385720613371, 0.030262875867215572, 0.03204211947299973, 0.0, 0.0]\n",
            "n_samples []\n",
            "bits [713.6031441625366, 2500.420532791453, 5000.840166654887, 6638.426439943572, 12502.102663957265]\n",
            "bits_per_parameter [0.18434594269246618, 0.6459365881662239, 1.2918729441113115, 1.7149125393809281, 3.2296829408311196]\n",
            "bits 12502.102663957265\n",
            "bits_per_parameter 3.2296829408311196\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8093988c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe808f2db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5]\n",
            "0.85\n",
            "2500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe81096fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80d292400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80ada9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80b624f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.5400000214576721]\n",
            "0.8900000214576721\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe807b5f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe810f4d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7.629394360719743e-08, 0.36000001430511475]\n",
            "0.9899999856948852\n",
            "50000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8090e8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80f9e8b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.0067900048134106e-08, 0.41999998688697815]\n",
            "0.9300000131130218\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80fc3fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80dc3b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[3.814697180359872e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "100000\n",
            "n_units 50\n",
            "p_l [0.85, 0.870000010728836, 0.8900000214576721, 0.9899999856948852, 0.9300000131130218, 0.9299999833106994]\n",
            "mi_score [3.336115749709434e-05, 0.0, 0.0, -1.6653345369377348e-16, 0.0, 0.003610762749224075]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000]\n",
            "bits [975.3992382089987, 4425.61844395885, 12502.102663957265, 45960.33846351982, 47555.72985262534, 63407.62868185831]\n",
            "bits_per_parameter [0.0933307088516887, 0.4234636344808008, 1.1962589861216404, 4.39769768094152, 4.550352105312921, 6.067135076247087]\n",
            "bits 63407.62868185831\n",
            "bits_per_parameter 6.067135076247087\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80e669400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80cc4c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.46000000834465027]\n",
            "0.8799999916553497\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8091e7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80c1d6bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80d4fd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80e050598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8090e8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe81117db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7.629394360719743e-08, 0.6399999856948853]\n",
            "0.9799999856948852\n",
            "100000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8075e5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80698f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "200000\n",
            "n_units 75\n",
            "p_l [0.8799999916553497, 0.8599999809265136, 0.8599999809265136, 0.9799999856948852, 0.8599999809265136]\n",
            "mi_score [-4.440892098500626e-16, 0.0015098281622372284, 0.004990165876221864, 0.0, 0.0]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000, 5000, 25000, 75000, 100000, 200000]\n",
            "bits [2353.195553630983, 10394.028460135132, 31182.0853804054, 85855.93771391182, 83152.22768108106]\n",
            "bits_per_parameter [0.1015358799461073, 0.4484824154355856, 1.3454472463067568, 3.7045192317014073, 3.5878593234846847]\n",
            "bits 85855.93771391182\n",
            "bits_per_parameter 3.7045192317014073\n",
            "bits_per_parameter [3.6852331900531907, 3.2296829408311196, 6.067135076247087, 3.7045192317014073]\n",
            "bits [538.0440457477658, 12502.102663957265, 63407.62868185831, 85855.93771391182]\n",
            "parameters [146, 3871, 10451, 23176]\n",
            "avg_bits_per_parameter 4.1716426097082016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "UQxPlKkHrNgt",
        "outputId": "2985eda7-356c-4788-c05b-0a815b1101fc"
      },
      "source": [
        "plt.plot(np,b)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multilayer layer LSTM')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multilayer layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "na38xHUtBWoW",
        "outputId": "084b689b-5755-46ef-caec-e13fb88c33ab"
      },
      "source": [
        "ns3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYHPvmtOBZpL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "I3XcBNWx4N5L",
        "outputId": "c02ea4e8-83f7-4ad4-cde2-345c3971bd6b"
      },
      "source": [
        "\n",
        "plt.plot(ns,b)\n",
        "plt.xlabel('Dataset Size')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multi layer LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JCalcqWr96Ln",
        "outputId": "ef68f69b-a4b5-49d8-de50-29f926777188"
      },
      "source": [
        "ns2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cuzpJofM99Sp",
        "outputId": "5db30216-fe13-4c50-f4bc-b43531b7fa77"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[538.0440457477658, 12502.102663957265, 63407.62868185831, 85855.93771391182]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "0tbT7Dm17Pap",
        "outputId": "598b061e-607e-4e86-d389-536c7d98d2f3"
      },
      "source": [
        "\n",
        "plt.plot(np,bp)\n",
        "#plt.plot(np,a_bp)\n",
        "\n",
        "plt.ylim(0,7)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "plt.title(\"Multi layer LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GwfYIJh3-tX"
      },
      "source": [
        "a_bp=[4.07,4.07,4.07,4.07]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0zTgEPvawFWi",
        "outputId": "88843e38-0ed7-4179-94c1-084f972d34b2"
      },
      "source": [
        "np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[146, 3871, 10451, 23176]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znBaRrH0M83w"
      },
      "source": [
        "#######################33multilayer#######relu\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z4T_3U5XaO9g",
        "outputId": "8e70b569-6768-4e53-ff52-3a4f4159a9c1"
      },
      "source": [
        "##33333333333##################################multilayer##tanh#############\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SimpleRNN\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.utils import compute_class_weight\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "units=[5]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[100,300,500,800,1000]\n",
        " \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    \n",
        "    \n",
        "    #n_samples_l.append(i)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp1=bits_per_parameter_f\n",
        "b1=bits_f\n",
        "np1=n_parameters_f\n",
        "ns1=n_samples_f\n",
        "\n",
        "\n",
        "####################################\n",
        "\n",
        "\n",
        "\n",
        "units=[30]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "  l=[1000,5000,10000,15000,25000]\n",
        " \n",
        "  \n",
        "  \n",
        "  \n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    #n_samples=i\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp2=bits_per_parameter_f\n",
        "b2=bits_f\n",
        "np2=n_parameters_f\n",
        "ns2=n_samples_f\n",
        "\n",
        "\n",
        "################\n",
        "\n",
        "\n",
        "\n",
        "units=[50]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[2500,10000,25000,50000,75000,100000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp3=bits_per_parameter_f\n",
        "b3=bits_f\n",
        "np3=n_parameters_f\n",
        "ns3=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "units=[75]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[5000,25000,75000,100000,200000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='tanh',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp4=bits_per_parameter_f\n",
        "b4=bits_f\n",
        "np4=n_parameters_f\n",
        "ns4=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b=b1+b2+b3+b4\n",
        "bp=bp1+bp2+bp3+bp4\n",
        "np=np1+np2+np3+np4\n",
        "ns=ns1+ns2+ns3+ns4\n",
        "a_bp=(bp[0]+bp[1]+bp[2]+bp[3])/4\n",
        "\n",
        "\n",
        "####final\n",
        "print('bits_per_parameter',bp)\n",
        "print('bits',b)\n",
        "print('parameters',np)\n",
        "print('avg_bits_per_parameter',a_bp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe807b83620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80c371ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.914138594993346e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "100\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8073bab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805bfabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.4836274188119205e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "300\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe809352ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80603f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.4836274188119205e-08, 0.5]\n",
            "0.84\n",
            "500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8091ddb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805ba98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.4000000059604645]\n",
            "0.9399999940395355\n",
            "800\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe805955bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe801960950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "1000\n",
            "n_units 5\n",
            "p_l [0.860000010728836, 0.8599999809265136, 0.84, 0.9399999940395355, 0.860000010728836]\n",
            "mi_score [0.04035537625281935, 0.00027923552157421705, 0.0169133807993318, 0.003274698923430519, 0.015223160256227886]\n",
            "n_samples []\n",
            "bits [41.57612164549989, 124.72834152162159, 182.84522267971693, 538.0440457477658, 415.7612164549988]\n",
            "bits_per_parameter [0.28476795647602665, 0.8543037090522027, 1.2523645389021707, 3.6852331900531907, 2.847679564760266]\n",
            "bits 538.0440457477658\n",
            "bits_per_parameter 3.6852331900531907\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8018fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8023bf598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[7.152557657263969e-08, 0.41999998688697815]\n",
            "0.9300000131130218\n",
            "1000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe810f170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805718378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.5]\n",
            "0.85\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8091dd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8091a61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.0067900048134106e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80a808048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80d1531e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "15000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80850bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805c5f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "25000\n",
            "n_units 30\n",
            "p_l [0.9300000131130218, 0.85, 0.9299999833106994, 0.9299999833106994, 0.9299999833106994]\n",
            "mi_score [0.0008116133750376564, 0.0008916516980914668, 0.0, 0.029244584622047987, 4.898219264504178e-05]\n",
            "n_samples []\n",
            "bits [634.0763980350046, 1950.7984764179973, 6340.762868185831, 9511.144302278746, 15851.907170464578]\n",
            "bits_per_parameter [0.1638017044781722, 0.503952073474037, 1.6380167574750275, 2.457025136212541, 4.0950418936875685]\n",
            "bits 15851.907170464578\n",
            "bits_per_parameter 4.0950418936875685\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8091b7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80a3d9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.0067900048134106e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "2500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe806087950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805c09598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.4399999976158142]\n",
            "0.9100000023841858\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe805a8a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe810b3bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.5400000214576721]\n",
            "0.8900000214576721\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80595cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80756a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.41999998688697815]\n",
            "0.9300000131130218\n",
            "50000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7fe16d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7fd7db268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.6200000047683716]\n",
            "0.9700000047683716\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7fc31a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7fc6d37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.914138594993346e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "100000\n",
            "n_units 50\n",
            "p_l [0.870000010728836, 0.9100000023841858, 0.8900000214576721, 0.9300000131130218, 0.9700000047683716, 0.870000010728836]\n",
            "mi_score [-3.3306690738754696e-16, 0.0006118816214351064, 0.0028027498943484497, 0.04574244967269907, 0.0012294745011640629, 0.00048027935029193447]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000]\n",
            "bits [1106.4046109897124, 5635.301908939984, 12502.102663957265, 31703.81990175023, 60420.61245611782, 44256.1844395885]\n",
            "bits_per_parameter [0.1058659086202002, 0.5392117413587201, 1.1962589861216404, 3.0335680702086143, 5.781323553355452, 4.234636344808009]\n",
            "bits 60420.61245611782\n",
            "bits_per_parameter 5.781323553355452\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7fe1b5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805ea7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe80742f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe805c5f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.4399999976158142]\n",
            "0.9000000023841858\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe807b83268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe81117d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[4.7683716530855236e-08, 0.4000000059604645]\n",
            "0.9399999940395355\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8110337b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe80a4971e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.0067900048134106e-08, 0.5]\n",
            "0.84\n",
            "100000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7fba86a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe8084926a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "200000\n",
            "n_units 75\n",
            "p_l [0.860000010728836, 0.9000000023841858, 0.9399999940395355, 0.84, 0.8599999809265136]\n",
            "mi_score [0.0028294381816895142, 0.01106283630255267, 0.02242013133074798, 0.005905997313449679, 0.0007397688914091982]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000, 5000, 25000, 75000, 100000, 200000]\n",
            "bits [2078.8060822749944, 13275.110349210221, 50441.629288853044, 36569.04453594339, 83152.22768108106]\n",
            "bits_per_parameter [0.08969649992556931, 0.5727955794446937, 2.176459669004705, 1.5778842136668703, 3.5878593234846847]\n",
            "bits 83152.22768108106\n",
            "bits_per_parameter 3.5878593234846847\n",
            "bits_per_parameter [3.6852331900531907, 4.0950418936875685, 5.781323553355452, 3.5878593234846847]\n",
            "bits [538.0440457477658, 15851.907170464578, 60420.61245611782, 83152.22768108106]\n",
            "parameters [146, 3871, 10451, 23176]\n",
            "avg_bits_per_parameter 4.287364490145224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv1BXLGtajlF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "tw2uLYJzfO3u",
        "outputId": "f582cae7-bf26-4fa6-b2b0-a1aaa3b7d1f2"
      },
      "source": [
        "plt.plot(np,b)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multilayer layer RNN')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multilayer layer RNN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Xx-IN3fPoE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "dsoIcSfVfXDp",
        "outputId": "99481df2-94cd-4cc6-8eeb-71ac6b452b5c"
      },
      "source": [
        "\n",
        "plt.plot(ns,b)\n",
        "plt.xlabel('Dataset Size')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multi layer RNN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer RNN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1wjpu9fXzK"
      },
      "source": [
        "a_bp=[4.3,4.3,4.3,4.3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "88yxleuvfte9",
        "outputId": "eab90961-e864-415f-e81a-35f3cc31719a"
      },
      "source": [
        "np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[146, 3871, 10451, 23176]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3hZk0Nm-fhKq",
        "outputId": "98202b3a-5da1-42cf-e937-4e607488e79d"
      },
      "source": [
        "\n",
        "plt.plot(np,bp)\n",
        "plt.plot(np,a_bp,label='4.3')\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "\n",
        "plt.ylim(0,7)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "plt.title(\"Multi layer RNN\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer RNN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZjS3rgfqGi"
      },
      "source": [
        "##################3MULTILAYERRNN############33RELU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNrA5XDBk1hs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dKIKnFLzk2PS",
        "outputId": "8be5998a-9529-412b-da5e-1089132679ee"
      },
      "source": [
        "##33333333333##################################multilayer##tanh#############\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SimpleRNN\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.utils import compute_class_weight\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "units=[5]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[100,300,500,800,1000]\n",
        " \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    \n",
        "    \n",
        "    #n_samples_l.append(i)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp1=bits_per_parameter_f\n",
        "b1=bits_f\n",
        "np1=n_parameters_f\n",
        "ns1=n_samples_f\n",
        "\n",
        "\n",
        "####################################\n",
        "\n",
        "\n",
        "\n",
        "units=[30]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "  l=[1000,5000,10000,15000,25000]\n",
        " \n",
        "  \n",
        "  \n",
        "  \n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    #n_samples=i\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp2=bits_per_parameter_f\n",
        "b2=bits_f\n",
        "np2=n_parameters_f\n",
        "ns2=n_samples_f\n",
        "\n",
        "\n",
        "################\n",
        "\n",
        "\n",
        "\n",
        "units=[50]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[2500,10000,25000,50000,75000,100000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp3=bits_per_parameter_f\n",
        "b3=bits_f\n",
        "np3=n_parameters_f\n",
        "ns3=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "units=[75]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[5000,25000,75000,100000,200000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(4*((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp4=bits_per_parameter_f\n",
        "b4=bits_f\n",
        "np4=n_parameters_f\n",
        "ns4=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b=b1+b2+b3+b4\n",
        "bp=bp1+bp2+bp3+bp4\n",
        "np=np1+np2+np3+np4\n",
        "ns=ns1+ns2+ns3+ns4\n",
        "a_bp=(bp[0]+bp[1]+bp[2]+bp[3])/4\n",
        "\n",
        "\n",
        "####final\n",
        "print('bits_per_parameter',bp)\n",
        "print('bits',b)\n",
        "print('parameters',np)\n",
        "print('avg_bits_per_parameter',a_bp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f9151730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f7c407b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "100\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f4af9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f51d41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5600000023841858]\n",
            "0.9000000023841858\n",
            "300\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f4d0fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f978cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.46000000834465027]\n",
            "0.8799999916553497\n",
            "500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f1f09840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f54028c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.5400000214576721]\n",
            "0.8800000214576721\n",
            "800\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f78c1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f7681ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "1000\n",
            "n_units 5\n",
            "p_l [0.860000010728836, 0.9000000023841858, 0.8799999916553497, 0.8800000214576721, 0.8599999809265136]\n",
            "mi_score [0.0006295752161339374, 0.006759358990009318, 9.160455235765474e-05, 0.006254808944014895, 0.001816677155757035]\n",
            "n_samples []\n",
            "bits [41.57612164549989, 159.30132419052265, 235.3195553630983, 376.5113571136436, 415.7611384054053]\n",
            "bits_per_parameter [0.28476795647602665, 1.0911049602090592, 1.6117777764595773, 2.578844911737285, 2.847679030174009]\n",
            "bits 415.7611384054053\n",
            "bits_per_parameter 2.847679030174009\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f71c3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f5492ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.3799999952316284]\n",
            "0.9700000047683716\n",
            "1000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f7523d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7fe16d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f5ffa9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f52cd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.4836274188119205e-08, 0.4399999976158142]\n",
            "0.9100000023841858\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f53c4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe810818ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "15000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7fc687400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7fd44da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "25000\n",
            "n_units 30\n",
            "p_l [0.9700000047683716, 0.870000010728836, 0.9100000023841858, 0.9299999833106994, 0.870000010728836]\n",
            "mi_score [0.006520362623756687, 0.007705365687744645, 0.0025304603797590697, 0.013496852612790156, 0.0025487260264365763]\n",
            "n_samples []\n",
            "bits [805.608166081571, 2212.809221979425, 5635.301908939984, 9511.144302278746, 11064.046109897125]\n",
            "bits_per_parameter [0.20811370862350065, 0.5716376186978622, 1.4557741950245373, 2.457025136212541, 2.8581880934893116]\n",
            "bits 11064.046109897125\n",
            "bits_per_parameter 2.8581880934893116\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7faac6bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f7eab950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.5]\n",
            "0.85\n",
            "2500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f967f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f9601b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f56e5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f56aa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f940b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f8ea92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.4399999976158142]\n",
            "0.9100000023841858\n",
            "50000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f91e1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f571dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.5799999833106995]\n",
            "0.9299999833106994\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f1eda950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f768e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.5199999809265137]\n",
            "0.8699999809265136\n",
            "100000\n",
            "n_units 50\n",
            "p_l [0.85, 0.9299999833106994, 0.9299999833106994, 0.9100000023841858, 0.9299999833106994, 0.8699999809265136]\n",
            "mi_score [0.04000319616755771, 0.015421694314173118, 0.007664497651708069, 0.0008512027906854153, 0.002235791870799489, 0.018309775841822917]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000]\n",
            "bits [975.3992382089987, 6340.762868185831, 15851.907170464578, 28176.50954469992, 47555.721511393735, 44256.17626629048]\n",
            "bits_per_parameter [0.0933307088516887, 0.6067135076247088, 1.5167837690617718, 2.6960587067936004, 4.550351307185315, 4.234635562749065]\n",
            "bits 47555.721511393735\n",
            "bits_per_parameter 4.550351307185315\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f7748488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f7826510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.41999998688697815]\n",
            "0.9200000131130218\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f78f0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f35aaea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.4399999976158142]\n",
            "0.9000000023841858\n",
            "25000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f30f0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f3086ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.5600000023841858]\n",
            "0.9000000023841858\n",
            "75000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f1708598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7edc6e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.6399999856948853]\n",
            "0.9799999856948852\n",
            "100000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f3009488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe7f513d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.46000000834465027]\n",
            "0.8799999916553497\n",
            "200000\n",
            "n_units 75\n",
            "p_l [0.9200000131130218, 0.9000000023841858, 0.9000000023841858, 0.9799999856948852, 0.8799999916553497]\n",
            "mi_score [0.006754363527967544, 0.013147407028427496, 0.014653936265871123, 0.020683787860959535, 2.2540020403027938e-05]\n",
            "n_samples [2500, 10000, 25000, 50000, 75000, 100000, 5000, 25000, 75000, 100000, 200000]\n",
            "bits [2989.1042800113682, 13275.110349210221, 39825.331047630665, 85855.93771391182, 94127.82214523932]\n",
            "bits_per_parameter [0.12897412323141907, 0.5727955794446937, 1.7183867383340812, 3.7045192317014073, 4.061435197844292]\n",
            "bits 94127.82214523932\n",
            "bits_per_parameter 4.061435197844292\n",
            "bits_per_parameter [2.847679030174009, 2.8581880934893116, 4.550351307185315, 4.061435197844292]\n",
            "bits [415.7611384054053, 11064.046109897125, 47555.721511393735, 94127.82214523932]\n",
            "parameters [146, 3871, 10451, 23176]\n",
            "avg_bits_per_parameter 3.5794134071732326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qggpluppk1XM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Hydsln13tZIU",
        "outputId": "203d22f7-eb50-4262-a796-39a51980ba15"
      },
      "source": [
        "plt.plot(np,b)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multilayer layer RNN - relu')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multilayer layer RNN - relu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrsHXB6Gk1N3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "56POX6Bgtz8n",
        "outputId": "00b3b086-4429-4b8a-ec5a-14bd0240908c"
      },
      "source": [
        "\n",
        "plt.plot(ns,b)\n",
        "plt.xlabel('Dataset Size')\n",
        "plt.ylabel(\"bits\")\n",
        "plt.title('Multi layer RNN-relu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer RNN-relu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5-p8F0ik1D5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDtHPqMKuEUK"
      },
      "source": [
        "a_bp=[3.6,3.6,3.6,3.6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "jhM5QFJGuE52",
        "outputId": "7e154781-e022-4b4b-b877-1311c4888160"
      },
      "source": [
        "\n",
        "plt.plot(np,bp)\n",
        "plt.plot(np,a_bp,label='3.6')\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "\n",
        "plt.ylim(0,15)\n",
        "\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"bits_per_parameter\")\n",
        "plt.title(\"Multi layer RNN-relu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Multi layer RNN-relu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mQmBHivuNMU"
      },
      "source": [
        "###########################################################################33"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn6Nc96g8HVk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCwZx7mZ8IJM",
        "outputId": "179f2c5d-ae93-472c-a2da-a76c4dcedb51"
      },
      "source": [
        "##33333333333##################################multilayer##tanh#############\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SimpleRNN\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.utils import compute_class_weight\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "units=[50]\n",
        "bits_f=[]\n",
        "\n",
        "\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  l=[100,300,500,800,1000]\n",
        " \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "sddsdsdsd\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    \n",
        "    \n",
        "    #n_samples_l.append(i)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp1=bits_per_parameter_f\n",
        "b1=bits_f\n",
        "np1=n_parameters_f\n",
        "ns1=n_samples_f\n",
        "\n",
        "\n",
        "####################################\n",
        "\n",
        "\n",
        "\n",
        "units=[1300]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "  l=[1000,5000,10000,15000,25000]\n",
        " \n",
        "  \n",
        "  \n",
        "  \n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    #n_samples=i\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp2=bits_per_parameter_f\n",
        "b2=bits_f\n",
        "np2=n_parameters_f\n",
        "ns2=n_samples_f\n",
        "\n",
        "\n",
        "################\n",
        "\n",
        "\n",
        "\n",
        "units=[3500]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[2500,10000,25000,50000,75000,100000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.85\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp3=bits_per_parameter_f\n",
        "b3=bits_f\n",
        "np3=n_parameters_f\n",
        "ns3=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "units=[7000]\n",
        "bits_f=[]\n",
        "bits_per_parameter_f=[]\n",
        "n_parameters_f=[]\n",
        "n_samples_f=[]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "for j in units:\n",
        "  n_parameters_l=[]\n",
        "  mi_score=[]\n",
        "  #n_samples_l=[]\n",
        "  bits_l=[]\n",
        "  bits_per_parameter_l=[]\n",
        "  p_l=[]\n",
        "  \n",
        "\n",
        "  l=[5000,25000,75000,100000,200000]\n",
        "  \n",
        "  \n",
        "  \n",
        "  print()\n",
        "  for i in l:\n",
        "    \n",
        "   \n",
        "   \n",
        "    import numpy as np\n",
        "    X =np.random.randint(2, size=i)\n",
        "    y=np.random.randint(2, size=100)\n",
        "    X=np.array(X).reshape(-1,1)\n",
        "    #scaler = Normalizer().fit(X)\n",
        "    #X= scaler.transform(X)\n",
        "    X=np.array(X).reshape(100,int(i/100),1)\n",
        "    y=np.array(y).reshape(100,1)\n",
        "\n",
        "    \n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
        "    #classWeight = dict(enumerate(classWeight))\n",
        "    #model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(j, activation='relu',return_sequences=True,input_shape=(X_train.shape[1:])))\n",
        "    model.add(SimpleRNN(j, activation='relu',input_shape=(X_train.shape[1:])))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt=tf.keras.optimizers.Adam(lr=1e-1,clipvalue=30.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X_train,y_train, epochs=50, batch_size=100,verbose=0)\n",
        "    \n",
        "    \n",
        "    #new_model.summary()\n",
        "    n_parameters=(((X_test.shape[2]*j)+(j*j)+(j))+((j*1)+1))\n",
        "    \n",
        "    n_parameters_l.append(n_parameters)\n",
        "   \n",
        "    \n",
        "    #yhat =new_model.predict(X_test)\n",
        "    yhat=model.predict_classes(X_test)\n",
        "    yhat=yhat.reshape(yhat.shape[0]*yhat.shape[1])\n",
        "    y_test=y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "    \n",
        "  \n",
        "    mi_score.append(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print(sklearn.metrics.mutual_info_score(y_test,yhat))\n",
        "\n",
        "    #print('n_parameters',n_parameters)\n",
        "    #z=accuracy_score(y_test, yhat.round(), normalize=False)\n",
        "    scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print(scores)\n",
        "    p=scores[1]\n",
        "    if p>0.5:\n",
        "      p=p-0.5\n",
        "    else:\n",
        "      p=0.5-p\n",
        "    p=p+0.84\n",
        "    #p=accuracy_score(y_test,yhat)\n",
        "    #p=(z/y_test.shape[0])\n",
        "    p_l.append(p)\n",
        "\n",
        "    print(p)\n",
        "\n",
        "    \n",
        "\n",
        "    b=X.shape[0]*X.shape[1]\n",
        "    print(b)\n",
        "\n",
        "    #no of samples\n",
        "    n_samples=X.shape[0]*X.shape[1]\n",
        "    \n",
        "    n_samples_l.append(n_samples)\n",
        "    #n_samples=X_test.shape[0]*X_test.shape[1]\n",
        "    \n",
        "    #n_samples_l.append(n_samples)\n",
        "\n",
        "    import math\n",
        "    bits=b+b*((p*math.log2(p))+((1-p)*math.log2(1-p)))\n",
        "    bits_per_parameter=(bits/n_parameters)\n",
        "    bits_l.append(bits)\n",
        "    bits_per_parameter_l.append(bits_per_parameter)\n",
        "    #print('bits : ',bits)\n",
        "    #print('bits_per_parameter : ',bits_per_parameter)\n",
        "  print('n_units',j)\n",
        "  print('p_l',p_l)\n",
        "  print('mi_score',mi_score)\n",
        "  #k=mi_score.index(max(mi_score)) \n",
        "  #k=p_l.index(max(p_l))\n",
        "  k=bits_l.index(max(bits_l))\n",
        "  #print('n_parameters',n_parameters_l)\n",
        "  print('n_samples',n_samples_l)\n",
        "  print('bits',bits_l)\n",
        "\n",
        "  print('bits_per_parameter',bits_per_parameter_l)\n",
        "\n",
        "  print('bits',bits_l[k])\n",
        "  bits_f.append(bits_l[k])\n",
        "  print('bits_per_parameter',bits_per_parameter_l[k])\n",
        "  bits_per_parameter_f.append(bits_per_parameter_l[k])\n",
        "  n_parameters_f.append(n_parameters)\n",
        "  n_samples_f.append(l[k])\n",
        "#print(bits_per_parameter_f)\n",
        "#print(bits_f)\n",
        "#print(n_parameters_f)\n",
        "bp4=bits_per_parameter_f\n",
        "b4=bits_f\n",
        "np4=n_parameters_f\n",
        "ns4=n_samples_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b=b1+b2+b3+b4\n",
        "bp=bp1+bp2+bp3+bp4\n",
        "np=np1+np2+np3+np4\n",
        "ns=ns1+ns2+ns3+ns4\n",
        "a_bp=(bp[0]+bp[1]+bp[2]+bp[3])/4\n",
        "\n",
        "\n",
        "####final\n",
        "print('bits_per_parameter',bp)\n",
        "print('bits',b)\n",
        "print('parameters',np)\n",
        "print('avg_bits_per_parameter',a_bp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc801806e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc803266d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.67572024326546e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "100\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80159b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc80159bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.960464477539063e-08, 0.5199999809265137]\n",
            "0.8599999809265136\n",
            "300\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc800e50d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc8011939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.914138594993346e-08, 0.41999998688697815]\n",
            "0.9200000131130218\n",
            "500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc802dc1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc802f99158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[4.5299529460862686e-08, 0.36000001430511475]\n",
            "0.9799999856948852\n",
            "800\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc802fc31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc80149dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.4836274188119205e-08, 0.47999998927116394]\n",
            "0.860000010728836\n",
            "1000\n",
            "n_units 50\n",
            "p_l [0.860000010728836, 0.8599999809265136, 0.9200000131130218, 0.9799999856948852, 0.860000010728836]\n",
            "mi_score [2.1053091354750197e-05, 0.004066631262178044, 0.0029969678110904896, 0.005355119613650927, 0.007046742053722299]\n",
            "n_samples []\n",
            "bits [41.57612164549989, 124.72834152162159, 298.9104280011368, 686.8475017112945, 415.7612164549988]\n",
            "bits_per_parameter [0.015683184324971667, 0.04704954414244496, 0.1127538393063511, 0.25908996669607487, 0.15683184324971663]\n",
            "bits 686.8475017112945\n",
            "bits_per_parameter 0.25908996669607487\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8017a59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc8011b6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.914138594993346e-08, 0.6000000238418579]\n",
            "0.9500000238418579\n",
            "1000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8033470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc8012c1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.2452087118126656e-08, 0.46000000834465027]\n",
            "0.8899999916553497\n",
            "5000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc801a29b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc803347d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[4.7683716530855236e-08, 0.46000000834465027]\n",
            "0.8899999916553497\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc806a3ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc8018b92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.41999998688697815]\n",
            "0.9300000131130218\n",
            "15000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc802c0dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc802c71950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[4.7683716530855236e-08, 0.41999998688697815]\n",
            "0.9300000131130218\n",
            "25000\n",
            "n_units 1300\n",
            "p_l [0.9500000238418579, 0.8899999916553497, 0.8899999916553497, 0.9300000131130218, 0.9300000131130218]\n",
            "mi_score [0.00637736648320919, 0.012391027130252558, 0.0061460024578183226, 0.015223160256227886, 0.0027851645251488755]\n",
            "n_samples []\n",
            "bits [713.6031441625366, 2500.4200833274435, 5000.840166654887, 9511.145970525069, 15851.909950875115]\n",
            "bits_per_parameter [0.00042127795199515004, 0.001476131180823108, 0.002952262361646216, 0.005614936156555235, 0.009358226927592058]\n",
            "bits 15851.909950875115\n",
            "bits_per_parameter 0.009358226927592058\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc802f848c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc8034629d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.437301891537572e-08, 0.5199999809265137]\n",
            "0.8699999809265136\n",
            "2500\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80346a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc801357400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[6.19888282926695e-08, 0.5]\n",
            "0.85\n",
            "10000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc800f9c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc802afbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[5.7220457705398076e-08, 0.47999998927116394]\n",
            "0.870000010728836\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9n66lIy8HJ9"
      },
      "source": [
        "#####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HffgbuiSrBiW"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "u1-zNPlCheHW",
        "outputId": "f9ad039d-1e8b-4d71-fc4f-2be281d4f7df"
      },
      "source": [
        "#filename = \"wonderland.txt\"\n",
        "raw_text = open(r\"C:\\Users\\lenovo\\Desktop\\rnn\\wonderland.txt\", 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-34302388abb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#filename = \"wonderland.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\lenovo\\Desktop\\rnn\\wonderland.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\rnn\\\\wonderland.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "-pHhuZsCiWko",
        "outputId": "960d0e7f-041a-4c22-c658-466b5ae4b51b"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "f = open(\"C:\\Users\\lenovo\\Desktop\\rnn\\wonderland.txt\")\n",
        "print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-e2464ae1883f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    f = open(\"C:\\Users\\lenovo\\Desktop\\rnn\\wonderland.txt\")\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "miVtmPp-i4io",
        "outputId": "8cdfd438-aa53-4207-96e0-833b43eee9b8"
      },
      "source": [
        "from google.colab import files\n",
        "files=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-396b680b-ed22-442f-b201-58e4c8c9722c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-396b680b-ed22-442f-b201-58e4c8c9722c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wonderland.txt to wonderland.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDS3NYVkJn9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv('Titanic (1).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRC1s69-II1"
      },
      "source": [
        "!wget /resources/data/Example1.txt https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/labs/example1.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Vfl2_T-IAw"
      },
      "source": [
        "####################################################################\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKRJdVdl-H4g"
      },
      "source": [
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "Fdtfbw5C-HwT",
        "outputId": "f61ae2ff-0182-4bb9-89e6-8b18fa15b6cc"
      },
      "source": [
        "infile = open(r'C:\\Users\\lenovo\\Desktop\\rnn\\wonderland')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-19f70d07020a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\lenovo\\Desktop\\rnn\\wonderland'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\rnn\\\\wonderland'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzqqeHLO-GcW"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRxCLs0PDWnC"
      },
      "source": [
        "mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "s = np.random.normal(mu, sigma, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5OXpqpYDT0e",
        "outputId": "b33424a4-20ed-4702-e343-00569f7c8cd5"
      },
      "source": [
        "abs(mu - np.mean(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003224074947889331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s86HRxS4T0Gb"
      },
      "source": [
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJufXT3OT5hX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgGxDZAiUWFx",
        "outputId": "f737a812-549f-41a7-cdf0-b435bc90a109"
      },
      "source": [
        "np.mean(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.003224074947889331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24jLM-RtUsU7",
        "outputId": "f6813aa8-5e9e-487b-ddd7-164632af39eb"
      },
      "source": [
        "np.std(X, ddof=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000132953604017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Ze_YxAUxh6"
      },
      "source": [
        "X=np.array(X).reshape(1000000,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "NKeK_PzRUZ-d",
        "outputId": "69a3ef00-2354-4ceb-e201-c914ef1dbea7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "count, bins, ignored = plt.hist(X, 30, density=True)\n",
        "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
        "               np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
        "         linewidth=2, color='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm46xZwXU0Mk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSKTcTruVRn8"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8XXofLSYKIP"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "inMUb-n-ZW-o",
        "outputId": "97c1ca7e-6cfc-4b69-9b6a-043084e71636"
      },
      "source": [
        "\n",
        "# mlp for regression with mse loss function\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "# generate regression dataset\n",
        "X,  x1= make_regression(n_samples=10000, n_features=50, noise=0.1, random_state=1)\n",
        "y,y1= make_regression(n_samples=10000, n_features=1, noise=0.1, random_state=1)\n",
        "#mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "#X = np.random.normal(mu, sigma,50000)\n",
        "#mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "#y = np.random.normal(mu, sigma, 1000)\n",
        "\n",
        "#X=np.array(X).reshape(1000000,1)\n",
        "#y=np.array(y).reshape(400,1)\n",
        "\n",
        "#X = StandardScaler().fit_transform(X)\n",
        "#y = StandardScaler().fit_transform(y)\n",
        "\n",
        "X=np.array(X).reshape(10000,50,1)\n",
        "y=np.array(y).reshape(10000,1)\n",
        "# standardize dataset\n",
        "\n",
        "# split into train and test\n",
        "#trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "#trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "model = Sequential()\n",
        "units=[5,35,50]\n",
        "pa_meters=[]\n",
        "loss_test=[]\n",
        "loss_train=[]\n",
        "for i in units:\n",
        "  \n",
        "  parameter=int(4*(i*i+i*X.shape[2]+i)+(i*1))\n",
        "  pa_meters.append(parameter)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(i, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "  \n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  #opt = adam(lr=0.01)\n",
        "  opt=tf.keras.optimizers.Adam(lr=1e-2,clipvalue=20.0)\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "  # fit model\n",
        "  history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=25, verbose=0)\n",
        "  # evaluate the model\n",
        "  train_mse = model.evaluate(X_train,y_train, verbose=0)\n",
        "  test_mse = model.evaluate(X_test,y_test, verbose=0)\n",
        "  print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "  # plot loss during training\n",
        "  pyplot.title('Loss / Mean Squared Error')\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  #los=np.mean(history.history['val_loss'])\n",
        "\n",
        "  loss_test.append(test_mse)\n",
        "  loss_train.append(train_mse)\n",
        "  #pyplot.legend()\n",
        "  #pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.989, Test: 0.999\n",
            "Train: 0.995, Test: 0.998\n",
            "Train: 0.997, Test: 0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta3UyV1IZ8F_",
        "outputId": "db200b98-330a-42ca-fcd7-1b1132219a80"
      },
      "source": [
        "pa_meters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[145, 5215, 10450]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj1jFDSAbiTU",
        "outputId": "ea52da25-7791-4aad-f661-5aed30f3168b"
      },
      "source": [
        "loss_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9991135001182556, 0.9978903532028198, 0.9955732226371765]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "L808csJbCWJP",
        "outputId": "e8cf4577-1427-4532-96da-6f2725cd17b2"
      },
      "source": [
        "plt.plot(pa_meters,loss_test)\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel(\"sqare error\")\n",
        "plt.title('LSTM model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'LSTM model')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7ZvJyLgCWpI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "uQ-KKa74C7-H",
        "outputId": "b04fcc9f-9c50-4701-deb1-47181b70a0d0"
      },
      "source": [
        "\n",
        "# mlp for regression with mse loss function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "# generate regression dataset\n",
        "X,  x1= make_regression(n_samples=10000, n_features=50, noise=0.1, random_state=1)\n",
        "y,y1= make_regression(n_samples=10000, n_features=1, noise=0.1, random_state=1)\n",
        "#mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "#X = np.random.normal(mu, sigma,50000)\n",
        "#mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "#y = np.random.normal(mu, sigma, 1000)\n",
        "\n",
        "#X=np.array(X).reshape(1000000,1)\n",
        "#y=np.array(y).reshape(400,1)\n",
        "\n",
        "#X = StandardScaler().fit_transform(X)\n",
        "#y = StandardScaler().fit_transform(y)\n",
        "\n",
        "X=np.array(X).reshape(10000,50,1)\n",
        "y=np.array(y).reshape(10000,1)\n",
        "# standardize dataset\n",
        "\n",
        "# split into train and test\n",
        "#trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "#trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "model = Sequential()\n",
        "units=[5,35,50]\n",
        "pa_meters=[]\n",
        "loss_test=[]\n",
        "loss_train=[]\n",
        "for i in units:\n",
        "  \n",
        "  parameter=int(4*(i*i+i*X.shape[2]+i)+(i*1))\n",
        "  pa_meters.append(parameter)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(GRU(i, activation='tanh',input_shape=(X_train.shape[1:])))\n",
        "  \n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  #opt = adam(lr=0.01)\n",
        "  opt=tf.keras.optimizers.Adam(lr=1e-2,clipvalue=20.0)\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "  # fit model\n",
        "  history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=25, verbose=0)\n",
        "  # evaluate the model\n",
        "  train_mse = model.evaluate(X_train,y_train, verbose=0)\n",
        "  test_mse = model.evaluate(X_test,y_test, verbose=0)\n",
        "  print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "  # plot loss during training\n",
        "  pyplot.title('Loss / Mean Squared Error')\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  #los=np.mean(history.history['val_loss'])\n",
        "\n",
        "  loss_test.append(test_mse)\n",
        "  loss_train.append(train_mse)\n",
        "  #pyplot.legend()\n",
        "  #pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 1.000, Test: 0.994\n",
            "Train: 0.999, Test: 0.994\n",
            "Train: 0.998, Test: 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpsPOWL8CFj_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuLa6dQ-GFlY",
        "outputId": "80fd5f77-0609-4547-8b5b-9eedef8de4c7"
      },
      "source": [
        "np.mean(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.029869216457009316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz0thONkbN52",
        "outputId": "e1c714ea-c4df-487b-c044-c154e73d205c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LVeUyfLbQct"
      },
      "source": [
        "mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "X = np.random.normal(mu, sigma, 1000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ4TjCo7fKiH",
        "outputId": "2ab001b5-f341-459b-abdb-1389343bda5e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUqVmdNfLI6S"
      },
      "source": [
        "X,X1= make_regression(n_samples=1000000, n_features=50, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XjeKdCLYz6"
      },
      "source": [
        "y,y1 = make_regression(n_samples=400, n_features=50, noise=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sftN-zS2Ldss",
        "outputId": "688c9e39-25ec-41e3-eac7-8a4e6036e76e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCMpMsIvLfK7",
        "outputId": "eb52d275-a106-4125-b69d-dc1c46ef469d"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvR_OuFrMR_p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "8SgAtivMMU2c",
        "outputId": "b823df0b-da49-4fb0-c334-6a5391e1f680"
      },
      "source": [
        "# mlp for regression with mse loss function\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "# generate regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
        "# standardize dataset\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]\n",
        "# split into train and test\n",
        "n_train = 500\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "# fit model\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
        "# evaluate the model\n",
        "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
        "test_mse = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "# plot loss during training\n",
        "pyplot.title('Loss / Mean Squared Error')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.003, Test: 0.008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BC5Efy8SzFs",
        "outputId": "2b23f72a-1157-42b0-9e3d-fbf49598b998"
      },
      "source": [
        "np.mean(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3798107302188873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3KgZMCGYmBN"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "M_oA0c_TS9IC",
        "outputId": "d755ec15-f121-479d-984b-4cf5a4588e4b"
      },
      "source": [
        " plt.plot([1000,2500,6000,10000],[0.9,0.85,0.82,0.80],\n",
        "          [1000,2500,6000,10000],[0.92,0.89,0.86,0.84])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('square error')\n",
        " #plt.title('LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'square error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4KCT5fiTZk2j",
        "outputId": "67ecf3a3-285e-4670-adaa-ef274f27714e"
      },
      "source": [
        " plt.plot([1000,2500,6000,10000],[0.98,0.977,0.974,0.973])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('square error')\n",
        " plt.title('RNN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'RNN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9bnH8c+ThIQtBAhhDTsohl0jgoos1ooKCMhVsFWxdal1a7221WvduJdqq7XuVlsR7aLiCi6IGyriRpB9CURcSEBBNKyyBJ77x0ziIY2QkBzOSfJ9v17nxZmZ30yeOR7z5DfPzO9n7o6IiEhFJMQ6ABERqX6UPEREpMKUPEREpMKUPEREpMKUPEREpMKUPEREpMKUPEREpMKUPESqkJl9ZmbfmdlWM/vSzKaYWcNw2xQzczPrF9G+i5l5xPJbZrbDzNpGrPuRmX12SE9E5ACUPESq3gh3bwj0AfoC10Zs+wb4vwPsvw24PkqxiVQJJQ+RKHH3L4GZBEmk2KNALzMbtJ9d7wbGm1nnaMYnUhlKHiJRYmaZwClAXsTq7cAfgEn72bUA+Btwc/SiE6kcJQ+Rqve8mW0B1gDrgRtLbX8QaGdmp+znGLcAI8yse5RiFKkUJQ+RqjfK3VOBwUA3oFnkRnffCfxv+CqTu28A7gUmRi9MkYOn5CESJe7+NjAFuL2MzY8AjYEx+znEbcAQ4KgqD06kkpJiHYBIDXcn8JmZ9Y5c6e5FZnYjQXG8TO5eaGZ/Bn4LbIlumCIVo56HSBSFl58eA24oY/PjwLoDHOIuYE9VxyVSWabJoEREpKLU8xARkQpT8hARkQpT8hARkQpT8hARkQqrFbfqNmvWzDt06BDrMEREqpV58+Z97e4ZZW2rFcmjQ4cO5OTkxDoMEZFqxcw+/6FtumwlIiIVpuQhIiIVpuQhIiIVpuQhIiIVpuQhIiIVFtXkYWbDzCzXzPLM7Joytrc3szfMbJGZvRXOvFa87U9mttTMlpvZ3WZm4fqjzGxxeMyS9SIicuhELXmYWSJwH8E0nFkEczJnlWp2O/CYu/cimPTmlnDfY4HjgF5AD+BooHjO5weAC4Gu4WtYtM5BRETKFs2eRz8gz91Xu/su4Ang9FJtsoA3w/ezIrY7UBdIBlKAOsBXZtYKaOTuH3gwHPBjwKhoncCrS7/k8Y++iNbhRUSqrWgmjzYEczgXyw/XRVrI9zOpjQZSzSzd3d8nSCbrwtdMd18e7p9/gGMCYGYXmVmOmeVs2LDhoE7gmY/zmfjCMgoKvzuo/UVEaqpYF8yvBgaZ2XyCy1IFwB4z6wIcAWQSJIehZjawIgd294fcPdvdszMyyny6/oCuH56F40x6adlB7S8iUlNFM3kUAG0jljPDdSXcfa27j3H3vsB14bpCgl7IB+6+1d23AjOAAeH+mfs7ZlXKbFKfy4Z04eXFXzJ71cH1XkREaqJoJo+5QFcz62hmycA4YHpkAzNrZmbFMVwLTA7ff0HQI0kyszoEvZLl7r4O2Gxm/cO7rM4FpkXxHLjwhE50SK/PjdOXsqtobzR/lIhItRG15OHuRcBlwExgOTDV3Zea2UQzGxk2GwzkmtlKoAUwKVz/NPAJsJigLrLQ3V8It/0S+DuQF7aZEa1zAEhJSuTGkd1ZvWEbD7/7aTR/lIhItVEr5jDPzs72yo6qe9FjObyb9zWvXzWI1o3rVVFkIiLxy8zmuXt2WdtiXTCvNq4fnsWevc6kl5bHOhQRkZhT8iintk3rc+mQLry0eB3vrvo61uGIiMSUkkcFXHRCJ9qn1+fG6UtUPBeRWk3JowLq1knkxhFZfLJhG4/MUfFcRGovJY8KGtqtBT86ogV3vbGKdZv05LmI1E5KHgfhxhEqnotI7abkcRDaNq3PLwd34cVF63gvT8VzEal9lDwO0sWDOtGuaX1u0JPnIlILKXkcpOLied76rUx5T8VzEaldlDwq4cQjWnBit+bc9foqvtq8I9bhiIgcMkoelXTjiO7sVvFcRGoZJY9Kapden0sGdWb6wrW894mK5yJSOyh5VIFLBnembdN63DhtKbv3qHguIjWfkkcVqFsnkRuHd2fV+q08+t5nsQ5HRCTqlDyqyI+yWjC0W3P+8tpKFc9FpMZT8qhCN47IYvde5w8vq3guIjWbkkcVap/egF+c0IlpC9byweqNsQ5HRCRqlDyq2CWDu5DZRMVzEanZlDyqWL3kRG4YnkXuV1tUPBeRGiuqycPMhplZrpnlmdk1ZWxvb2ZvmNkiM3vLzDLD9UPMbEHEa4eZjQq3DTWzj81siZk9amZJ0TyHg3FSVgsGH57Bna+vYr2K5yJSA0UteZhZInAfcAqQBYw3s6xSzW4HHnP3XsBE4BYAd5/l7n3cvQ8wFNgOvGpmCcCjwDh37wF8DpwXrXM4WGbGTSO6s6toL7fMWBHrcEREqlw0ex79gDx3X+3uu4AngNNLtckC3gzfzypjO8BYYIa7bwfSgV3uvjLc9hpwRpVHXgU6NGvAxYM68dz8Aj5U8VxEaphoJo82wJqI5fxwXaSFwJjw/Wgg1czSS7UZBzwevv8aSDKz7HB5LNC2rB9uZheZWY6Z5WzYsOEgT6Fyfjm4C20a1+PG6UspUvFcRGqQWBfMrwYGmdl8YBBQAOwp3mhmrYCewEwAd3eCZPIXM/sI2BLZPpK7P+Tu2e6enZGREd2z+AH1khO5fngWK77cwmPvfx6TGEREoiGayaOAfXsFmeG6Eu6+1t3HuHtf4LpwXWFEkzOB59x9d8Q+77v7QHfvB7wDrCSOndy9BYMOy+Avr61k/RYVz0WkZohm8pgLdDWzjmaWTNBjmB7ZwMyahUVwgGuByaWOMZ7vL1kV79M8/DcF+B3w1yjEXmXMjJtGdmdn0V5ufVnFcxGpGaKWPNy9CLiM4JLTcmCquy81s4lmNjJsNhjINbOVQAtgUvH+ZtaBoOfydqlD/8bMlgOLgBfc/U3iXMdmDbjwhI48O7+AuZ99E+twREQqzYIyQs2WnZ3tOTk5MY1h+64iTrrjHVLrJvHi5ceTlBjrcpOIyP6Z2Tx3zy5rm36DHSL1k5O4fvgRrPhyC//4QMVzEanelDwOoZO7t2Rg12bc8epKNmzZGetwREQOmpLHIWRm3DyyOzuK9nCrnjwXkWpMyeMQ65TRkAsHduKZj/PJUfFcRKopJY8YuGxoF1qn1eX6aXryXESqJyWPGKifnMTvh2exfN1m/vXhF7EOR0SkwpQ8YuSUHkHx/PZXc/l6q4rnIlK9KHnESPGT5zt2q3guItWPkkcMdc5oyM+P78TT8/KZ9/m3sQ5HRKTclDxi7PKhXWiVVpcbpi1hz96a/7S/iNQMSh4x1iAlid+flsXStZv594d68lxEqgcljzhwas+WHNclndtm5rJRxXMRqQaUPOJA8ZPn23ft4Y+vqHguIvFPySNOdGmeys8HdmRqTj4ff6HiuYjENyWPOHLF0K60bKTiuYjEPyWPONIgJYnrTjuCJQWb+fdHevJcROKXkkecGd6rFcd2Tuf2mbl8s21XrMMRESmTkkecKS6eb9tZxJ9UPBeROKXkEYe6tkjlZ8d35Im5a5iv4rmIxCEljzh1xYldadEohRumLVXxXETiTlSTh5kNM7NcM8szs2vK2N7ezN4ws0Vm9paZZYbrh5jZgojXDjMbFW470cw+Dte/a2ZdonkOsdIwJYnrTsticcEmnpir4rmIxJeoJQ8zSwTuA04BsoDxZpZVqtntwGPu3guYCNwC4O6z3L2Pu/cBhgLbgVfDfR4AfhJu+zfw+2idQ6yN6NWKAZ3S+dMrKp6LSHyJZs+jH5Dn7qvdfRfwBHB6qTZZwJvh+1llbAcYC8xw9+3hsgONwvdpwNoqjTqOmBk3nx4Uz2+bqeK5iMSPaCaPNsCaiOX8cF2khcCY8P1oINXM0ku1GQc8HrF8AfCymeUD5wC3lvXDzewiM8sxs5wNGzYc5CnE3mEtUplwbAeemLuGhWsKYx2OiAgQ+4L51cAgM5sPDAIKgD3FG82sFdATmBmxz6+BU909E3gEuKOsA7v7Q+6e7e7ZGRkZ0Yr/kLjyR13JaJjC9XryXETiRDSTRwHQNmI5M1xXwt3XuvsYd+8LXBeui/zz+kzgOXffDWBmGUBvd/8w3P4kcGyU4o8bqXXrcN1pR7AofxNPzl1z4B1ERKIsmsljLtDVzDqaWTLB5afpkQ3MrJmZFcdwLTC51DHGs+8lq2+BNDM7LFw+CVhe5ZHHoZG9W3NMx6b8aeYKvlXxXERiLGrJw92LgMsILjktB6a6+1Izm2hmI8Nmg4FcM1sJtAAmFe9vZh0Iei5vlzrmhcAzZraQoObxm2idQzwxMyae3oMtO4q47dXcWIcjIrWcudf8a+jZ2dmek5MT6zCqxP++uIzJcz5l2qXH0SuzcazDEZEazMzmuXt2WdtiXTCXCvrVj7rSrGEK109byl4Vz0UkRpQ8qpnUunX4n1O7sXBNIVNzVDwXkdhQ8qiGRvVpQ78OTfnjKyso3K7iuYgcekoe1ZCZMXFUdzbvKOK2mSqei8ihp+RRTXVr2YhzB7Tn3x99weL8TbEOR0RqGSWPauzXJx1GeoPgyXMVz0XkUFLyqMYahcXzBWsKeWqeiucicujsN3mYWYKZnXmogpGKG923DUd3aMIfX8lV8VxEDpn9Jg933wv89hDFIgchmPO8B4Xbd/HnV1fGOhwRqSXKc9nqdTO72szamlnT4lfUI5Nyy2rdiHMHdOBfH37OkgIVz0Uk+sqTPM4CLgXeAeaFr5ox1kcN8uuTDqNpg2QVz0XkkDhg8nD3jmW8Oh2K4KT80urV4ZpTjmD+F4U8/XF+rMMRkRrugMnDzOqY2RVm9nT4uszM6hyK4KRixvRtQ3b7Jvxxxgo2bd8d63BEpAYrz2WrB4CjgPvD11HhOokzCQnBsO3fbt/Fn1/Tk+ciEj1J5WhztLv3jlh+M5xLQ+JQVutGnNO/Pf/44HPOOrot3VunxTokEamBytPz2GNmnYsXzKwTEfOMS/y56seH06R+Mjdo2HYRiZLyJI+rgVlm9paZvQ28Cfx3dMOSygiK592Y9/m3PDu/4MA7iIhU0H4vW5lZItAb6AocHq7Odfed0Q5MKueMIzN5/KMvuOXl5ZyU1YK0errHQUSqzoGeMN8DjHf3ne6+KHwpcVQDkcXzv7ymJ89FpGqV57LVHDO718wGmtmRxa/yHNzMhplZrpnlmdk1ZWxvb2ZvmNmi8LJYZrh+iJktiHjtMLNR4bbZEevXmtnzFTrjWqRHmzR+2r89j73/GcvWbo51OCJSg5j7/guqZjarjNXu7kMPsF8isBI4CcgH5hL0YpZFtHkKeNHdHzWzocD57n5OqeM0BfKATHffXmrbM8A0d39sf7FkZ2d7Tk7tfCh+0/bdDP3zW3Rs1oCnfjEAM4t1SCJSTZjZPHfPLmvbgUbVTQSmu/uQUq/9Jo5QPyDP3Ve7+y7gCeD0Um2yCArwALPK2A4wFphRRuJoBAwF1PPYj7T6dfjdsG7kfP4t97yZp7uvRKRKlKvmcZDHbgNETjKRH66LtBAYE74fDaSaWXqpNuOAx8s4/ijgDXcv83qMmV1kZjlmlrNhw4YKB1+TjD0qk9N6tuKO11YyYcpc1m/ZEeuQRKSai2rNoxyuBgaZ2XxgEFBAxDMkZtYK6AnMLGPf8ZSdVABw94fcPdvdszMyMqoo3OopIcG49+y+/N+oHnz06UZOuXM2byz/KtZhiUg1Vp4nzPuE/06MWOcEl4z2pwBoG7GcGa77/iDuawl7HmbWEDjD3QsjmpwJPOfu+wzUZGbNCC6LjS5H/EIw78dP+7enf6emXP74An7+aA7nDmjP/5x6BHXrJMY6PBGpZg6YPNx9yEEeey7Q1cw6EiSNccDZkQ3CJPBNOOnUtcDkUscYH64vbSxBoV3XXyqoS/NUnr/0WP70Si4Pv/spH6zeyN3j+9KtZaNYhyYi1Uh5RtVtYWYPm9mMcDnLzH5+oP3cvQi4jOCS03JgqrsvNbOJZjYybDYYyDWzlUALYFLEz+1A0HN5u4zD/1AdRMohJSmR64dn8ejP+vHNtt2MvHcOj8z5lAPdeSciUqw8t+rOAB4BrnP33maWBMx3956HIsCqUJtv1T2QjVt38tunF/HGivUMPjyD28b2JiM1JdZhiUgcOOhbdUPN3H0qsBdKehQaGLGGSG+Ywt/Py2bi6d15/5ONnHLXO8xasT7WYYlInCtP8tgW3j7rAGbWH9BE2TWImXHugA68cPnxNGuYwvlT5nLT9KXs2K2/EUSkbOVJHlcB04HOZjYHeAy4PKpRSUwc1iKV5y89jvOP68CU9z5j1H1zyP1yS6zDEpE4dMCaB0BY5zgcMIJRdavVHKeqeVTcrNz1/OaphWzZUcT/nHoE5w5or6FNRGqZytY8cPcid1/q7kuqW+KQgzPk8ObMuPIEBnRO58bpS7ng0Ry+3qoBlUUkUK7kIbVTRmoKj0w4mptGZDE772uG3Tmbt1fW7qFeRCSg5CH7ZWZMOK4j0y87jqYN6nDe5I+Y+MIydhapmC5Sm5XnIUEzs5+a2Q3hcjsz6xf90CSedGvZiOmXHc95A9ozec6njLrvPVZ9pWK6SG1Vnp7H/cAAvh9ddwtwX9QikrhVt04iN5/eg8kTslm/eQfD73mXf3zwuZ5MF6mFypM8jnH3S4EdAO7+LZAc1agkrg3t1oIZvxrIMZ3Suf75JVz42Dy+2bYr1mGJyCFUnuSxO5wUqvghwQzCp82l9mqeWpcpE47m+uFZvLNyAyff+Q6zV6mYLlJblCd53A08BzQ3s0nAu8AfohqVVAsJCcbPj+/I85ceR+N6dTjn4Y+Y9JKK6SK1wYGmoU0APgV+C9wCrANGuftThyA2qSayWgfF9J/2b8ffZn/KmPvfI2/91liHJSJRVJ5Rdee7e99DFE9U6AnzQ+e1ZV/x26cX8t3uPVw/PIuz+7XTk+ki1VRlnzB/w8zOMP0GkHI4KasFM391Akd3aMp1zy3h4n/M41sV00VqnPIkj4uBp4CdZrbZzLaY2eYoxyXVWPNGdXn0/H78/rQjmJW7nmF3vcOcvK9jHZaIVKEDJg93T3X3BHdPdvdG4bLmLJX9SkgwLhjYied+eRwNU5L46cMfcsvLy9lVpBv1RGqCcg1PYmZNzKyfmZ1Q/Ip2YFIz9GiTxouXD2R8v3Y8+M5qznjgPVZvUDFdpLorz/AkFwDvEMxFfnP4703RDUtqknrJifxhdE8ePOco1ny7ndPufpcnPvpCT6aLVGPl6XlcCRwNfO7uQ4C+QGF5Dm5mw8ws18zyzOyaMra3N7M3zGyRmb1lZpnh+iFmtiDitcPMRoXbzMwmmdlKM1tuZleU+2wlpk7u3pJXrjyBvu0ac82zi/nlvz6mcLuK6SLVUXmSxw533wFgZinuvoJgYqj9Cp9Kvw84BcgCxptZVqlmtwOPuXsvYCLBsyS4+yx37+PufYChwHbg1XCfCUBboJu7HwE8UY5zkDjRMq0u//z5MVx7SjdeX/4Vw+6czfufbIx1WCJSQeVJHvlm1hh4HnjNzKYBn5djv35AnruvdvddBL/kTy/VJgt4M3w/q4ztAGOBGe6+PVy+BJjo7nsB3H19OWKROJKQYFw8qDPPXnIc9ZMTOfvvH/DHV1awe4+K6SLVRXnuthrt7oXufhNwPfAwMKocx24DrIlYzg/XRVoIjAnfjwZSzSy9VJtxwOMRy52Bs8wsx8xmmFnXsn64mV0UtsnZsEFjLsWjnplpvHjF8ZyV3ZYH3vqEMx54j0+/3hbrsESkHMpTMG9X/CIYqmQB0LKKfv7VwCAzmw8MAgqAkoGRzKwV0JOgSF8sheBSWjbwN2ByWQd294fcPdvdszMyMqooXKlq9ZOTuPWMXjzwkyP5fON2Trt7NlPnrlExXSTOJZWjzUsEI+oaUBfoCOQC3Q+wXwFBbaJYZriuhLuvJex5mFlD4Ax3jyzGnwk8V2re9Hzg2fD9c8Aj5TgHiXOn9GxFn3aNuerJhfz2mUW8vXIDfxjdk7T6dWIdmoiUoTyXrXq6e6/w364EtYz3y3HsuUBXM+toZskEl5+mRzYws2bh4IsA1/KfvYjx7HvJCoLay5Dw/SBgZTlikWqgVVo9/nnBMfxuWDdmLv2SU+56hw9Xq5guEo8qPIe5u38MHFOOdkXAZQSXnJYDU919qZlNNLORYbPBQK6ZrQRaAJOK9zezDgQ9l7dLHfpW4AwzW0xwd9YFFT0HiV+JCcYlgzvzzCXHkpyUwLi/fcBtM1VMF4k35RlV96qIxQTgSCDd3U+OZmBVSaPqVk/bdhZx8wtLmZqTT++2jbl7XB/apzeIdVgitUZlR9VNjXilENRAyrqlVqRKNUhJ4k9je3Pf2Ufy6YatnHrXbJ6el69iukgcOGDPoyZQz6P6Kyj8jl8/uYCPPv2G4b1aMWl0T9LqqZguEk3763kc8G4rM3uBcP7ysrj7yB/aJlJV2jSux+MX9uevb3/CHa+tZP4Xhdw5rg9Hd2ga69BEaqXyXLZaDXxH8EzF34CtwCfAn8OXyCGRmGBcOqQLT/9iAIkJxlkPvs8dr+ZSpGK6yCFXnoJ5TuluS1nr4pkuW9U8W3cWceO0pTzzcT592zXmrrP60i69fqzDEqlRKlswb2BmnSIO1hHQLS8SUw1Tkvjzmb25Z3xf8tZv5dS7Z/Pc/PxYhyVSa5QnefwaeCscMv1tggEMr4xuWCLlM6J3a2ZcOZAjWqXy6ycXcuUT89m8Y/eBdxSRSinX3VZmlgJ0CxdXuPvOqEZVxXTZquYr2rOX+9/6hLveWEWrtLrcNa4PR7VXMV2kMip12crM/gtIdveFwAjgcTM7sopjFKmUpMQErjixK1MvHoAZ/Ndf3+fO11eqmC4SJeW5bHW9u28xs+OBEwmGZH8gumGJHJyj2jfh5SsGMqpPG+58fRXjHvqANd9sP/COIlIh5UkexUOknwb8zd1fApKjF5JI5aTWrcMdZ/XhrnF9yP1yC6feNZtpCwoOvKOIlFt5kkeBmT0InAW8HNY/KjygosihdnqfNrx85UAOa5nKlU8s4KonF7BFxXSRKlGeJHAmwci4J4dzbTQFfhPVqESqSNum9Xnyov786kddeX5BAafd/S4ff/FtrMMSqfbKM5/Hdnd/1t1Xhcvr3P3V6IcmUjWSEhP41Y8OY+rFA9iz1/mvv77P3W+sYs/emj+um0i06PKT1BrZHZoy41cDGd6rFXe8tpLxD31AQeF3sQ5LpFpS8pBapVHdOtw1ri9/Oas3y9ZtZtid7/DCwrWxDkuk2lHykFppdN9MXr5iIF2aN+Tyx+fz31MXsnVnUazDEqk2lDyk1mqXXp+pFw/giqFdeG5+PqfdPZsFawpjHZZItaDkIbVancQErvrx4Txx0QCK9jhjH3iP+2blqZgucgBRTR5mNszMcs0sz8yuKWN7ezN7w8wWhQMvZobrh5jZgojXDjMbFW6bYmafRmzrE81zkNqhX8emvHzlQIb1aMltM3M5+28fsFbFdJEfFLVpaM0sEVgJnATkA3OB8e6+LKLNU8CL7v6omQ0Fznf3c0odpymQB2S6+3YzmxLu83R5Y9HAiFJe7s4zHxdw47QlJCYYt57Ri1N7top1WCIxUdn5PA5WPyDP3Ve7+y7gCeD0Um2ygDfD97PK2A4wFpjh7hqgSKLOzBh7VCYvXTGQjs0a8Mt/fcxvn17INhXTRfYRzeTRBlgTsZwfrou0EBgTvh8NpJpZeqk244DHS62bFF7q+ks4XMp/MLOLzCzHzHI2bNhwcGcgtVaHZg14+pJjuXRIZ56al8/we95lUb6K6SLFYl0wvxoYZGbzgUFAAd8PxIiZtQJ6EgyPUuxagrlFjiYYKuV3ZR3Y3R9y92x3z87IyIhS+FKT1UlM4Dcnd+PxC/uzY/cextz/Hg+89Ql7VUwXiWryKADaRixnhutKuPtadx/j7n2B68J1kX/enQk85+67I/ZZ54GdwCMEl8dEoqZ/p3ReufIEfty9BX98ZQU/+fuHrNukYrrUbtFMHnOBrmbW0cySCS4/TY9sYGbNzKw4hmuByaWOMZ5Sl6zC3ghmZsAoYEkUYhfZR1r9Otx39pH86YxeLMwvZNids3llybpYhyUSM1FLHu5eBFxGcMlpOTDV3Zea2UQzGxk2GwzkmtlKoAUwqXh/M+tA0HN5u9Sh/2Vmi4HFQDPg/6J1DiKRzIwzj27LS1cMpH16fX7xz4+59tlFbN+lYrrUPlG7VTee6FZdqWq7ivbyl9dX8te3P6FjswbcPa4vPdqkxToskSoVq1t1RWqs5KQEfjesG/+64Bi279zD6Pvn8ODbKqZL7aHkIVIJx3ZuxowrB3JitxbcMmMF50z+kK8274h1WCJRp+QhUklNGiTzwE+P5NYxPfn480KG3fkOry79MtZhiUSVkodIFTAzxvVrx4tXHE+bJvW46B/z+J/nFvPdrj0H3lmkGlLyEKlCnTMa8uwlx3HxCZ3494dfMPye2SxduynWYYlUOSUPkSqWnJTAtacewb8uOIatO4sYfd97/H32ahXTpUZR8hCJkuO6NOOVK09g8OEZ/N9LyznvkY9Yr2K61BBKHiJR1KRBMg+ecxSTRvdg7mffMOyu2by+7KtYhyVSaUoeIlFmZvzkmPa8ePnxtGxUlwsey+H655ewY7eK6VJ9KXmIHCJdmqfy3KXHcuHAjvzjg88Zcc+7LF+3OdZhiRwUJQ+RQyglKZHrTsvisZ/1o/C73Zx+7xwmv/sptWGYIKlZlDxEYuCEwzJ45cqBnHBYMya+uIwJj8xlw5adsQ5LpNyUPERiJL1hCn87N5v/HdWDD1ZvZNid7/DmChXTpXpQ8hCJITPjnP7teeHy48lITeFnU3K4afpSFdMl7il5iMSBw1qk8vylx/Gz4zoy5b3POP3eOeR+uSXWYYn8ICUPkThRt04iN4zIYsr5R7Nx2y5G3PsuU+aomC7xSclDJM4MPrw5r/xqIMd1TuemF5bxsylz+XqriukSX5Q8ROJQs4YpTJ5wNDeP7M6cT4Ji+lu562MdlkgJJQ+ROABK5Q8AABBySURBVGVmnHdsB1647HjSG6Qw4ZG53PyCiukSH5Q8ROLc4S1TmXbZcUw4tgOPzPmMUffNYeVXKqZLbEU1eZjZMDPLNbM8M7umjO3tzewNM1tkZm+ZWWa4foiZLYh47TCzUaX2vdvMtkYzfpF4UbdOIjeN7M4jE47m6607GXHPu/zj/c9UTJeYiVryMLNE4D7gFCALGG9mWaWa3Q485u69gInALQDuPsvd+7h7H2AosB14NeLY2UCTaMUuEq+GdGvOjCtPoH+ndK6ftpQLH8tho4rpEgMWrb9czGwAcJO7nxwuXwvg7rdEtFkKDHP3NWZmwCZ3b1TqOBcBg9z9J+FyIvA6cDawyt0bHiiW7Oxsz8nJqaIzE4m9vXudKe99xq0zVrDXncNbptIrszF92qbRK7MxXZs3JClRV6Wlcsxsnrtnl7UtKYo/tw2wJmI5HzimVJuFwBjgLmA0kGpm6e6+MaLNOOCOiOXLgOnuvi7IN2ULk85FAO3atTvYcxCJSwkJxs+O78jxXZsxbUEBi/I38dKitTz+0RcA1KuTSI82jeiV2ZjebRvTOzONdk3rs7//Z0QqIpo9j7EEvYoLwuVzgGPc/bKINq2Be4GOwDvAGUAPdy8Mt7cCFgGt3X132H4qMNjdi8xsq3oeIgF357ON21mUX8iCNYUsyt/EkoJN7CzaC0Dj+nWC3klm0Dvp1TaN5ql1Yxy1xLNY9TwKgLYRy5nhuhLuvpag54GZNQTOKE4coTOB59x9d7jcF+gC5IV/QdU3szx37xKdUxCpPsyMjs0a0LFZA07v0waA3Xv2svKrLSxcs6kkqdz31tfsCedTb51Wd5/eSc/MNFLr1onlaUg1Ec2eRxKwEjiRIGnMBc5296URbZoB37j7XjObBOxx9xsitn8AXOvus37gZ6jnIVJB3+3aw9K1m0p6JwvzC/l843YAzKBTswZhMgmSyhGtUklJSoxx1BILMel5hJeVLgNmAonAZHdfamYTgRx3nw4MBm4xMye4bHVpRNAdCHoub0crRpHaqF5yItkdmpLdoWnJum+37WJRwSYWrSlkYX4hs1d9zbMfBxcK6iQa3Vo2ondYjO/TtjGdMxqSmKD6SW0WtZ5HPFHPQ6Ri3J0vN+9g4ZpCFuZvYuGaQhbnb2LLziIAGiQn0qNNGr3bNqZXZhq9MxuT2aSeCvI1TKxqHiJSTZkZrdLq0SqtHsN6tAKC24NXf72NRfmFJUllynufsSssyDdtkEzvzO97J70y00hvmBLL05AoUvIQkXJJSDC6NG9Il+YNGXNkJgC7ivaS++UWFoYJZVH+Jt5auYriCxqZTeqFtZMgqfRsk0aDFP3aqQl02UpEqtS2nUUsKQgK8Qvzg7u81nzzHRAU5Ls2b7jPHV7dWjYiOUkPNMYjXbYSkUOmQUoSx3RK55hO6SXrNm7dyaKCTSW9k1kr1vP0vHwAkhMTOKJ1I3qHtZPebdPo1KwhCSrIxzX1PETkkHN3Cgq/K3n+ZGF+UJDftisYbj41JamkIN87M/i3VVpdFeQPMfU8RCSumBmZTeqT2aQ+p/UKCvJ79jqrN2zd5/mTh99dze49wR+4zRqmlCSS4ju8mjRIjuVp1GpKHiISFxITjK4tUunaIpX/yg4Gp9hZtIfl67bsM+TKm7nrSwry7ZrW36d30r11I+on69faoaDLViJSrWzZsZvFBZuC3kmYUAoKg4J8gsFhLVLpHY7d1TuzMYe3TKWORhg+KPu7bKXkISLV3oYtO8PaSXFCKeTb7cGQeClJCXRvXTzCcJBQOqQ3UEG+HJQ8lDxEahV3Z8033+3z/Mnigk18F87/nlo3KeidZKaVjOPVMk0jDJemgrmI1CpmRrv0+rRLr8+I3q0BKNqzl7wNW0uejl+UX8hD76ymKBxhuEWjlKB3UlyUb9OYtPoaYfiHKHmISK2QlJhAt5aN6NayEWcdHazbsXsPy9ZtLumdLFxTyGvLvirZp2OzBiV3dvVum0b31mnUraMRhkHJQ0Rqsbp1EjmyXROObNekZN2m73azpKB4yPpCPlz9DdMWrAWCO8IOb5FaUjvpldmYw1rUzil/VfMQETmAr8IRhoufP1m4ppDNO4IRhuvWSaBH6++fP+nTtnGNmfJXNQ8RkUpo0aguP+7ekh93bwnsO+XvwjVBQvnnB5/vM+VvzzZp4ejCQR2leaOaVZBX8hARqaD9TflbXDtZmL+J+9/6pGTK31Zpdfd5/qRnZhqNqvGUv7psJSISJcVT/kY+f/JZOOUvQKeMBvSJuGX4iFaN4qogr8tWIiIxUNaUv4Xbd+3TO5md9zXPzt93yt/v7/BqTJfm8Tnlr3oeIiIx9P2Uv0HtZFF+IYvWfD/lb/3iKX8jHmg8VFP+xuwJczMbBtwFJAJ/d/dbS21vD0wGMoBvgJ+6e76ZDQH+EtG0GzDO3Z83s4eBbMCAlcAEd9+6vziUPESkOtm71/l047aSO7wWrClk2brN+0z526tkyt/g32ZRmPI3JsnDzBIJfrmfBOQDc4Hx7r4sos1TwIvu/qiZDQXOd/dzSh2nKZAHZLr7djNr5O6bw213AOtLJ6XSlDxEpLrbVRQU5IufP1m4ZhOr1m8hrMfTpnG9fZ4/6ZmZRsNKTvkbq5pHPyDP3VeHQTwBnA4si2iTBVwVvp8FPF/GccYCM9x9O0BE4jCgHlDzr7uJSK2XnJRAjzZp9GiTBrQHvp/yt+T5k/xCXl78JRBM+dsloyEP/PRIujRPrfJ4opk82gBrIpbzgWNKtVkIjCG4tDUaSDWzdHffGNFmHHBH5E5m9ghwKkEi+u+yfriZXQRcBNCuXbuDPwsRkThV1pS/32zbFdROwhpKtJ4vifXdVlcD95rZBOAdoADYU7zRzFoBPYGZkTu5+/nhZbF7gLOAR0of2N0fAh6C4LJVlOIXEYkrTRskM+Tw5gw5vHlUf040B2QpANpGLGeG60q4+1p3H+PufYHrwnWFEU3OBJ5z992lD+7ue4AngDOqOnAREdm/aCaPuUBXM+toZskEl5+mRzYws2ZmVhzDtQR3XkUaDzwe0d7MrEvxe2AksCJK8YuIyA+IWvJw9yLgMoJLTsuBqe6+1MwmmtnIsNlgINfMVgItgEnF+5tZB4Key9sRhzXgUTNbDCwGWgETo3UOIiJSNj0kKCIiZdrfrbq1bxB6ERGpNCUPERGpMCUPERGpMCUPERGpsFpRMDezDcDnsY6jkpoBX8c6iDihz2Jf+jz2pc/je5X9LNq7e0ZZG2pF8qgJzCznh+56qG30WexLn8e+9Hl8L5qfhS5biYhIhSl5iIhIhSl5VB8PxTqAOKLPYl/6PPalz+N7UfssVPMQEZEKU89DREQqTMlDREQqTMkjRsysrZnNMrNlZrbUzK4M1zc1s9fMbFX4b5NwvZnZ3WaWZ2aLzOzIiGOdF7ZfZWbnxeqcKsvMEs1svpm9GC53NLMPw3N+MhzaHzNLCZfzwu0dIo5xbbg+18xOjs2ZVJ6ZNTazp81shZktN7MBtfy78evw/5MlZva4mdWtTd8PM5tsZuvNbEnEuir7PpjZUWa2ONzn7nDKi/1zd71i8CIYTv7I8H0qsJJgTvc/AdeE668B/hi+PxWYQTAsfX/gw3B9U2B1+G+T8H2TWJ/fQX4mVwH/Bl4Ml6cC48L3fwUuCd//Evhr+H4c8GT4PotgauMUoCPwCZAY6/M6yM/iUeCC8H0y0Li2fjcIprT+FKgX8b2YUJu+H8AJwJHAkoh1VfZ9AD4K21q47ykHjCnWH4peJV+EacBJQC7QKlzXCsgN3z8IjI9onxtuHw88GLF+n3bV5UUw0+QbwFDgxfBL/DWQFG4fAMwM388EBoTvk8J2RjCh2LURxyxpV51eQFr4y9JKra+t3402wJrwl15S+P04ubZ9P4AOpZJHlXwfwm0rItbv0+6HXrpsFQfCbnVf4EOghbuvCzd9STBJFnz/P1Cx/HDdD62vbu4EfgvsDZfTgUIPJhWDfc+r5JzD7ZvC9jXls+gIbAAeCS/j/d3MGlBLvxvuXgDcDnwBrCP47z2P2vv9KFZV34c24fvS6/dLySPGzKwh8AzwK3ffHLnNgz8Davy91GY2HFjv7vNiHUucSCK4RPGAu/cFthFclihRW74bAOG1/NMJkmproAEwLKZBxZlYfB+UPGLIzOoQJI5/ufuz4eqvzKxVuL0VsD5cX0AwLW+xzHDdD62vTo4DRprZZ8ATBJeu7gIam1lS2CbyvErOOdyeBmykZnwWEPzll+/uH4bLTxMkk9r43QD4EfCpu29w993AswTfmdr6/ShWVd+HgvB96fX7peQRI+HdDA8Dy939johN04HiuyDOI6iFFK8/N7yToj+wKeyyzgR+bGZNwr/Qfhyuqzbc/Vp3z3T3DgQFzjfd/SfALGBs2Kz0Z1H8GY0N23u4flx4t01HoCtBIbBacfcvgTVmdni46kRgGbXwuxH6AuhvZvXD/2+KP49a+f2IUCXfh3DbZjPrH36+50Yc64fFughUW1/A8QTdzEXAgvB1KsG12TeAVcDrQNOwvQH3EdwhshjIjjjWz4C88HV+rM+tkp/LYL6/26oTwf/cecBTQEq4vm64nBdu7xSx/3XhZ5RLOe4YidcX0AfICb8fzxPcHVNrvxvAzcAKYAnwD4I7pmrN9wN4nKDes5ugZ/rzqvw+ANnhZ/sJcC+lbtYo66XhSUREpMJ02UpERCpMyUNERCpMyUNERCpMyUNERCpMyUNERCpMyUOkGjCzCWbWOtZxiBRT8hCpIhFPO0fDBIKhOcotyvFILafnPEQihINUvkIw8N6RwFKCJ26vBkYA9YD3gIvd3c3sLYIHPI8neJBrJfB7gmHUNwI/cfevzOwmgrGZOgHtgF8TDIF9CsFQECPcfbeZHQXcATQkGA12AsFQHFPCdt8RjCCbVbqdu68rI54vgBuBPQRPGp9QlZ+X1F7qeYj8p8OB+939CGAzwfwQ97r70e7egyCBDI9on+zu2e7+Z+BdoL8HAxo+QTBScLHOBON2jQT+Ccxy954ECeG0cKyze4Cx7n4UMBmY5O5PEzxt/hN37wMUldXuB+K5ATjZ3XuHP1ekSqhbK/Kf1rj7nPD9P4ErgE/N7LdAfYJ5JZYCL4RtnozYNxN4MhyoLplgXo5iM8LexWIgkaCHA8EQEh0IklYP4LVwIrdEgiEpSjtQu8h45gBTzGwqwYCCIlVCyUPkP5W+luvA/QRjBK0JL0HVjdi+LeL9PcAd7j7dzAYDN0Vs2wng7nvNbLd/f814L8H/iwYsdfcBB4jvQO1K4nH3X5jZMcBpwDwzO8rdNx7g+CIHpMtWIv+pnZkV/2I+m+BSFMDX4fwrY8veDQiG/y4ezrqic4bnAhnFP9vM6phZ93DbFoLpig/Ubh9m1tndP3T3GwgmmGpbVjuRilLPQ+Q/5QKXmtlkgqG/HyAY1XYJwYxtc/ez703AU2b2LfAmQZG8XNx9l5mNBe42szSC/z/vJLhENgX4q5kVF8x/qF1pt5lZV4LeyhsEc3iLVJruthKJEN5t9WJYGBeRH6DLViIiUmHqeYiISIWp5yEiIhWm5CEiIhWm5CEiIhWm5CEiIhWm5CEiIhX2/8XLQbOiItkJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "hbcEgchGanYM",
        "outputId": "c7c41276-8b28-42a7-b2ee-ba29a80d2c33"
      },
      "source": [
        "plt.plot([25000,66000,130000,200000,304000],[2.217092580795288,1.7183354389667511,1.5264577686786651,1.38,1.25])\n",
        "plt.xlabel('parameters')\n",
        "plt.ylabel('Bits per charecter')\n",
        " #plt.title('LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Bits per charecter')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68p9Bk_2NOj2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "J-tS2jQCNdDv",
        "outputId": "f31e80b2-2cb9-43ed-a1d0-a870a32fe876"
      },
      "source": [
        " plt.plot([1000,5000,10000,15000,20000],[3200,23000,51000,90000,124000],label='RNN')\n",
        " plt.plot([1000,5000,10000,15000,20000],[3100,22000,50000,88000,120000],label='LSTM')\n",
        " plt.plot([1000,5000,10000,15000,20000],[3000,21000,49000,87000,115000],label='GRU')\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('Bits')\n",
        " plt.title('1 Layer')\n",
        " plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f84a4be50b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuoEG8awugem"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "FL0Gq9bmuj0w",
        "outputId": "907bf6ef-6750-4cf6-a5cf-b6a1477eba3c"
      },
      "source": [
        " plt.plot([1000,5000,10000,15000,20000],[3.2,4.6,5.1,6.0,6.2],label='RNN')\n",
        " plt.plot([1000,5000,10000,15000,20000],[3.1,4.4,5.0,5.8,6.0],label='LSTM')\n",
        " plt.plot([1000,5000,10000,15000,20000],[3.0,4.,49000,87000,115000],label='GRU')\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('Bits')\n",
        " plt.title('1 Layer')\n",
        " plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f84a4b3f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "1KTKE6GJswRM",
        "outputId": "924e4348-f471-4303-949a-ef4b56d5eda6"
      },
      "source": [
        " plt.plot([1000,5000,10000,15000,20000],[3300,24000,53000,89500,123000],\n",
        "          [1000,5000,10000,15000,20000],[3200,22000,52000,89000,120000],\n",
        "          [1000,5000,10000,15000,20000],[3000,20000,49000,87000,115000,])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('Bits')\n",
        " plt.title('2 Layer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2 Layer')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "2sVoN8ALQeol",
        "outputId": "5ebebd81-6276-4cfa-e193-6109df9b1cfa"
      },
      "source": [
        " plt.plot([1000,5000,10000,20000],[3800,19000,48000,90800])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('Bits')\n",
        " plt.title('LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "UANuilpMdUSg",
        "outputId": "6a06878f-f5e0-441c-c154-608f63c2cc68"
      },
      "source": [
        " plt.plot([1000,5000,10000,20000],[4100,21000,50500,100100])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('Bits')\n",
        " plt.title('Gru')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Gru')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AaH3GYEdUIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImGk4KUmdT7j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "S_WreaAfQdUk",
        "outputId": "d755ec15-f121-479d-984b-4cf5a4588e4b"
      },
      "source": [
        " plt.plot([1000,2500,6000,10000],[0.9,0.85,0.82,0.80],\n",
        "          [1000,2500,6000,10000],[0.92,0.89,0.86,0.84])\n",
        " plt.xlabel('parameters')\n",
        " plt.ylabel('square error')\n",
        " #plt.title('LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'square error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}